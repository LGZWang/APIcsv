index:ID,package,description,:LABEL
10001,java.applet,"Provides the classes necessary to create an applet and the classes an applet
uses to communicate with its applet context.

The applet framework involves two
entities: the applet and the applet context. An applet is an 
embeddable window (see the Panel class) with a few extra methods that the applet 
context can use to initialize, start, and stop the applet.

The applet context is an application that is responsible for loading and running
applets. For example, the applet context could be a Web browser or an applet
development environment.",Package
10002,java.awt,"Contains all of the classes for creating user
interfaces and for painting graphics and images. A user interface object such as a button or a
scrollbar is called, in AWT terminology, a component. The Component class is the root of all
AWT components. See Component for a detailed description of properties that all AWT 
components share.

Some components fire events when a user interacts with the components. The AWTEvent
class and its subclasses are used to represent the events that AWT components can fire. See
AWTEvent for a description of the AWT event model.

A container is a component that can contain components and other containers. A con
tainer can also have a layout manager that controls the visual placement of components in the
container. The AWT package contains several layout manager classes and an interface for
building your own layout manager. See Container and LayoutManager for more information.

Each Component object is limited in its maximum size and
its location because the values are stored as an integer.
Also, a platform may further restrict maximum size and location
coordinates. The exact maximum values are dependent on the platform.
There is no way to change these maximum values, either in Java
code or in native code.
These limitations also impose restrictions on component layout.
If the bounds of a Component object exceed a platform limit,
there is no way to properly arrange them within a Container object.
The object's bounds are defined by any object's coordinate
in combination with its size on a respective axis. 

Additional Specification

The AWT Focus Subsystem
The AWT Modality",Package
10003,java.awt.color,"Provides classes for color spaces.  It contains an
implementation of a color space based on the International Color
Consortium (ICC) Profile Format Specification, Version 3.4, August 15,
1997.  It also contains color profiles based on the ICC Profile Format
Specification.",Package
10004,java.awt.datatransfer,"Provides interfaces and classes for transferring data
between and within applications.  It defines the notion of a
""transferable"" object, which is an object capable of being
transferred between or within applications. An object identifies
itself as being transferable by implementing the Transferable
interface.

It also provides a clipboard mechanism, which is an object that
temporarily holds a transferable object that can be transferred
between or within an application. The clipboard is typically used
for copy and paste operations. Although it is possible to create
a clipboard to use within an application, most applications will
use the system clipboard to ensure the data can be transferred
across applications running on the platform.",Package
10005,java.awt.dnd,"Drag and Drop is a direct manipulation gesture found in many Graphical
User Interface systems that provides a mechanism to transfer
information between two entities logically associated with presentation
elements in the GUI. Normally driven by a physical gesture of a
human user using an appropriate input device, Drag and Drop provides both
a mechanism to enable continuous feedback regarding the
possible outcome of any subsequent data transfer to the user during
navigation over the presentation elements in the GUI, and the facilities
to provide for any subsequent data negotiation and transfer. 

This package defines the classes and interfaces necessary to perform Drag
and Drop operations in Java. It
defines classes for the drag-source and the drop-target, as well as
events for transferring the data being dragged. This package also provides
a means for giving visual feedback to the user throughout the
duration of the Drag and Drop operation. 

A typical Drag and Drop operation can be decomposed into the following
states (not entirely sequentially): 

A DragSource comes into existence, 
associated with some presentation
element (Component) in the GUI, to initiate a Drag and Drop of
some potentially Transferable data. 

1 or more DropTarget(s) come into/go out of 
existence, associated
with presentation elements in the GUI (Components), potentially
capable of consuming Transferable data types. 

 A DragGestureRecognizer is 
obtained from the DragSource and is
associated with a Component in order 
to track and identify any Drag
initiating gesture by the user over the Component. 

 A user makes a Drag gesture over the Component, 
which the registered
DragGestureRecognizer detects, and notifies its
DragGestureListener of. 

Note: Although this API consistently refers to the stimulus for a
drag and drop operation being a physical gesture by a human user, this
does not preclude a programmatically driven DnD operation given the
appropriate implementation of a DragSource. This package
contains the abstract class MouseDragGestureRecognizer for
recognizing mouse device gestures. Other abstract subclasses may be
provided by the platform to support other input devices or
particular Component class semantics. 
    
 The DragGestureListener causes the 
DragSource to initiate the Drag
and Drop operation on behalf of the user, perhaps animating the
GUI Cursor and/or rendering an Image of the item(s) that are the
subject of the operation.

 As the user gestures navigate over Component(s) 
in the GUI with
associated DropTarget(s), the DragSource 
receives notifications in order
to provide ""Drag Over"" feedback effects, and the DropTarget(s)
receive notifications in order to provide ""Drag Under"" feedback effects
based upon the operation(s) supported and the data type(s) involved. 



The gesture itself moves a logical cursor across the GUI hierarchy,
intersecting the geometry of GUI Component(s), possibly resulting in
the logical ""Drag"" cursor entering, crossing, and subsequently
leaving Component(s) and associated DropTarget(s). 

The DragSource object manifests ""Drag Over"" feedback to the user, in the typical case by animating the GUI Cursor associated with the
logical cursor. 

DropTarget objects manifest ""Drag Under"" feedback to the user, in
the typical case, by rendering animations into their associated GUI
Component(s) under the GUI Cursor. 

The determination of the feedback effects, and the ultimate success
or failure of the data transfer, should one occur, is parameterized
as follows: 

 By the transfer ""operation"" selected by the user, and supported by
both the DragSource and DropTarget: Copy, Move or Reference(link). 

 By the intersection of the set of data types provided by the
DragSource and the set of data types comprehensible by the 
DropTarget. 

When the user terminates the drag operation, normally resulting in a
successful Drop, both the DragSource and DropTarget
receive
notifications that include, and result in the type negotiation and
transfer of, the information associated with the DragSource via a
Transferable object.",Package
10006,java.awt.event,"Provides interfaces and classes for dealing with different
types of events fired by AWT components. See the java.awt.AWTEvent
class for details on the AWT event model.  Events are fired by event
sources.  An event listener registers with an event source to receive
notifications about the events of a particular type.  This package
defines events and event listeners, as well as event listener
adapters, which are convenience classes to make easier the process of
writing event listeners.",Package
10007,java.awt.font,"Provides classes and interface relating to fonts.  It
contains support for representing Type 1, Type 1 Multiple Master
fonts, OpenType fonts, and TrueType fonts.",Package
10008,java.awt.geom,"Provides the Java 2D classes for defining and performing operations
on objects related to two-dimensional geometry.  Some important features
of the package include:

classes for manipulating geometry, such as AffineTransform and
the PathIterator interface which is implemented by all Shape objects.

classes that implement the Shape interface, such as
CubicCurve2D, Ellipse2D, Line2D, Rectangle2D, and GeneralShape.

the Area class which provides mechanisms for add (union), subtract,
intersect, and exclusiveOR operations on other Shape objects.",Package
10009,java.awt.im,"Provides classes and interfaces for the input method framework.
This package enables text editing components to receive text input
through input methods. Input methods are software components that let
the user enter text in ways other than simple typing on a keyboard.
They are commonly used to enter Japanese, Chinese, or Korean -
languages using thousands of different characters - on keyboards with
far fewer keys. However, the framework also supports input methods
for other languages and the use of entirely different input
mechanisms, such as handwriting or speech recognition.
Package Specification

Input Method
   Framework Specification
Input
   Method Client API Reference

Related Documentation
For overviews, tutorials, examples, guides, and tool
documentation, please see:

Input Method
   Framework Overview
Input
   Method Client API Tutorial",Package
10010,java.awt.im.spi,"Provides interfaces that enable the development of input methods
that can be used with any Java runtime environment. Input methods are
software components that let the user enter text in ways other than
simple typing on a keyboard. They are commonly used to enter
Japanese, Chinese, or Korean - languages using thousands of different
characters - on keyboards with far fewer keys. However, this package
also allows the development of input methods for other languages and
the use of entirely different input mechanisms, such as handwriting
recognition.
Package Specification

Input Method
   Framework Specification
Input
   Method Engine SPI Reference

Packaging Input Methods
Input methods are packaged as installed extensions, as specified
by the Extension
Mechanism. The main JAR file of an input method must contain the
file:
    META-INF/services/java.awt.im.spi.InputMethodDescriptor
The file should contain a list of fully-qualified class names, one
per line, of classes implementing the
java.awt.im.spi.InputMethodDescriptor interface. Space
and tab characters surrounding each name, as well as blank lines, are
ignored. The comment character is '#'
(\u0023); on each line all characters following the
first comment character are ignored. The file must be encoded in
UTF-8.
For example, if the fully-qualified name of the class that
implements java.awt.im.spi.InputMethodDesciptor for the
Foo input method is
com.sun.ime.FooInputMethodDescriptor, the file
META-INF/services/java.awt.im.spi.InputMethodDescriptor
contains a line:
    com.sun.ime.FooInputMethodDescriptor
The input method must also provide at least two classes: one class
implementing the java.awt.im.spi.InputMethodDescriptor
interface, one class implementing the
java.awt.im.spi.InputMethod interface. The input method
should separate the implementations for these interfaces, so that
loading of the class implementing InputMethod can be
deferred until actually needed.
Loading Input Methods
The input method framework will usually defer loading of input
method classes until they are absolutely needed. It loads only the
InputMethodDescriptor implementations during AWT
initialization. It loads an InputMethod implementation
when the input method has been selected.
Java Input Methods and Peered Text
Components
The Java input method framework intends to support all
combinations of input methods (host input methods and Java input
methods) and components (peered and lightweight). However, because of
limitations in the underlying platform, it may not always be possible
to enable the communication between Java input methods and peered AWT
components. Support for this specific combination is therefore
platform dependent. In Sun's Java SE Runtime Environments, this
combination is supported on Windows, but not on Solaris.
Related Documentation
For overviews, tutorials, examples, guides, and tool
documentation, please see:

Input
   Method Framework Overview
Input
   Method Engine SPI Tutorial",Package
10011,java.awt.image,"Provides classes for creating and modifying images.
Images are processed using a streaming framework that involves an
image producer, optional image filters, and an image consumer.  This
framework makes it possible to progressively render an image while it
is being fetched and generated.  Moreover, the framework allows an
application to discard the storage used by an image and to regenerate
it at any time.  This package provides a number of image producers,
consumers, and filters that you can configure for your image
processing needs.",Package
10012,java.awt.image.renderable,"Provides classes and interfaces for producing
rendering-independent images.",Package
10013,java.awt.print,"Provides classes and interfaces for a general printing API.  The
API includes such features as:

the ability to specify document types
mechanisms for control of page setup and page formats
the ability to manage job control dialogs",Package
10014,java.beans,"Contains classes related to developing
beans -- components
based on the JavaBeans™ architecture.
A few of the
classes are used by beans while they run in an application. 
For example, the event classes are
used by beans that fire property and vetoable change 
events (see 
PropertyChangeEvent). However, most of the classes in this
package are meant to be used by a bean editor (that is, a development environment 
for customizing and putting together beans to create an application). In
particular, these classes help the bean editor create a user 
interface that the user can use to customize the bean. For example, a bean may 
contain a property of a special type that a bean editor may not know how to handle. 
By using the PropertyEditor interface, a bean developer can
provide an editor for this special type.


To minimize the resources used by a bean, the classes used by bean editors are loaded only
when the bean is being edited. They are not needed while the bean is running in an application
and therefore not loaded. This information is kept in what's called a bean-info (see BeanInfo).


Unless explicitly stated, null values or empty Strings are not valid 
parameters for the methods in this package. You may expect to see 
exceptions if these parameters are used.


Long-Term Persistence

As of v1.4,
the java.beans package provides support for 
long-term persistence -- reading and
writing a bean as a textual representation of its property values.
The property values are treated as beans,
and are recursively read or written to capture 
their publicly available state.
This approach is suitable for long-term storage 
because it relies only on public API,
rather than the likely-to-change private implementation.



Note:
The persistence scheme cannot automatically instantiate 
custom inner classes, such as you might use for event handlers.
By using the EventHandler class
instead of inner classes for custom event handlers,
you can avoid this problem.




You read and write beans in XML format using the
XMLDecoder
and 
XMLEncoder
classes, respectively.
One notable feature of the persistence scheme is that
reading in a bean requires no special knowledge of the bean.


Writing out a bean, on the other hand,
sometimes requires special knowledge of the bean's type.
If the bean's state can be
expressed using only the no-argument constructor and 
public getter and setter methods for properties,
no special knowledge is required.
Otherwise, the bean requires a custom persistence delegate --
an object that is in charge of writing out beans of a particular type.
All classes provided in the JDK that descend 
from java.awt.Component, 
as well as all their properties, 
automatically have persistence delegates.



If you need (or choose) to provide a persistence delegate for a bean,
you can do so either by using a 
DefaultPersistenceDelegate
instance
or by creating your own subclass of PersistenceDelegate.
If the only reason a bean needs a persistence delegate 
is because you want to invoke the bean's constructor with 
property values as arguments,
you can create the bean's persistence delegate 
with the one-argument
DefaultPersistenceDelegate
constructor.
Otherwise,
you need to implement your own persistence delegate,
for which you're likely to need the following classes:


 PersistenceDelegate
 The abstract class from which all persistence delegates descend.
     Your subclass should use its knowledge of the bean's type to provide 
     whatever Statements and Expressions
     are necessary to create the bean
     and restore its state.
 Statement
 Represents the invocation of a single method on an object.
     Includes a set of arguments to the method.
 Expression
 A subclass of Statement
     used for methods that return a value.


Once you create a persistence delegate,
you register it using the
setPersistenceDelegate method of
XMLEncoder.


Related Documentation

For overview, architecture, and tutorial documentation, please see:

JavaBeans, a trail in The Java Tutorial.
  Long-Term Persistence, an article in The Swing Connection.",Package
10015,java.beans.beancontext,"Provides classes and interfaces relating to bean context.
A bean context is a container for beans and defines the execution
environment for the beans it contains.  There can be several beans in
a single bean context, and a bean context can be nested within another
bean context.  This package also contains events and listener
interface for beans being added and removed from a bean context.",Package
10016,java.io,"Provides for system input and output through data streams,serialization and the file system.Unless otherwise noted, passing a null argument to a constructoror method in any class or interface in this package will cause a
NullPointerException to be thrown.

Package Specification

 Java Object Serialization Specification 

Related Documentation

For overviews, tutorials, examples, guides, and tool documentation,
please see:

Serialization Enhancements",Package
10017,java.lang,"Provides classes that are fundamental to the design of the Java
 programming language. The most important classes are Object, which is the root of the class hierarchy, and Class, instances of which represent classes at run time.

 Frequently it is necessary to represent a value of primitive
 type as if it were an object. The wrapper classes Boolean,
 Character, Integer, Long, Float,
 and Double serve this purpose.  An object of type Double, for example, contains a field whose type is double,
 representing that value in such a way that a reference to it can be
 stored in a variable of reference type.  These classes also provide
 a number of methods for converting among primitive values, as well
 as supporting such standard methods as equals and hashCode.  The
 Void class is a non-instantiable class that holds a
 reference to a Class object representing the type void.

 The class Math provides commonly used mathematical
 functions such as sine, cosine, and square root. The classes String, StringBuffer, and StringBuilder similarly
 provide commonly used operations on character strings.

 Classes ClassLoader, Process, ProcessBuilder, Runtime, SecurityManager, and
 System provide ""system operations"" that manage the dynamic
 loading of classes, creation of external processes, host
 environment inquiries such as the time of day, and enforcement of
 security policies.

 Class Throwable encompasses objects that may be thrown
 by the throw statement. Subclasses of Throwable
 represent errors and exceptions.

 
Character Encodings

 The specification of the java.nio.charset.Charset class describes the naming conventions
 for character encodings as well as the set of standard encodings
 that must be supported by every implementation of the Java
 platform.",Package
10018,java.lang.annotation,"Provides library support for the Java programming language
 annotation facility.",Package
10019,java.lang.instrument,"Provides services that allow Java programming language agents to instrument programs running on the JVM. 
The mechanism for instrumentation is modification of the byte-codes of methods.

Package Specification
 
An agent is deployed as a JAR file. An attribute in the JAR file manifest specifies the
agent class which will be loaded to start the agent. For implementations that support a command-line 
interface, an agent is started by specifying an option on the command-line.  
Implementations may also support a mechanism to start agents some time after the VM has
started. For example, an implementation may provide a mechanism that allows a tool to 
attach to a running application, and initiate the loading of the tool's agent into
the running application. The details as to how the load is initiated, is implementation
dependent.

Command-Line Interface
 
On implementations with a command-line interface, an agent is started by
adding this option to the command-line:

-javaagent:jarpath[=options]

jarpath is the path to the agent JAR file.
options is the agent options.
This switch may be used multiple times on the same command-line, 
thus creating multiple agents.
More than one agent may use the same jarpath.
An agent JAR file must conform to the JAR file specification.


The manifest of the agent JAR file must contain the attribute Premain-Class. The
value of this attribute is the name of the agent class. The agent class must implement a 
public static premain method similar in principle to the main application 
entry point.  After the Java Virtual Machine (JVM) has initialized, each premain method 
will be called in the order the agents were specified, then the real application
main method will be called. 
Each premain method must return in order for the startup sequence to proceed.


The premain method has one of two possible signatures. The JVM first attempts to
invoke the following method on the agent class:


public static void
premain(String agentArgs, Instrumentation inst);



If the agent class does not implement this method then the JVM will attempt to invoke:


public static void
premain(String agentArgs);



The agent class may also have an agentmain method for use when the agent is started 
after VM startup. When the agent is started using a command-line option, the agentmain
method is not invoked.



The agent class will be loaded by the system class loader
(see ClassLoader.getSystemClassLoader). This is
the class loader which typically loads the class containing the application main method.
The premain methods will be run under the same security and classloader 
rules as the application main method.
There are no modeling restrictions on what the agent premain method may do.
Anything application main can do, including creating threads, is legal from premain.


Each agent is passed its agent options via the agentArgs parameter.
The agent options are passed as a single string,
any additional parsing should be performed by the agent itself.


If the agent cannot be resolved 
(for example, because the agent class cannot be loaded,
or because the agent class does not have an appropriate premain method), the JVM will abort.
If a premain method throws an uncaught exception, the JVM will abort.



Starting Agents After VM Startup

An implementation may provide a mechanism to start agents sometime after the
the VM has started. The details as to how this is initiated are implementation 
specific but typically the application has already started and its 
main method has already been invoked. In cases where an implementation
supports the starting of agents after the VM has started the following applies:


The manifest of the agent JAR must contain the attribute Agent-Class. 
      The value of this attribute is the name of the agent class. 
The agent class must implement a public static agentmain method. 
The system class loader (
      ClassLoader.getSystemClassLoader) must
      support a mechanism to add an agent JAR file to the system class path. 


The agent JAR is appended to the system class path. This is the class loader that typically loads 
the class containing the application main method. The agent class is loaded and the
JVM attempts to invoke the agentmain method. The JVM first attempts to invoke 
the following method on the agent class:


public static void
agentmain(String agentArgs, Instrumentation inst);



If the agent class does not implement this method then the JVM will attempt to invoke:


public static void
agentmain(String agentArgs);



The agent class may also have an premain method for use when the agent is started
using a command-line option. When the agent is started after VM startup the premain
method is not invoked.



The agent is passed its agent options via the agentArgs parameter.
The agent options are passed as a single string,
any additional parsing should be performed by the agent itself. 


The agentmain method should do any necessary initialization 
required to start the agent. When startup is complete the method should 
return. If the agent cannot be started
(for example, because the agent class cannot be loaded,
or because the agent class does not have a conformant agentmain method), the JVM will
not abort. If the agentmain method throws an uncaught exception it will be ignored.



Manifest Attributes
The following manifest attributes are defined for an agent JAR file:


Premain-Class

                        When an agent is specified at JVM launch time this attribute
                        specifies the agent class.
                        That is, the class containing the premain method.
                        When an agent is specified at JVM launch time this attribute
                        is required. If the attribute is not present the JVM will abort.
                        Note: this is a class name, not a file name or path.                                                    

Agent-Class

                        If an implementation supports a mechanism to start agents 
                        sometime after the VM has started then this attribute specifies
                        the agent class.
                        That is, the class containing the agentmain method.
                        This attribute is required, if it is not present the agent
                        will not be started.
                        Note: this is a class name, not a file name or path.

Boot-Class-Path

                        A list of paths to be searched by the bootstrap class
                        loader. Paths represent directories or libraries
                        (commonly referred to as JAR or zip libraries on
                        many platforms).                        
                        These paths are searched by the
                        bootstrap class loader after the platform specific
                        mechanisms of locating a class have failed.
                        Paths are searched in the order listed.
                        Paths in the list are separated by one or more spaces.
                        A path takes the syntax of the path component of a
                        hierarchical URI. The path is
                        absolute if it begins with a slash character ('/'),
                        otherwise it is relative. A relative path is resolved
                        against the absolute path of the agent JAR file.
                        Malformed and non-existent paths are ignored.   
                        When an agent is started sometime after the VM has
                        started then paths that do not represent a JAR file
                        are ignored.
                        This attribute is optional.

Can-Redefine-Classes

                        Boolean (true or false, case irrelevant).
                        Is the ability to redefine classes
                        needed by this agent.
                        Values other than true are considered false.
                        This attribute is optional, the default is false.

Can-Retransform-Classes

                        Boolean (true or false, case irrelevant).
                        Is the ability to retransform classes
                        needed by this agent.
                        Values other than true are considered false.
                        This attribute is optional, the default is false.

Can-Set-Native-Method-Prefix

                        Boolean (true or false, case irrelevant).
                        Is the ability to set native method prefix needed by this agent.
                        Values other than true are considered false.
                        This attribute is optional, the default is false.



 
An agent JAR file may have both the Premain-Class and Agent-Class
attributes present in the manifest. When the agent is started on the command-line using
the -javaagent option then the Premain-Class attribute
specifies the name of the agent class and the Agent-Class attribute is
ignored. Similarly, if the agent is started sometime after the VM has started, then
the Agent-Class attribute specifies the name of the agent class
(the value of Premain-Class attribute is ignored).

Related Documentation

For tool documentation, please see:

JDK Tools and Utilities",Package
10020,java.lang.invoke,"The java.lang.invoke package contains dynamic language support provided directly by
 the Java core class libraries and virtual machine.

 
 As described in the Java Virtual Machine Specification,
 certain types in this package have special relations to dynamic
 language support in the virtual machine:
 
The class MethodHandle contains
 signature polymorphic methods
 which can be linked regardless of their type descriptor.
 Normally, method linkage requires exact matching of type descriptors.
 
The JVM bytecode format supports immediate constants of
 the classes MethodHandle and MethodType.
 

Summary of relevant Java Virtual Machine changes
 The following low-level information summarizes relevant parts of the
 Java Virtual Machine specification.  For full details, please see the
 current version of that specification.

 Each occurrence of an invokedynamic instruction is called a dynamic call site.
 invokedynamic instructions
 A dynamic call site is originally in an unlinked state.  In this state, there is
 no target method for the call site to invoke.
 
 Before the JVM can execute a dynamic call site (an invokedynamic instruction),
 the call site must first be linked.
 Linking is accomplished by calling a bootstrap method
 which is given the static information content of the call site,
 and which must produce a method handle
 that gives the behavior of the call site.
 
 Each invokedynamic instruction statically specifies its own
 bootstrap method as a constant pool reference.
 The constant pool reference also specifies the call site's name and type descriptor,
 just like invokevirtual and the other invoke instructions.
 
 Linking starts with resolving the constant pool entry for the
 bootstrap method, and resolving a MethodType object for
 the type descriptor of the dynamic call site.
 This resolution process may trigger class loading.
 It may therefore throw an error if a class fails to load.
 This error becomes the abnormal termination of the dynamic
 call site execution.
 Linkage does not trigger class initialization.
 
 The bootstrap method is invoked on at least three values:
 
a MethodHandles.Lookup, a lookup object on the caller class in which dynamic call site occurs 
a String, the method name mentioned in the call site 
a MethodType, the resolved type descriptor of the call 
optionally, between 1 and 251 additional static arguments taken from the constant pool 

 Invocation is as if by
 MethodHandle.invoke.
 The returned result must be a CallSite (or a subclass).
 The type of the call site's target must be exactly equal to the type
 derived from the dynamic call site's type descriptor and passed to
 the bootstrap method.
 The call site then becomes permanently linked to the dynamic call site.
 
 As documented in the JVM specification, all failures arising from
 the linkage of a dynamic call site are reported
 by a BootstrapMethodError,
 which is thrown as the abnormal termination of the dynamic call
 site execution.
 If this happens, the same error will the thrown for all subsequent
 attempts to execute the dynamic call site.

 timing of linkage
 A dynamic call site is linked just before its first execution.
 The bootstrap method call implementing the linkage occurs within
 a thread that is attempting a first execution.
 
 If there are several such threads, the bootstrap method may be
 invoked in several threads concurrently.
 Therefore, bootstrap methods which access global application
 data must take the usual precautions against race conditions.
 In any case, every invokedynamic instruction is either
 unlinked or linked to a unique CallSite object.
 
 In an application which requires dynamic call sites with individually
 mutable behaviors, their bootstrap methods should produce distinct
 CallSite objects, one for each linkage request.
 Alternatively, an application can link a single CallSite object
 to several invokedynamic instructions, in which case
 a change to the target method will become visible at each of
 the instructions.
 
 If several threads simultaneously execute a bootstrap method for a single dynamic
 call site, the JVM must choose one CallSite object and install it visibly to
 all threads.  Any other bootstrap method calls are allowed to complete, but their
 results are ignored, and their dynamic call site invocations proceed with the originally
 chosen target object.

 
Discussion:
 These rules do not enable the JVM to duplicate dynamic call sites,
 or to issue “causeless” bootstrap method calls.
 Every dynamic call site transitions at most once from unlinked to linked,
 just before its first invocation.
 There is no way to undo the effect of a completed bootstrap method call.

 types of bootstrap methods
 As long as each bootstrap method can be correctly invoked
 by MethodHandle.invoke, its detailed type is arbitrary.
 For example, the first argument could be Object
 instead of MethodHandles.Lookup, and the return type
 could also be Object instead of CallSite.
 (Note that the types and number of the stacked arguments limit
 the legal kinds of bootstrap methods to appropriately typed
 static methods and constructors of CallSite subclasses.)
 
 If a given invokedynamic instruction specifies no static arguments,
 the instruction's bootstrap method will be invoked on three arguments,
 conveying the instruction's caller class, name, and method type.
 If the invokedynamic instruction specifies one or more static arguments,
 those values will be passed as additional arguments to the method handle.
 (Note that because there is a limit of 255 arguments to any method,
 at most 251 extra arguments can be supplied, since the bootstrap method
 handle itself and its first three arguments must also be stacked.)
 The bootstrap method will be invoked as if by either MethodHandle.invoke
 or invokeWithArguments.  (There is no way to tell the difference.)
 
 The normal argument conversion rules for MethodHandle.invoke apply to all stacked arguments.
 For example, if a pushed value is a primitive type, it may be converted to a reference by boxing conversion.
 If the bootstrap method is a variable arity method (its modifier bit 0x0080 is set),
 then some or all of the arguments specified here may be collected into a trailing array parameter.
 (This is not a special rule, but rather a useful consequence of the interaction
 between CONSTANT_MethodHandle constants, the modifier bit for variable arity methods,
 and the asVarargsCollector transformation.)
 
 Given these rules, here are examples of legal bootstrap method declarations,
 given various numbers N of extra arguments.
 The first rows (marked *) will work for any number of extra arguments.
 
Nsample bootstrap method
*CallSite bootstrap(Lookup caller, String name, MethodType type, Object... args)
*CallSite bootstrap(Object... args)
*CallSite bootstrap(Object caller, Object... nameAndTypeWithArgs)
0CallSite bootstrap(Lookup caller, String name, MethodType type)
0CallSite bootstrap(Lookup caller, Object... nameAndType)
1CallSite bootstrap(Lookup caller, String name, MethodType type, Object arg)
2CallSite bootstrap(Lookup caller, String name, MethodType type, Object... args)
2CallSite bootstrap(Lookup caller, String name, MethodType type, String... args)
2CallSite bootstrap(Lookup caller, String name, MethodType type, String x, int y)

 The last example assumes that the extra arguments are of type
 CONSTANT_String and CONSTANT_Integer, respectively.
 The second-to-last example assumes that all extra arguments are of type
 CONSTANT_String.
 The other examples work with all types of extra arguments.
 
 As noted above, the actual method type of the bootstrap method can vary.
 For example, the fourth argument could be MethodHandle,
 if that is the type of the corresponding constant in
 the CONSTANT_InvokeDynamic entry.
 In that case, the MethodHandle.invoke call will pass the extra method handle
 constant as an Object, but the type matching machinery of MethodHandle.invoke
 will cast the reference back to MethodHandle before invoking the bootstrap method.
 (If a string constant were passed instead, by badly generated code, that cast would then fail,
 resulting in a BootstrapMethodError.)
 
 Extra bootstrap method arguments are intended to allow language implementors
 to safely and compactly encode metadata.
 In principle, the name and extra arguments are redundant,
 since each call site could be given its own unique bootstrap method.
 Such a practice is likely to produce large class files and constant pools.",Package
10021,java.lang.management,"Provides the management interfaces for monitoring and management of the
Java virtual machine and other components in the Java runtime.
It allows both local and remote
monitoring and management of the running Java virtual machine.

Platform MXBean

A platform MXBean is a managed bean that
conforms to the JMX
Instrumentation Specification and only uses a set of basic data types.
Each platform MXBean is a PlatformManagedObject
with a unique
name.

ManagementFactory
The ManagementFactory class is the management
factory class for the Java platform.  This class provides a set of
static factory methods to obtain the MXBeans for the Java platform
to allow an application to access the MXBeans directly.

A platform MBeanServer can be accessed with the
getPlatformMBeanServer method.  On the first call to this method,
it creates the platform MBeanServer and registers all platform MXBeans
including platform MXBeans.
Each platform MXBean is registered with a unique name defined in
the specification of the management interface.
This is a single MBeanServer that can be shared by different managed
components running within the same Java virtual machine.

Interoperability
A management application and a platform MBeanServer of a running
virtual machine can interoperate
without requiring classes used by the platform MXBean interfaces.
The data types being transmitted between the JMX connector
server and the connector client are JMX
open types and
this allows interoperation across versions.
A data type used by the MXBean interfaces are mapped to an
open type when being accessed via MBeanServer interface.
See the 
MXBean specification for details.

Ways to Access MXBeans
An application can monitor the instrumentation of the
Java virtual machine and the runtime in the following ways:

1. Direct access to an MXBean interface


Get an MXBean instance locally in the running Java virtual machine:

   RuntimeMXBean mxbean = ManagementFactory.getRuntimeMXBean();

   // Get the standard attribute ""VmVendor""
   String vendor = mxbean.getVmVendor();

Or by calling the
        getPlatformMXBean or
        getPlatformMXBeans method:

   RuntimeMXBean mxbean = ManagementFactory.getPlatformMXBean(RuntimeMXBean.class);

   // Get the standard attribute ""VmVendor""
   String vendor = mxbean.getVmVendor();



Construct an MXBean proxy instance that forwards the
    method calls to a given MBeanServer:

   MBeanServerConnection mbs;

   // Connect to a running JVM (or itself) and get MBeanServerConnection
   // that has the JVM MBeans registered in it
   ...

   // Get a MBean proxy for RuntimeMXBean interface
   RuntimeMXBean proxy =
       ManagementFactory.getPlatformMXBean(mbs,
                                           RuntimeMXBean.class);
   // Get standard attribute ""VmVendor""
   String vendor = proxy.getVmVendor();

A proxy is typically used to access an MXBean
   in a remote Java virtual machine.
   An alternative way to create an MXBean proxy is:

   RuntimeMXBean proxy =
       ManagementFactory.newPlatformMXBeanProxy(mbs,
                                                ManagementFactory.RUNTIME_MXBEAN_NAME,
                                                RuntimeMXBean.class);




2. Indirect access to an MXBean interface via MBeanServer

Go through the
    platform MBeanServer to access MXBeans locally or
    a specific MBeanServerConnection to access
    MXBeans remotely.
    The attributes and operations of an MXBean use only
    JMX open types which include basic data types,
    CompositeData,
    and TabularData
    defined in OpenType.

   MBeanServerConnection mbs;

   // Connect to a running JVM (or itself) and get MBeanServerConnection
   // that has the JVM MXBeans registered in it
   ...

   try {
       // Assuming the RuntimeMXBean has been registered in mbs
       ObjectName oname = new ObjectName(ManagementFactory.RUNTIME_MXBEAN_NAME);

       // Get standard attribute ""VmVendor""
       String vendor = (String) mbs.getAttribute(oname, ""VmVendor"");
   } catch (....) {
       // Catch the exceptions thrown by ObjectName constructor
       // and MBeanServer.getAttribute method
       ...
   }



Platform Extension
A Java virtual machine implementation may add its platform extension to
the management interface by defining platform-dependent
interfaces that extend the standard management interfaces to include
platform-specific metrics and management operations.
The static factory methods in the ManagementFactory class will
return the MXBeans with the platform extension.


It is recommended to name the platform-specific attributes with
a vendor-specific prefix such as the vendor's name to
avoid collisions of the attribute name between the future extension
to the standard management interface and the platform extension.
If the future extension to the standard management interface defines
a new attribute for a management interface and the attribute name
is happened to be same as some vendor-specific attribute's name,
the applications accessing that vendor-specific attribute would have
to be modified to cope with versioning and compatibility issues.

Below is an example showing how to access an attribute
from the platform extension:


1) Direct access to the Oracle-specific MXBean interface


   List<com.sun.management.GarbageCollectorMXBean> mxbeans =
       ManagementFactory.getPlatformMXBeans(com.sun.management.GarbageCollectorMXBean.class);

   for (com.sun.management.GarbageCollectorMXBean gc : mxbeans) {
       // Get the standard attribute ""CollectionCount""
       String count = mxbean.getCollectionCount();

       // Get the platform-specific attribute ""LastGcInfo""
       GcInfo gcinfo = gc.getLastGcInfo();
       ...
   }



2) Access the Oracle-specific MXBean interface via MBeanServer
   through proxy


   MBeanServerConnection mbs;

   // Connect to a running JVM (or itself) and get MBeanServerConnection
   // that has the JVM MXBeans registered in it
   ...

   List<com.sun.management.GarbageCollectorMXBean> mxbeans =
       ManagementFactory.getPlatformMXBeans(mbs, com.sun.management.GarbageCollectorMXBean.class);

   for (com.sun.management.GarbageCollectorMXBean gc : mxbeans) {
       // Get the standard attribute ""CollectionCount""
       String count = mxbean.getCollectionCount();

       // Get the platform-specific attribute ""LastGcInfo""
       GcInfo gcinfo = gc.getLastGcInfo();
       ...
   }

 Unless otherwise noted, passing a null argument to a constructor
or method in any class or interface in this package will cause a NullPointerException to be thrown.

 The java.lang.management API is thread-safe.",Package
10022,java.lang.ref,"Provides reference-object classes, which support a limited degree of
interaction with the garbage collector.  A program may use a reference object
to maintain a reference to some other object in such a way that the latter
object may still be reclaimed by the collector.  A program may also arrange to
be notified some time after the collector has determined that the reachability
of a given object has changed.


Package Specification

A reference object encapsulates a reference to some other object so
that the reference itself may be examined and manipulated like any other
object.  Three types of reference objects are provided, each weaker than the
last: soft, weak, and phantom.  Each type
corresponds to a different level of reachability, as defined below.  Soft
references are for implementing memory-sensitive caches, weak references are
for implementing canonicalizing mappings that do not prevent their keys (or
values) from being reclaimed, and phantom references are for scheduling
pre-mortem cleanup actions in a more flexible way than is possible with the
Java finalization mechanism.

 Each reference-object type is implemented by a subclass of the abstract
base Reference class.  An instance of one of
these subclasses encapsulates a single reference to a particular object, called
the referent.  Every reference object provides methods for getting and
clearing the reference.  Aside from the clearing operation reference objects
are otherwise immutable, so no set operation is provided.  A
program may further subclass these subclasses, adding whatever fields and
methods are required for its purposes, or it may use these subclasses without
change.


Notification

A program may request to be notified of changes in an object's reachability by
registering an appropriate reference object with a reference
queue at the time the reference object is created.  Some time after the
garbage collector determines that the reachability of the referent has changed
to the value corresponding to the type of the reference, it will add the
reference to the associated queue.  At this point, the reference is considered
to be enqueued.  The program may remove references from a queue either
by polling or by blocking until a reference becomes available.  Reference
queues are implemented by the ReferenceQueue
class.

 The relationship between a registered reference object and its queue is
one-sided.  That is, a queue does not keep track of the references that are
registered with it.  If a registered reference becomes unreachable itself, then
it will never be enqueued.  It is the responsibility of the program using
reference objects to ensure that the objects remain reachable for as long as
the program is interested in their referents.

 While some programs will choose to dedicate a thread to removing reference
objects from one or more queues and processing them, this is by no means
necessary.  A tactic that often works well is to examine a reference queue in
the course of performing some other fairly-frequent action.  For example, a
hashtable that uses weak references to implement weak keys could poll its
reference queue each time the table is accessed.  This is how the WeakHashMap class works.  Because the ReferenceQueue.poll method simply
checks an internal data structure, this check will add little overhead to the
hashtable access methods.


Automatically-cleared references

Soft and weak references are automatically cleared by the collector before
being added to the queues with which they are registered, if any.  Therefore
soft and weak references need not be registered with a queue in order to be
useful, while phantom references do.  An object that is reachable via phantom
references will remain so until all such references are cleared or themselves
become unreachable.



Reachability

Going from strongest to weakest, the different levels of reachability reflect
the life cycle of an object.  They are operationally defined as follows:


 An object is strongly reachable if it can be reached by some
thread without traversing any reference objects.  A newly-created object is
strongly reachable by the thread that created it.

 An object is softly reachable if it is not strongly reachable but
can be reached by traversing a soft reference.

 An object is weakly reachable if it is neither strongly nor
softly reachable but can be reached by traversing a weak reference.  When the
weak references to a weakly-reachable object are cleared, the object becomes
eligible for finalization.

 An object is phantom reachable if it is neither strongly, softly,
nor weakly reachable, it has been finalized, and some phantom reference refers
to it.

 Finally, an object is unreachable, and therefore eligible for
reclamation, when it is not reachable in any of the above ways.",Package
10023,java.lang.reflect,"Provides classes and interfaces for obtaining reflective
 information about classes and objects.  Reflection allows
 programmatic access to information about the fields, methods and
 constructors of loaded classes, and the use of reflected fields,
 methods, and constructors to operate on their underlying
 counterparts, within security restrictions.

 AccessibleObject allows suppression of access checks if
 the necessary ReflectPermission is available.

 Array provides static methods to dynamically create and
 access arrays.

 Classes in this package, along with java.lang.Class
 accommodate applications such as debuggers, interpreters, object
 inspectors, class browsers, and services such as Object
 Serialization and JavaBeans that need access to either the public
 members of a target object (based on its runtime class) or the
 members declared by a given class.",Package
10024,java.math,"Provides classes for performing arbitrary-precision integer
 arithmetic (BigInteger) and arbitrary-precision decimal
 arithmetic (BigDecimal).  BigInteger is analogous
 to the primitive integer types except that it provides arbitrary
 precision, hence operations on BigIntegers do not overflow
 or lose precision.  In addition to standard arithmetic operations,
 BigInteger provides modular arithmetic, GCD calculation,
 primality testing, prime generation, bit manipulation, and a few
 other miscellaneous operations.

 BigDecimal provides arbitrary-precision signed decimal
 numbers suitable for currency calculations and the like.  BigDecimal gives the user complete control over rounding behavior,
 allowing the user to choose from a comprehensive set of eight
 rounding modes.",Package
10025,java.net,"Provides the classes for implementing networking applications.

 The java.net package can be roughly divided in two sections:

 A Low Level API, which deals with the following abstractions:

Addresses, which are networking identifiers, like IP addresses.
Sockets, which are basic bidirectional data communication mechanisms.
Interfaces, which describe network interfaces. 

 A High Level API, which deals with the following abstractions:

URIs, which represent Universal Resource Identifiers.
URLs, which represent Universal Resource Locators.
Connections, which represents connections to the resource pointed to by URLs.


Addresses
Addresses are used throughout the java.net APIs as either host identifiers, or socket endpoint identifiers.
The InetAddress class is the abstraction representing an IP (Internet Protocol) address.  It has two subclasses:

Inet4Address for IPv4 addresses.
Inet6Address for IPv6 addresses.

But, in most cases, there is no need to deal directly with the subclasses, as the InetAddress abstraction should cover most of the needed functionality.
About IPv6
Not all systems have support for the IPv6 protocol, and while the Java networking stack will attempt to detect it and use it transparently when available, it is also possible to disable its use with a system property. In the case where IPv6 is not available, or explicitly disabled, Inet6Address are not valid arguments for most networking operations any more. While methods like InetAddress.getByName(java.lang.String) are guaranteed not to return an Inet6Address when looking up host names, it is possible, by passing literals, to create such an object. In which case, most methods, when called with an Inet6Address will throw an Exception.
Sockets
Sockets are means to establish a communication link between machines over the network. The java.net package provides 4 kinds of Sockets:

Socket is a TCP client API, and will typically be used to connect to a remote host.
ServerSocket is a TCP server API, and will typically accept connections from client sockets.
DatagramSocket is a UDP endpoint API and is used to send and receive datagram packets.
MulticastSocket is a subclass of DatagramSocket used when dealing with multicast groups.

Sending and receiving with TCP sockets is done through InputStreams and OutputStreams which can be obtained via the Socket.getInputStream() and Socket.getOutputStream() methods.
Interfaces
The NetworkInterface class provides APIs to browse and query all the networking interfaces (e.g. ethernet connection or PPP endpoint) of the local machine. It is through that class that you can check if any of the local interfaces is configured to support IPv6.
High level API
A number of classes in the java.net package do provide for a much higher level of abstraction and allow for easy access to resources on the network. The classes are:

URI is the class representing a Universal Resource Identifier, as specified in RFC 2396. As the name indicates, this is just an Identifier and doesn't provide directly the means to access the resource.
URL is the class representing a Universal Resource Locator, which is both an older concept for URIs and a means to access the resources.
URLConnection is created from a URL and is the communication link used to access the resource pointed by the URL. This abstract class will delegate most of the work to the underlying protocol handlers like http or ftp.
HttpURLConnection is a subclass of URLConnection and provides some additional functionalities specific to the HTTP protocol.

The recommended usage is to use URI to identify resources, then convert it into a URL when it is time to access the resource. From that URL, you can either get the URLConnection for fine control, or get directly the InputStream.
Here is an example:

URI uri = new URI(""http://java.sun.com/"");
URL url = uri.toURL();
InputStream in = url.openStream();

Protocol Handlers
As mentioned, URL and URLConnection rely on protocol handlers which must be present, otherwise an Exception is thrown. This is the major difference with URIs which only identify resources, and therefore don't need to have access to the protocol handler. So, while it is possible to create an URI with any kind of protocol scheme (e.g. myproto://myhost.mydomain/resource/), a similar URL will try to instantiate the handler for the specified protocol; if it doesn't exist an exception will be thrown.
By default the protocol handlers are loaded dynamically from the default location. It is, however, possible to add to the search path by setting the java.protocol.handler.pkgs system property. For instance if it is set to myapp.protocols, then the URL code will try, in the case of http, first to load myapp.protocols.http.Handler, then, if this fails, http.Handler from the default location.
Note that the Handler class has to be a subclass of the abstract class URLStreamHandler.
Additional Specification

Networking System Properties",Package
10026,java.nio,"Defines buffers, which are containers for data, and provides an overview of the
other NIO packages.


 The central abstractions of the NIO APIs are: 

 Buffers, which are containers for data;
  
 Charsets and their
  associated decoders and encoders,  which translate between
  bytes and Unicode characters; 
 Channels of
  various types, which represent connections  to entities capable of
  performing I/O operations; and 
 Selectors and selection keys, which together with 
selectable channels define a multiplexed, non-blocking 
  I/O facility.  

 The java.nio package defines the buffer classes, which are used
throughout the NIO APIs.  The charset API is defined in the java.nio.charset package, and the channel and selector APIs are defined in the
java.nio.channels package.  Each of these subpackages has its own
service-provider (SPI) subpackage, the contents of which can be used to extend
the platform's default implementations or to construct alternative
implementations.




BuffersDescription
Buffer
Position, limit, and capacity;
          clear, flip, rewind, and mark/reset
  ByteBuffer
Get/put, compact, views; allocate, wrap
    MappedByteBuffer  
A byte buffer mapped to a file
  CharBuffer
Get/put, compact; allocate, wrap
  DoubleBuffer
    ' '
  FloatBuffer
    ' '
  IntBuffer
    ' '
  LongBuffer
    ' '
  ShortBuffer
    ' '
ByteOrder
Typesafe enumeration for byte orders

 A buffer is a container for a fixed amount of data of a specific
primitive type.  In addition to its content a buffer has a position,
which is the index of the next element to be read or written, and a
limit, which is the index of the first element that should not be read
or written.  The base Buffer class defines these properties as
well as methods for clearing, flipping, and rewinding, for
marking the current position, and for resetting the position to
the previous mark.

 There is a buffer class for each non-boolean primitive type.  Each class
defines a family of get and put methods for moving data out of
and in to a buffer, methods for compacting, duplicating, and
slicing a buffer, and static methods for allocating a new buffer
as well as for wrapping an existing array into a buffer.

 Byte buffers are distinguished in that they can be used as the sources and
targets of I/O operations.  They also support several features not found in the
other buffer classes:


 A byte buffer can be allocated as a 
direct buffer, in which case the Java virtual machine will make a
  best effort to perform native I/O operations directly upon it.  
 A byte buffer can be created by mapping a region of a
  file directly into memory, in which case a few additional file-related
  operations defined in the MappedByteBuffer class are
  available.  
 A byte buffer provides access to its content as either a heterogeneous
  or homogeneous sequence of binary data
  of any non-boolean primitive type, in either big-endian or little-endian byte order.  

 Unless otherwise noted, passing a null argument to a constructor
or method in any class or interface in this package will cause a NullPointerException to be thrown.",Package
10027,java.nio.channels,"Defines channels, which represent connections to entities that are capable of
 performing I/O operations, such as files and sockets; defines selectors, for
 multiplexed, non-blocking I/O operations.

 

ChannelsDescription
Channel
A nexus for I/O operations
  ReadableByteChannel
Can read into a buffer
    ScatteringByteChannel  
Can read into a sequence of buffers
  WritableByteChannel
Can write from a buffer
    GatheringByteChannel
Can write from a sequence of buffers
  ByteChannel
Can read/write to/from a buffer
    SeekableByteChannel
A ByteChannel connected to an entity that contains a variable-length sequence of bytes
  AsynchronousChannel
Supports asynchronous I/O operations.
    AsynchronousByteChannel
Can read and write bytes asynchronously
  NetworkChannel
A channel to a network socket
    MulticastChannel
Can join Internet Protocol (IP) multicast groups
Channels
Utility methods for channel/stream interoperation

 A channel represents an open connection to an entity such as a
 hardware device, a file, a network socket, or a program component that is
 capable of performing one or more distinct I/O operations, for example reading
 or writing.  As specified in the Channel interface,
 channels are either open or closed, and they are both asynchronously
 closeable and interruptible.

  The Channel interface is extended by several
 other interfaces.

  The ReadableByteChannel interface specifies a
 read method that reads bytes
 from the channel into a buffer; similarly, the WritableByteChannel interface specifies a write method that writes bytes
 from a buffer to the channel. The ByteChannel
 interface unifies these two interfaces for the common case of channels that can
 both read and write bytes. The SeekableByteChannel
 interface extends the ByteChannel interface with methods to query and modify the channel's
 current position, and its size.

  The ScatteringByteChannel and GatheringByteChannel interfaces extend the ReadableByteChannel and WritableByteChannel interfaces, respectively, adding read and write methods that take a
 sequence of buffers rather than a single buffer.

  The NetworkChannel interface specifies methods
 to bind the channel's socket,
 obtain the address to which the socket is bound, and methods to get and set socket options. The MulticastChannel interface specifies methods to join
 Internet Protocol (IP) multicast groups.

  The Channels utility class defines static methods
 that support the interoperation of the stream classes of the java.io package with the channel classes of this package.  An appropriate
 channel can be constructed from an InputStream or an OutputStream, and conversely an InputStream or an
 OutputStream can be constructed from a channel.  A Reader can be constructed that uses a given charset to decode bytes
 from a given readable byte channel, and conversely a Writer can
 be constructed that uses a given charset to encode characters into bytes and
 write them to a given writable byte channel.

 
File channelsDescription
FileChannel
Reads, writes, maps, and manipulates files
FileLock
A lock on a (region of a) file
MappedByteBuffer  
A direct byte buffer mapped to a region of a file

 The FileChannel class supports the usual
 operations of reading bytes from, and writing bytes to, a channel connected to
 a file, as well as those of querying and modifying the current file position
 and truncating the file to a specific size.  It defines methods for acquiring
 locks on the whole file or on a specific region of a file; these methods return
 instances of the FileLock class.  Finally, it defines
 methods for forcing updates to the file to be written to the storage device that
 contains it, for efficiently transferring bytes between the file and other
 channels, and for mapping a region of the file directly into memory.

  A FileChannel is created by invoking one of its static open methods, or by invoking the getChannel method of a FileInputStream, FileOutputStream, or RandomAccessFile to return a
 file channel connected to the same underlying file as the java.io
 class.

 

Multiplexed, non-blocking I/ODescription
SelectableChannel
A channel that can be multiplexed
  DatagramChannel
A channel to a datagram-oriented socket
  Pipe.SinkChannel
The write end of a pipe
  Pipe.SourceChannel
The read end of a pipe
  ServerSocketChannel  
A channel to a stream-oriented listening socket
  SocketChannel
A channel for a stream-oriented connecting socket
Selector
A multiplexor of selectable channels
SelectionKey
A token representing the registration  of a channel
     with a selector
Pipe
Two channels that form a unidirectional pipe

 Multiplexed, non-blocking I/O, which is much more scalable than
 thread-oriented, blocking I/O, is provided by selectors, selectable
 channels, and selection keys.

  A selector is a multiplexor of selectable channels, which in turn are
 a special type of channel that can be put into non-blocking mode.  To perform
 multiplexed I/O operations, one or more selectable channels are first created,
 put into non-blocking mode, and registered
 with a selector.  Registering a channel specifies the set of I/O operations
 that will be tested for readiness by the selector, and returns a selection key that represents the
 registration.

  Once some channels have been registered with a selector, a selection operation can be performed in
 order to discover which channels, if any, have become ready to perform one or
 more of the operations in which interest was previously declared.  If a channel
 is ready then the key returned when it was registered will be added to the
 selector's selected-key set.  The key set, and the keys within it, can
 be examined in order to determine the operations for which each channel is
 ready.  From each key one can retrieve the corresponding channel in order to
 perform whatever I/O operations are required.

  That a selection key indicates that its channel is ready for some operation
 is a hint, but not a guarantee, that such an operation can be performed by a
 thread without causing the thread to block.  It is imperative that code that
 performs multiplexed I/O be written so as to ignore these hints when they prove
 to be incorrect.

  This package defines selectable-channel classes corresponding to the DatagramSocket, ServerSocket, and Socket classes defined in the java.net package.
 Minor changes to these classes have been made in order to support sockets that
 are associated with channels.  This package also defines a simple class that
 implements unidirectional pipes.  In all cases, a new selectable channel is
 created by invoking the static open method of the corresponding class.
 If a channel needs an associated socket then a socket will be created as a side
 effect of this operation.

  The implementation of selectors, selectable channels, and selection keys
 can be replaced by ""plugging in"" an alternative definition or instance of the
 SelectorProvider class defined in the java.nio.channels.spi package.  It is not expected that many developers
 will actually make use of this facility; it is provided primarily so that
 sophisticated users can take advantage of operating-system-specific
 I/O-multiplexing mechanisms when very high performance is required.

  Much of the bookkeeping and synchronization required to implement the
 multiplexed-I/O abstractions is performed by the AbstractInterruptibleChannel, AbstractSelectableChannel, AbstractSelectionKey, and AbstractSelector classes in the java.nio.channels.spi package.  When defining a custom selector provider,
 only the AbstractSelector and AbstractSelectionKey classes should be subclassed
 directly; custom channel classes should extend the appropriate SelectableChannel subclasses defined in this package.

 

Asynchronous I/ODescription
AsynchronousFileChannel
An asynchronous channel for reading, writing, and manipulating a file
AsynchronousSocketChannel
An asynchronous channel to a stream-oriented connecting socket
AsynchronousServerSocketChannel  
An asynchronous channel to a stream-oriented listening socket
CompletionHandler
A handler for consuming the result of an asynchronous operation
AsynchronousChannelGroup
A grouping of asynchronous channels for the purpose of resource sharing

 Asynchronous channels are a
 special type of channel capable of asynchronous I/O operations. Asynchronous
 channels are non-blocking and define methods to initiate asynchronous
 operations, returning a Future representing the
 pending result of each operation. The Future can be used to poll or
 wait for the result of the operation. Asynchronous I/O operations can also
 specify a CompletionHandler to invoke when the
 operation completes. A completion handler is user provided code that is executed
 to consume the result of I/O operation.

  This package defines asynchronous-channel classes that are connected to
 a stream-oriented connecting or listening socket, or a datagram-oriented socket.
 It also defines the AsynchronousFileChannel class
 for asynchronous reading, writing, and manipulating a file. As with the FileChannel it supports operations to truncate the file
 to a specific size, force updates to the file to be written to the storage
 device, or acquire locks on the whole file or on a specific region of the file.
 Unlike the FileChannel it does not define methods for mapping a
 region of the file directly into memory. Where memory mapped I/O is required,
 then a FileChannel can be used.

  Asynchronous channels are bound to an asynchronous channel group for the
 purpose of resource sharing. A group has an associated ExecutorService to which tasks are submitted to handle
 I/O events and dispatch to completion handlers that consume the result of
 asynchronous operations performed on channels in the group. The group can
 optionally be specified when creating the channel or the channel can be bound
 to a default group. Sophisticated users may wish to create their
 own asynchronous channel groups or configure the ExecutorService
 that will be used for the default group.

  As with selectors, the implementatin of asynchronous channels can be
 replaced by ""plugging in"" an alternative definition or instance of the AsynchronousChannelProvider class defined in the
 java.nio.channels.spi package.  It is not expected that many
 developers will actually make use of this facility; it is provided primarily
 so that sophisticated users can take advantage of operating-system-specific
 asynchronous I/O mechanisms when very high performance is required.

 
 Unless otherwise noted, passing a null argument to a constructor
 or method in any class or interface in this package will cause a NullPointerException to be thrown.",Package
10028,java.nio.channels.spi,"Service-provider classes for the java.nio.channels package.

 Only developers who are defining new selector providers or asynchronous
channel providers should need to make direct use of this package.  
 Unless otherwise noted, passing a null argument to a constructor
or method in any class or interface in this package will cause a NullPointerException to be thrown.",Package
10029,java.nio.charset,"Defines charsets, decoders, and encoders, for translating between bytes and
Unicode characters.


Class nameDescription
Charset
A named mapping between charactersand bytes
CharsetDecoder
Decodes bytes into characters
CharsetEncoder  
Encodes characters into bytes
CoderResult  
Describes coder results
CodingErrorAction  
Describes actions to take whencoding errors are detected

 A charset is named mapping between sequences of sixteen-bit Unicode
characters and sequences of bytes, in the sense defined in RFC 2278.  A
decoder is an engine which transforms bytes in a specific charset into
characters, and an encoder is an engine which transforms characters into
bytes.  Encoders and decoders operate on byte and character buffers.  They are
collectively referred to as coders.

 The Charset class defines methods for creating
coders for a given charset and for retrieving the various names associated with
a charset.  It also defines static methods for testing whether a particular
charset is supported, for locating charset instances by name, and for
constructing a map that contains every charset for which support is available
in the current Java virtual machine.

 Most users will not use these classes directly; instead they will use the
existing charset-related constructors and methods in the String class, together with the existing InputStreamReader and OutputStreamWriter classes, all
of whose implementations have been reworked to make use of the charset
facilities defined in this package.  A small number of changes have been made
to the InputStreamReader and OutputStreamWriter
classes in order to allow explicit charset objects to be specified in the
construction of instances of those classes.

 Support for new charsets can be made available via the interface defined in
the CharsetProvider class in the java.nio.charset.spi package.

 Unless otherwise noted, passing a null argument to a constructor
or method in any class or interface in this package will cause a NullPointerException to be thrown.",Package
10030,java.nio.charset.spi,"Service-provider classes for the java.nio.charset package.

 Only developers who are defining new charsets should need to make direct
use of this package.  
 Unless otherwise noted, passing a null argument to a constructor
or method in any class or interface in this package will cause a NullPointerException to be thrown.",Package
10031,java.nio.file,"Defines interfaces and classes for the Java virtual machine to access files,
 file attributes, and file systems.

  The java.nio.file package defines classes to access files and file
 systems. The API to access file and file system attributes is defined in the
 java.nio.file.attribute package. The java.nio.file.spi
 package is used by service provider implementors wishing to extend the
 platform default provider, or to construct other provider implementations. 
Symbolic Links
 Many operating systems and file systems support for symbolic links.
 A symbolic link is a special file that serves as a reference to another file.
 For the most part, symbolic links are transparent to applications and
 operations on symbolic links are automatically redirected to the target
 of the link. Exceptions to this are when a symbolic link is deleted or
 renamed/moved in which case the link is deleted or removed rather than the
 target of the link. This package includes support for symbolic links where
 implementations provide these semantics. File systems may support other types
 that are semantically close but support for these other types of links is
 not included in this package. 

 Interoperability
 The File class defines the toPath method to construct a Path by converting
 the abstract path represented by the java.io.File object. The resulting
 Path can be used to operate on the same file as the File
 object. The Path specification provides further information
 on the interoperability between Path
 and java.io.File objects. 

 Visibility
 The view of the files and file system provided by classes in this package are
 guaranteed to be consistent with other views provided by other instances in the
 same Java virtual machine.  The view may or may not, however, be consistent with
 the view of the file system as seen by other concurrently running programs due
 to caching performed by the underlying operating system and delays induced by
 network-filesystem protocols. This is true regardless of the language in which
 these other programs are written, and whether they are running on the same machine
 or on some other machine.  The exact nature of any such inconsistencies are
 system-dependent and are therefore unspecified. 

 Synchronized I/O File Integrity
 The SYNC and DSYNC options are used when opening a file
 to require that updates to the file are written synchronously to the underlying
 storage device. In the case of the default provider, and the file resides on
 a local storage device, and the seekable channel is connected to a file that was opened with one of these
 options, then an invocation of the write
 method is only guaranteed to return when all changes made to the file
 by that invocation have been written to the device. These options are useful
 for ensuring that critical information is not lost in the event of a system
 crash. If the file does not reside on a local device then no such guarantee
 is made. Whether this guarantee is possible with other provider implementations is provider
 specific. 

 General Exceptions
 Unless otherwise noted, passing a null argument to a constructor
 or method of any class or interface in this package will cause a NullPointerException to be thrown. Additionally,
 invoking a method with a collection containing a null element will
 cause a NullPointerException, unless otherwise specified. 

  Unless otherwise noted, methods that attempt to access the file system
 will throw ClosedFileSystemException when invoked on
 objects associated with a FileSystem that has been
 closed. Additionally, any methods
 that attempt write access to a file system will throw ReadOnlyFileSystemException when invoked on an object associated
 with a FileSystem that only provides read-only
 access. 
 Unless otherwise noted, invoking a method of any class or interface in
 this package created by one provider with a parameter that is an object created by another provider,
 will throw ProviderMismatchException. 
Optional Specific Exceptions
 Most of the methods defined by classes in this package that access the
 file system specify that IOException be thrown when an I/O
 error occurs. In some cases, these methods define specific I/O exceptions
 for common cases. These exceptions, noted as optional specific exceptions,
 are thrown by the implementation where it can detect the specific error.
 Where the specific error cannot be detected then the more general IOException is thrown.",Package
10032,java.nio.file.attribute,"Interfaces and classes providing access to file and file system attributes.

 
Attribute viewsDescription
AttributeView
Can read or update non-opaque values associated with objects in a file system
  FileAttributeView
Can read or update file attributes
    BasicFileAttributeView  
Can read or update a basic set of file attributes
      PosixFileAttributeView  
Can read or update POSIX defined file attributes
      DosFileAttributeView  
Can read or update FAT file attributes
   &nbspFileOwnerAttributeView  
Can read or update the owner of a file
     AclFileAttributeView  
Can read or update Access Control Lists
    UserDefinedFileAttributeView  
Can read or update user-defined file attributes
  FileStoreAttributeView
Can read or update file system attributes

 An attribute view provides a read-only or updatable view of the non-opaque
 values, or metadata, associated with objects in a file system.
 The FileAttributeView interface is
 extended by several other interfaces that that views to specific sets of file
 attributes. FileAttributeViews are selected by invoking the Files.getFileAttributeView(java.nio.file.Path, java.lang.Class<V>, java.nio.file.LinkOption...) method with a
 type-token to identify the required view. Views can also be identified
 by name. The FileStoreAttributeView interface
 provides access to file store attributes. A FileStoreAttributeView of
 a given type is obtained by invoking the FileStore.getFileStoreAttributeView(java.lang.Class<V>) method.

  The BasicFileAttributeView
 class defines methods to read and update a basic set of file
 attributes that are common to many file systems.

  The PosixFileAttributeView
 interface extends BasicFileAttributeView by defining methods
 to access the file attributes commonly used by file systems and operating systems
 that implement the Portable Operating System Interface (POSIX) family of
 standards.

  The DosFileAttributeView
 class extends BasicFileAttributeView by defining methods to
 access the legacy ""DOS"" file attributes supported on file systems such as File
 Allocation Tabl (FAT), commonly used in consumer devices.

  The AclFileAttributeView
 class defines methods to read and write the Access Control List (ACL)
 file attribute. The ACL model used by this file attribute view is based
 on the model defined by 
RFC 3530: Network File System (NFS) version 4 Protocol.

  In addition to attribute views, this package also defines classes and
 interfaces that are used when accessing attributes:

 
 The UserPrincipal and
   GroupPrincipal interfaces represent an
   identity or group identity. 
 The UserPrincipalLookupService
   interface defines methods to lookup user or group principals. 
 The FileAttribute interface
   represents the value of an attribute for cases where the attribute value is
   required to be set atomically when creating an object in the file system. 

 Unless otherwise noted, passing a null argument to a constructor
 or method in any class or interface in this package will cause a NullPointerException to be thrown.",Package
10033,java.nio.file.spi,"Service-provider classes for the java.nio.file package.

  Only developers who are defining new file system providers or file type
 detectors should need to make direct use of this package.  
 Unless otherwise noted, passing a null argument to a constructor
 or method in any class or interface in this package will cause a NullPointerException to be thrown.",Package
10034,java.rmi,"Provides the RMI package. RMI is Remote Method Invocation.  It is a
mechanism that enables an object on one Java virtual machine to invoke
methods on an object in another Java virtual machine.  Any object that
can be invoked this way must implement the Remote interface. When such
an object is invoked, its arguments are ``marshalled'' and sent from the
local virtual machine to the remote one, where the arguments are
``unmarshalled.''  When the method terminates, the results are
marshalled from the remote machine and sent to the caller's virtual
machine.  If the method invocation results in an exception being
thrown, the exception is indicated to caller.",Package
10035,java.rmi.activation,"Provides support for RMI Object Activation.  A remote
object's reference can be made ``persistent'' and later activated into a
``live'' object using the RMI activation mechanism.",Package
10036,java.rmi.dgc,"Provides classes and interface for RMI distributed
garbage-collection (DGC).  When the RMI server returns an object to
its client (caller of the remote method), it tracks the remote
object's usage in the client. When there are no more references to the
remote object on the client, or if the reference's ``lease'' expires and
not renewed, the server garbage-collects the remote object.",Package
10037,java.rmi.registry,"Provides a class and two interfaces for the RMI registry.
A registry is a remote object that maps names to remote objects.  A
server registers its remote objects with the registry so that they can
be looked up.  When an object wants to invoke a method on a remote
object, it must first lookup the remote object using its name.  The
registry returns to the calling object a reference to the remote
object, using which a remote method can be invoked.",Package
10038,java.rmi.server,"Provides classes and interfaces for supporting the server
side of RMI.  A group of classes are used by the stubs and skeletons
generated by the rmic stub compiler.  Another group of classes
implements the RMI Transport protocol and HTTP tunneling.",Package
10039,java.security,"Provides the classes and interfaces for the security framework.
This includes classes that implement an easily configurable,
fine-grained access control security architecture.
This package also supports
the generation and storage of cryptographic public key pairs,
as well as a number of exportable cryptographic operations
including those for message digest and signature generation.  Finally,
this package provides classes that support signed/guarded objects
and secure random number generation.

Many of the classes provided in this package (the cryptographic
and secure random number generator classes in particular) are
provider-based.  The class itself defines a programming interface
to which applications may write.  The implementations themselves may
then be written by independent third-party vendors and plugged
in seamlessly as needed.  Therefore application developers may
take advantage of any number of provider-based implementations
without having to add or rewrite code.

Package Specification


JavaTM
    Cryptography Architecture (JCA) Reference Guide
PKCS #8: Private-Key Information Syntax Standard, Version 1.2,
    November 1993

JavaTM
    Cryptography Architecture Standard Algorithm Name 
    Documentation

Related Documentation

For further documentation, please see:


JavaTM
    SE Platform Security Architecture

How to Implement a Provider in the
    JavaTM Cryptography Architecture
    

    Default Policy Implementation and Policy File Syntax
    

    Permissions in the
    JavaTM SE Development Kit (JDK)
    

    Summary of Tools for
    JavaTM Platform Security
    
keytool
    (
      for Solaris/Linux)
    (
      for Windows)
    
jarsigner
    (
      for Solaris/Linux)
    (
      for Windows)",Package
10040,java.security.acl,"The classes and interfaces in this package have been
superseded by classes in the java.security package.
See that package and, for example, java.security.Permission for details.",Package
10041,java.security.cert,"Provides classes and interfaces for parsing and managing
certificates, certificate revocation lists (CRLs), and 
certification paths. It contains support for X.509 v3 
certificates and X.509 v2 CRLs.

Package Specification


JavaTM
    Cryptography Architecture (JCA) Reference Guide
RFC 3280: Internet X.509 Public Key Infrastructure Certificate and 
    Certificate Revocation List (CRL) Profile
  
JavaTM
    Cryptography Architecture Standard Algorithm Name
    Documentation

Related Documentation

For information about X.509 certificates and CRLs, please see:


    http://www.ietf.org/rfc/rfc3280.txt

JavaTM
    PKI Programmer's Guide

    X.509 Certificates and Certificate Revocation Lists (CRLs)",Package
10042,java.security.interfaces,"Provides interfaces for generating RSA (Rivest, Shamir and
Adleman AsymmetricCipher algorithm)
keys as defined in the RSA Laboratory Technical Note
PKCS#1, and DSA (Digital Signature
Algorithm) keys as defined in NIST's FIPS-186.

Note that these interfaces are intended only for key
implementations whose key material is accessible and 
available. These interfaces are not intended for key 
implementations whose key material resides in 
inaccessible, protected storage (such as in a 
hardware device). 

For more developer information on how to use these 
interfaces, including information on how to design 
Key classes for hardware devices, please refer
to these cryptographic provider developer guides:


How to Implement a Provider for the
    JavaTM Cryptography Architecture
    

Package Specification

PKCS #1: RSA Encryption Standard, Version 1.5, November 1993 
Federal Information Processing Standards Publication (FIPS PUB) 186:
    Digital Signature Standard (DSS) 

Related Documentation

For further documentation, please see:



JavaTM
      Cryptography Architecture API Specification and Reference",Package
10043,java.security.spec,"Provides classes and interfaces for key specifications and algorithm
parameter specifications.

A key specification is a transparent representation of the key material
that constitutes a key. A key may be specified in an algorithm-specific
way, or in an algorithm-independent encoding format (such as ASN.1).
This package contains key specifications for DSA public and private keys,
RSA public and private keys, PKCS #8 private keys in DER-encoded format,
and X.509 public and private keys in DER-encoded format.

An algorithm parameter specification is a transparent representation
of the sets of parameters used with an algorithm. This package contains
an algorithm parameter specification for parameters used with the
DSA algorithm.

Package Specification

PKCS #1: RSA Encryption Standard, Version 1.5, November 1993
PKCS #8: Private-Key Information Syntax Standard, 
    Version 1.2, November 1993
Federal Information Processing Standards Publication (FIPS PUB) 186:
    Digital Signature Standard (DSS)

Related Documentation

For documentation that includes information about algorithm parameter
and key specifications, please see:



JavaTM
      Cryptography Architecture API Specification and Reference
      


How to Implement a Provider for the
      JavaTM Cryptography Architecture",Package
10044,java.sql,"Provides the API for accessing and processing data stored in a 
data source (usually a relational database) using the 
JavaTM programming language. 
This API includes a framework whereby different
drivers can be installed dynamically to access different data sources.
Although the JDBCTM API is mainly geared 
to passing SQL statements to a database, it provides for reading and
writing data from any data source with a tabular format.
The reader/writer facility, available through the 
javax.sql.RowSet group of interfaces, can be customized to
use and update data from a spread sheet, flat file, or any other tabular 
data source.

What the JDBCTM 4.1 API Includes
The JDBCTM 4.1 API includes both
the java.sql package, referred to as the JDBC core API,
and the javax.sql package, referred to as the JDBC Optional
Package API. This complete JDBC API
is included in the JavaTM  
Standard Edition (Java SETM), version 7.
The javax.sql package extends the functionality of the JDBC API 
from a client-side API to a server-side API, and it is an essential part
of the JavaTM  Enterprise Edition
(Java EETM) technology. 

Versions
The JDBC 4.1 API incorporates all of the previous JDBC API versions:

 The JDBC 4.0 API
  The JDBC 3.0 API
  The JDBC 2.1 core API
  The JDBC 2.0 Optional Package API
      (Note that the JDBC 2.1 core API and the JDBC 2.0 Optional Package
      API together are referred to as the JDBC 2.0 API.)
  The JDBC 1.2 API
  The JDBC 1.0 API


Classes, interfaces, methods, fields, constructors, and exceptions 
have the following ""since"" tags that indicate when they were introduced 
into the Java platform. When these ""since"" tags are used in
JavadocTM comments for the JDBC API,
they indicate the following:

Since 1.7 -- new in the JDBC 4.1 API and part of the Java SE platform,
     version 7
Since 1.6 -- new in the JDBC 4.0 API and part of the Java SE platform,
     version 6
 Since 1.4 -- new in the JDBC 3.0 API and part of the J2SE platform, 
     version 1.4
 Since 1.2 -- new in the JDBC 2.0 API and part of the J2SE platform, 
     version 1.2
 Since 1.1 or no ""since"" tag -- in the original JDBC 1.0 API and part of
      the JDKTM, version 1.1


NOTE: Many of the new features are optional; consequently, there is 
some variation in drivers and the features they support. Always 
check your driver's documentation to see whether it supports a feature before
you try to use it.

NOTE: The class SQLPermission was added in the
JavaTM 2 SDK, Standard Edition, 
version 1.3 release. This class is used to prevent unauthorized
access to the logging stream associated with the DriverManager,
which may contain information such as table names, column data, and so on.

What the java.sql Package Contains
The java.sql package contains API for the following:

Making a connection with a database via the DriverManager facility
  
DriverManager class -- makes a connection with a driver
         SQLPermission class -- provides permission when code
                  running within a Security Manager, such as an applet,
                  attempts to set up a logging stream through the
                  DriverManager
Driver interface -- provides the API for registering
             and connecting drivers based on JDBC technology (""JDBC drivers""); 
             generally used only by the DriverManager class
         DriverPropertyInfo class -- provides properties for a
             JDBC driver; not used by the general user
  
Sending SQL statements to a database
  
Statement --  used to send basic SQL statements
         PreparedStatement --  used to send prepared statements or 
              basic SQL statements (derived from Statement)
         CallableStatement --  used to call database stored 
              procedures (derived from PreparedStatement)
         Connection interface --  provides methods for creating
             statements and managing connections and their properties
         Savepoint --  provides savepoints in a transaction

  
Retrieving and updating the results of a query
  
ResultSet interface
  
Standard mappings for SQL types to classes and interfaces in the 
      Java programming language
  
Array interface -- mapping for SQL ARRAY
Blob interface -- mapping for SQL BLOB
Clob interface -- mapping for SQL CLOB
Date class -- mapping for SQL DATE
NClob interface -- mapping for SQL NCLOB
Ref interface -- mapping for SQL REF
RowId interface -- mapping for SQL ROWID
Struct interface -- mapping for SQL STRUCT
SQLXML interface -- mapping for SQL XML
Time class -- mapping for SQL TIME
Timestamp class -- mapping for SQL TIMESTAMP
Types class -- provides constants for SQL types
  
Custom mapping an SQL user-defined type (UDT) to a class in the
          Java programming language
  
SQLData interface -- specifies the mapping of
              a UDT to an instance of this class
         SQLInput interface -- provides methods for reading
              UDT attributes from a stream
         SQLOutput interface -- provides methods for writing
              UDT attributes back to a stream
  
Metadata
  
DatabaseMetaData interface -- provides information
              about the database
         ResultSetMetaData interface -- provides information
              about the columns of a ResultSet object
         ParameterMetaData interface -- provides information
              about the parameters to PreparedStatement commands
  
Exceptions
        
SQLException -- thrown by most methods when there
                 is a problem accessing data and by some methods for other reasons
          SQLWarning -- thrown to indicate a warning
          DataTruncation -- thrown to indicate that data may have
          been truncated
          BatchUpdateException -- thrown to indicate that not all
                 commands in a batch update executed successfully
        


java.sql and javax.sql Features Introduced in the JDBC 4.1 API

Allow Connection,
        ResultSet and Statement objects to be
        used with the try-with-resources statement
Supported added to CallableStatement and
        ResultSet to specify the Java type to convert to via the
        getObject method
DatabaseMetaData methods to return PseudoColumns and if a
        generated key is always returned
Added support to Connection to specify a database schema,
    abort and timeout a physical connection.
Added support to close a Statement object when its dependent
    objects have been closed
Support for obtaining the parent logger for a Driver,
     DataSource, ConnectionPoolDataSource and
     XADataSource

java.sql and javax.sql Features Introduced in the JDBC 4.0 API

auto java.sql.Driver discovery -- no longer need to load a 
java.sql.Driver class via Class.forName
National Character Set support added
 Support added for the SQL:2003 XML data type
 SQLException enhancements -- Added support for cause chaining; New SQLExceptions
 added for common SQLState class value codes
 Enhanced Blob/Clob functionality -- Support provided to create and free a Blob/Clob instance
 as well as additional methods added to improve accessiblity
 Support added for accessing a SQL ROWID
 Support added to allow a JDBC application to access an instance of a JDBC resource
 that has been wrapped by a vendor, usually in an application server or connection 
 pooling environment.
 Availability to be notified when a PreparedStatement that is associated
 with a PooledConnection has been closed or the driver determines is invalid
 
 



java.sql and javax.sql Features Introduced in the JDBC 3.0 API

Pooled statements -- reuse of statements associated with a pooled 
       connection
  Savepoints -- allow a transaction to be rolled back to a designated
      savepoint
  Properties defined for ConnectionPoolDataSource -- specify
      how connections are to be pooled
  Metadata for parameters of a PreparedStatement object
  Ability to retrieve values from automatically generated columns
  Ability to have multiple ResultSet objects 
       returned from CallableStatement objects open at the
      same time
  Ability to identify parameters to CallableStatement
      objects by name as well as by index
  ResultSet holdability -- ability to specify whether cursors
      should be held open or closed at the end of a transaction
  Ability to retrieve and update the SQL structured type instance that a
      Ref object references
  Ability to programmatically update BLOB,
      CLOB, ARRAY, and REF values.
  Addition of the java.sql.Types.DATALINK data type -- 
      allows JDBC drivers access to objects stored outside a data source
  Addition of metadata for retrieving SQL type hierarchies


java.sql Features Introduced in the JDBC 2.1 Core API

Scrollable result sets--using new methods in the ResultSet
          interface that allow the cursor to be moved to a particular row or to a
          position relative to its current position
  Batch updates
  Programmatic updates--using ResultSet updater methods
  New data types--interfaces mapping the SQL3 data types
  Custom mapping of user-defined types (UDTs)
  Miscellaneous features, including performance hints, the use of character
          streams, full precision for java.math.BigDecimal values,
          additional security, and
          support for time zones in date, time, and timestamp values. 


javax.sql Features Introduced in the JDBC 2.0 Optional
Package API

The DataSource interface as a means of making a connection.  The
      Java Naming and Directory InterfaceTM
      (JNDI) is used for registering a DataSource object with a 
      naming service and also for  retrieving it.
  Pooled connections -- allowing connections to be used and reused
  Distributed transactions -- allowing a transaction to span diverse
      DBMS servers
  RowSet technology -- providing a convenient means of
       handling and passing data



Custom Mapping of UDTs
A user-defined type (UDT) defined in SQL can be mapped to a class in the Java
programming language. An SQL structured type or an SQL DISTINCT
type are the UDTs that may be custom mapped.  The following three
steps set up a custom mapping:

Defining the SQL structured type or DISTINCT type in SQL
  Defining the class in the Java programming language to which the
          SQL UDT will be mapped.  This class must implement the
          SQLData interface.
  Making an entry in a Connection object's type map
      that contains two things:
   
the fully-qualified SQL name of the UDT
       the Class object for the class that implements the 
           SQLData interface
   


When these are in place for a UDT, calling the methods
ResultSet.getObject or CallableStatement.getObject 
on that UDT will automatically retrieve the custom mapping for it. Also, the
PreparedStatement.setObject method will automatically map the
object back to its SQL type to store it in the data source.

Package Specification

Specification 
      of the JDBC 4.0 API

Related Documentation

Getting Started--overviews of the major interfaces

Chapters on the JDBC 
     API--from the online version of The Java Tutorial Continued


JDBCTMAPI Tutorial and Reference, 
Third Edition--
a complete reference and tutorial for the JDBC 3.0 API",Package
10045,java.text,"Provides classes and interfaces for handling text, dates, numbers, and messages
in a manner independent of natural languages.  This means your main application
or applet can be written to be language-independent, and it can rely upon
separate, dynamically-linked localized resources. This allows the flexibility
of adding localizations for new localizations at any time.

These classes are capable of formatting dates, numbers, and messages, parsing;
searching and sorting strings; and iterating over characters, words, sentences,
and line breaks.  This package contains three main groups of classes and
interfaces:

Classes for iteration over text
Classes for formatting and parsing
Classes for string collation",Package
10046,java.text.spi,Service provider classes for the classes in the java.text package.,Package
10047,java.util,"Contains the collections framework, legacy collection classes, event model,
date and time facilities, internationalization, and miscellaneous utility
classes (a string tokenizer, a random-number generator, and a bit array).

Package Specification

Collections Framework Overview

       Collections Framework Annotated Outline

Related Documentation
For overviews, tutorials, examples, guides, and tool documentation, please see:


Collections Framework Tutorial
Collections
    Framework Design FAQ",Package
10048,java.util.concurrent,"Utility classes commonly useful in concurrent programming.  This
 package includes a few small standardized extensible frameworks, as
 well as some classes that provide useful functionality and are
 otherwise tedious or difficult to implement.  Here are brief
 descriptions of the main components.  See also the
 java.util.concurrent.locks and
 java.util.concurrent.atomic packages.

 Executors
Interfaces.
Executor is a simple standardized
 interface for defining custom thread-like subsystems, including
 thread pools, asynchronous IO, and lightweight task frameworks.
 Depending on which concrete Executor class is being used, tasks may
 execute in a newly created thread, an existing task-execution thread,
 or the thread calling execute, and may execute sequentially or concurrently.

 ExecutorService provides a more
 complete asynchronous task execution framework.  An
 ExecutorService manages queuing and scheduling of tasks,
 and allows controlled shutdown.

 The ScheduledExecutorService
 subinterface and associated interfaces add support for
 delayed and periodic task execution.  ExecutorServices
 provide methods arranging asynchronous execution of any
 function expressed as Callable,
 the result-bearing analog of Runnable.

 A Future returns the results of
 a function, allows determination of whether execution has
 completed, and provides a means to cancel execution.

 A RunnableFuture is a Future
 that possesses a run method that upon execution,
 sets its results.

 
Implementations.

 Classes ThreadPoolExecutor and
 ScheduledThreadPoolExecutor
 provide tunable, flexible thread pools.

 The Executors class provides
 factory methods for the most common kinds and configurations
 of Executors, as well as a few utility methods for using
 them.  Other utilities based on Executors include the
 concrete class FutureTask
 providing a common extensible implementation of Futures, and
 ExecutorCompletionService, that
 assists in coordinating the processing of groups of
 asynchronous tasks.

 Class ForkJoinPool provides an
 Executor primarily designed for processing instances of ForkJoinTask and its subclasses.  These
 classes employ a work-stealing scheduler that attains high
 throughput for tasks conforming to restrictions that often hold in
 computation-intensive parallel processing.

 Queues

 The ConcurrentLinkedQueue class
 supplies an efficient scalable thread-safe non-blocking FIFO
 queue.

 Five implementations in java.util.concurrent support
 the extended BlockingQueue
 interface, that defines blocking versions of put and take:
 LinkedBlockingQueue,
 ArrayBlockingQueue,
 SynchronousQueue,
 PriorityBlockingQueue, and
 DelayQueue.
 The different classes cover the most common usage contexts
 for producer-consumer, messaging, parallel tasking, and
 related concurrent designs.

  Extended interface TransferQueue,
 and implementation LinkedTransferQueue
 introduce a synchronous transfer method (along with related
 features) in which a producer may optionally block awaiting its
 consumer.

 The BlockingDeque interface
 extends BlockingQueue to support both FIFO and LIFO
 (stack-based) operations.
 Class LinkedBlockingDeque
 provides an implementation.

 Timing

 The TimeUnit class provides
 multiple granularities (including nanoseconds) for
 specifying and controlling time-out based operations.  Most
 classes in the package contain operations based on time-outs
 in addition to indefinite waits.  In all cases that
 time-outs are used, the time-out specifies the minimum time
 that the method should wait before indicating that it
 timed-out.  Implementations make a ""best effort""
 to detect time-outs as soon as possible after they occur.
 However, an indefinite amount of time may elapse between a
 time-out being detected and a thread actually executing
 again after that time-out.  All methods that accept timeout
 parameters treat values less than or equal to zero to mean
 not to wait at all.  To wait ""forever"", you can use a value
 of Long.MAX_VALUE.

 Synchronizers

 Five classes aid common special-purpose synchronization idioms.
 
Semaphore is a classic concurrency tool.

 CountDownLatch is a very simple yet
 very common utility for blocking until a given number of signals,
 events, or conditions hold.

 A CyclicBarrier is a resettable
 multiway synchronization point useful in some styles of parallel
 programming.

 A Phaser provides
 a more flexible form of barrier that may be used to control phased
 computation among multiple threads.

 An Exchanger allows two threads to
 exchange objects at a rendezvous point, and is useful in several
 pipeline designs.

 
Concurrent Collections

 Besides Queues, this package supplies Collection implementations
 designed for use in multithreaded contexts:
 ConcurrentHashMap,
 ConcurrentSkipListMap,
 ConcurrentSkipListSet,
 CopyOnWriteArrayList, and
 CopyOnWriteArraySet.
 When many threads are expected to access a given collection, a
 ConcurrentHashMap is normally preferable to a synchronized
 HashMap, and a ConcurrentSkipListMap is normally
 preferable to a synchronized TreeMap.
 A CopyOnWriteArrayList is preferable to a synchronized
 ArrayList when the expected number of reads and traversals
 greatly outnumber the number of updates to a list.

 The ""Concurrent"" prefix used with some classes in this package
 is a shorthand indicating several differences from similar
 ""synchronized"" classes.  For example java.util.Hashtable and
 Collections.synchronizedMap(new HashMap()) are
 synchronized.  But ConcurrentHashMap is ""concurrent"".  A
 concurrent collection is thread-safe, but not governed by a
 single exclusion lock.  In the particular case of
 ConcurrentHashMap, it safely permits any number of
 concurrent reads as well as a tunable number of concurrent
 writes.  ""Synchronized"" classes can be useful when you need
 to prevent all access to a collection via a single lock, at
 the expense of poorer scalability.  In other cases in which
 multiple threads are expected to access a common collection,
 ""concurrent"" versions are normally preferable.  And
 unsynchronized collections are preferable when either
 collections are unshared, or are accessible only when
 holding other locks.

 Most concurrent Collection implementations (including most
 Queues) also differ from the usual java.util conventions in that
 their Iterators provide weakly consistent rather than
 fast-fail traversal.  A weakly consistent iterator is thread-safe,
 but does not necessarily freeze the collection while iterating, so
 it may (or may not) reflect any updates since the iterator was
 created.

 Memory Consistency Properties

 Chapter 17 of
 The Java™ Language Specification
 defines the
 happens-before relation on memory operations such as reads and
 writes of shared variables.  The results of a write by one thread are
 guaranteed to be visible to a read by another thread only if the write
 operation happens-before the read operation.  The
 synchronized and volatile constructs, as well as the
 Thread.start() and Thread.join() methods, can form
 happens-before relationships.  In particular:

 
Each action in a thread happens-before every action in that
   thread that comes later in the program's order.

   An unlock (synchronized block or method exit) of a
   monitor happens-before every subsequent lock (synchronized
   block or method entry) of that same monitor.  And because
   the happens-before relation is transitive, all actions
   of a thread prior to unlocking happen-before all actions
   subsequent to any thread locking that monitor.

   A write to a volatile field happens-before every
   subsequent read of that same field.  Writes and reads of
   volatile fields have similar memory consistency effects
   as entering and exiting monitors, but do not entail
   mutual exclusion locking.

   A call to start on a thread happens-before any
   action in the started thread.

   All actions in a thread happen-before any other thread
   successfully returns from a join on that thread.

 


 The methods of all classes in java.util.concurrent and its
 subpackages extend these guarantees to higher-level
 synchronization.  In particular:

 
Actions in a thread prior to placing an object into any concurrent
   collection happen-before actions subsequent to the access or
   removal of that element from the collection in another thread.

   Actions in a thread prior to the submission of a Runnable
   to an Executor happen-before its execution begins.
   Similarly for Callables submitted to an ExecutorService.

   Actions taken by the asynchronous computation represented by a
   Future happen-before actions subsequent to the
   retrieval of the result via Future.get() in another thread.

   Actions prior to ""releasing"" synchronizer methods such as
   Lock.unlock, Semaphore.release, and
   CountDownLatch.countDown happen-before actions
   subsequent to a successful ""acquiring"" method such as
   Lock.lock, Semaphore.acquire,
   Condition.await, and CountDownLatch.await on the
   same synchronizer object in another thread.

   For each pair of threads that successfully exchange objects via
   an Exchanger, actions prior to the exchange()
   in each thread happen-before those subsequent to the
   corresponding exchange() in another thread.

   Actions prior to calling CyclicBarrier.await and
   Phaser.awaitAdvance (as well as its variants)
   happen-before actions performed by the barrier action, and
   actions performed by the barrier action happen-before actions
   subsequent to a successful return from the corresponding await
   in other threads.",Package
10049,java.util.concurrent.atomic,"A small toolkit of classes that support lock-free thread-safe
 programming on single variables.  In essence, the classes in this
 package extend the notion of volatile values, fields, and
 array elements to those that also provide an atomic conditional update
 operation of the form:

 
   boolean compareAndSet(expectedValue, updateValue);
 
This method (which varies in argument types across different
 classes) atomically sets a variable to the updateValue if it
 currently holds the expectedValue, reporting true on
 success.  The classes in this package also contain methods to get and
 unconditionally set values, as well as a weaker conditional atomic
 update operation weakCompareAndSet described below.

 The specifications of these methods enable implementations to
 employ efficient machine-level atomic instructions that are available
 on contemporary processors.  However on some platforms, support may
 entail some form of internal locking.  Thus the methods are not
 strictly guaranteed to be non-blocking --
 a thread may block transiently before performing the operation.

 Instances of classes
 AtomicBoolean,
 AtomicInteger,
 AtomicLong, and
 AtomicReference
 each provide access and updates to a single variable of the
 corresponding type.  Each class also provides appropriate utility
 methods for that type.  For example, classes AtomicLong and
 AtomicInteger provide atomic increment methods.  One
 application is to generate sequence numbers, as in:

 
 class Sequencer {
   private final AtomicLong sequenceNumber
     = new AtomicLong(0);
   public long next() {
     return sequenceNumber.getAndIncrement();
   }
 }
 
The memory effects for accesses and updates of atomics generally
 follow the rules for volatiles, as stated in section 17.4 of
 The Java™ Language Specification.

 
 get has the memory effects of reading a
 volatile variable.

    set has the memory effects of writing (assigning) a
 volatile variable.

    lazySet has the memory effects of writing (assigning)
   a volatile variable except that it permits reorderings with
   subsequent (but not previous) memory actions that do not themselves
   impose reordering constraints with ordinary non-volatile
   writes.  Among other usage contexts, lazySet may apply when
   nulling out, for the sake of garbage collection, a reference that is
   never accessed again.

   weakCompareAndSet atomically reads and conditionally
   writes a variable but does not
   create any happens-before orderings, so provides no guarantees
   with respect to previous or subsequent reads and writes of any
   variables other than the target of the weakCompareAndSet.

    compareAndSet
   and all other read-and-update operations such as getAndIncrement
   have the memory effects of both reading and
   writing volatile variables.
 
In addition to classes representing single values, this package
 contains Updater classes that can be used to obtain
 compareAndSet operations on any selected volatile
 field of any selected class.

 AtomicReferenceFieldUpdater,
 AtomicIntegerFieldUpdater, and
 AtomicLongFieldUpdater are
 reflection-based utilities that provide access to the associated
 field types.  These are mainly of use in atomic data structures in
 which several volatile fields of the same node (for
 example, the links of a tree node) are independently subject to
 atomic updates.  These classes enable greater flexibility in how
 and when to use atomic updates, at the expense of more awkward
 reflection-based setup, less convenient usage, and weaker
 guarantees.

 The
 AtomicIntegerArray,
 AtomicLongArray, and
 AtomicReferenceArray classes
 further extend atomic operation support to arrays of these types.
 These classes are also notable in providing volatile access
 semantics for their array elements, which is not supported for
 ordinary arrays.

 
The atomic classes also support method weakCompareAndSet,
 which has limited applicability.  On some platforms, the weak version
 may be more efficient than compareAndSet in the normal case,
 but differs in that any given invocation of the
 weakCompareAndSet method may return false
spuriously (that is, for no apparent reason).  A
 false return means only that the operation may be retried if
 desired, relying on the guarantee that repeated invocation when the
 variable holds expectedValue and no other thread is also
 attempting to set the variable will eventually succeed.  (Such
 spurious failures may for example be due to memory contention effects
 that are unrelated to whether the expected and current values are
 equal.)  Additionally weakCompareAndSet does not provide
 ordering guarantees that are usually needed for synchronization
 control.  However, the method may be useful for updating counters and
 statistics when such updates are unrelated to the other
 happens-before orderings of a program.  When a thread sees an update
 to an atomic variable caused by a weakCompareAndSet, it does
 not necessarily see updates to any other variables that
 occurred before the weakCompareAndSet.  This may be
 acceptable when, for example, updating performance statistics, but
 rarely otherwise.

 The AtomicMarkableReference
 class associates a single boolean with a reference.  For example, this
 bit might be used inside a data structure to mean that the object
 being referenced has logically been deleted.

 The AtomicStampedReference
 class associates an integer value with a reference.  This may be
 used for example, to represent version numbers corresponding to
 series of updates.

 Atomic classes are designed primarily as building blocks for
 implementing non-blocking data structures and related infrastructure
 classes.  The compareAndSet method is not a general
 replacement for locking.  It applies only when critical updates for an
 object are confined to a single variable.

 Atomic classes are not general purpose replacements for
 java.lang.Integer and related classes.  They do not
 define methods such as hashCode and
 compareTo.  (Because atomic variables are expected to be
 mutated, they are poor choices for hash table keys.)  Additionally,
 classes are provided only for those types that are commonly useful in
 intended applications.  For example, there is no atomic class for
 representing byte.  In those infrequent cases where you would
 like to do so, you can use an AtomicInteger to hold
 byte values, and cast appropriately.

 You can also hold floats using
 Float.floatToIntBits(float) and
 Float.intBitsToFloat(int) conversions, and doubles using
 Double.doubleToLongBits(double) and
 Double.longBitsToDouble(long) conversions.",Package
10050,java.util.concurrent.locks,"Interfaces and classes providing a framework for locking and waiting
 for conditions that is distinct from built-in synchronization and
 monitors.  The framework permits much greater flexibility in the use of
 locks and conditions, at the expense of more awkward syntax.

 The Lock interface supports
 locking disciplines that differ in semantics (reentrant, fair, etc),
 and that can be used in non-block-structured contexts including
 hand-over-hand and lock reordering algorithms.  The main implementation
 is ReentrantLock.

 The ReadWriteLock interface
 similarly defines locks that may be shared among readers but are
 exclusive to writers.  Only a single implementation, ReentrantReadWriteLock, is provided, since
 it covers most standard usage contexts.  But programmers may create
 their own implementations to cover nonstandard requirements.

 The Condition interface
 describes condition variables that may be associated with Locks.
 These are similar in usage to the implicit monitors accessed using
 Object.wait, but offer extended capabilities.
 In particular, multiple Condition objects may be associated
 with a single Lock.  To avoid compatibility issues, the
 names of Condition methods are different from the
 corresponding Object versions.

 The AbstractQueuedSynchronizer
 class serves as a useful superclass for defining locks and other
 synchronizers that rely on queuing blocked threads.  The AbstractQueuedLongSynchronizer class
 provides the same functionality but extends support to 64 bits of
 synchronization state.  Both extend class AbstractOwnableSynchronizer, a simple
 class that helps record the thread currently holding exclusive
 synchronization.  The LockSupport
 class provides lower-level blocking and unblocking support that is
 useful for those developers implementing their own customized lock
 classes.",Package
10051,java.util.jar,"Provides classes for reading and writing the JAR (Java ARchive) file
format, which is based on the standard ZIP file format with an
optional manifest file.  The manifest stores meta-information about the
JAR file contents and is also used for signing JAR files.


Package Specification

The java.util.jar package is based on the following specifications:

Info-ZIP file format - The JAR format is based on the Info-ZIP 
      file format. See 
      java.util.zip
      package description. 
      In JAR files, all file names must be encoded in the UTF-8 encoding. 


      Manifest and Signature Specification - The manifest format specification.",Package
10052,java.util.logging,"Provides the classes and interfaces of 
the JavaTM 2
 platform's core logging facilities.
The central goal of the logging APIs is to support maintaining and servicing
software at customer sites. 


There are four main target uses of the logs:


 Problem diagnosis by end users and system administrators. 
          This consists of simple logging of common problems that can be fixed 
          or tracked locally, such as running out of resources, security failures,
          and simple configuration errors.
        
    Problem diagnosis by field service engineers. The logging information
           used by field service engineers may be considerably more complex and
           verbose than that required by system administrators.  Typically such information
           will require extra logging within particular subsystems.

    Problem diagnosis by the development organization.
         When a problem occurs in the field, it may be necessary to return the captured logging
         information to the original development team for diagnosis. This logging
         information may be extremely detailed and fairly inscrutable. Such information might include
         detailed tracing on the internal execution of particular subsystems.           

    Problem diagnosis by developers. The Logging APIs may also be
           used to help debug an application under development. This may 
           include logging information generated by the target application
           as well as logging information generated by lower-level libraries.          
           Note however that while this use is perfectly reasonable,
           the logging APIs are not intended to replace the normal debugging 
           and profiling tools that may already exist in the development environment. 



The key elements of this package include:

 Logger: The main entity on which applications make 
                logging calls. A Logger object is used to log messages 
                for a specific system or application
                component.
    LogRecord: Used to pass logging requests between the logging
                   framework and individual log handlers.
    Handler: Exports LogRecord objects to a variety of destinations
                 including memory, output streams, consoles, files, and sockets.
                 A variety of Handler subclasses exist for this purpose. Additional Handlers
                 may be developed by third parties and delivered on top of the core platform.
    Level: Defines a set of standard logging levels that can be used
                      to control logging output. Programs can be configured to output logging
                      for some levels while ignoring output for others.
    Filter: Provides fine-grained control over what gets logged,
                       beyond the control provided by log levels. The logging APIs support a general-purpose
                       filter mechanism that allows application code to attach arbitrary filters to 
                       control logging output. 
                       
    Formatter: Provides support for formatting LogRecord objects. This 
                          package includes two formatters, SimpleFormatter and 
                          XMLFormatter, for formatting log records in plain text
                          or XML respectively. As with Handlers, additional Formatters 
                          may be developed by third parties.


The Logging APIs offer both static and dynamic configuration control.
Static control enables field service staff to set up a particular configuration and then re-launch the 
application with the new logging settings. Dynamic control allows for updates to the 
logging configuration within a currently running program. The APIs also allow for logging to be 
enabled or disabled for different functional areas of the system. For example, 
a field service engineer might be interested in tracing all AWT events, but might have no interest in 
socket events or memory management.

Null Pointers

In general, unless otherwise noted in the javadoc, methods and
constructors will throw NullPointerException if passed a null argument.
The one broad exception to this rule is that the logging convenience
methods in the Logger class (the config, entering, exiting, fine, finer, finest, 
log, logp, logrb, severe, throwing, and warning methods)  
will accept null values 
for all arguments except for the initial Level argument (if any).

Related Documentation

For an overview of control flow, 
please refer to the 

Java Logging Overview.",Package
10053,java.util.prefs,"This package allows applications to store and retrieve user and system
preference and configuration data. This data is stored persistently in an
implementation-dependent backing store. There are two separate trees of
preference nodes, one for user preferences and one for system preferences.",Package
10054,java.util.regex,"Classes for matching character sequences against patterns specified by regular
expressions.

 An instance of the Pattern class represents a
regular expression that is specified in string form in a syntax similar to
that used by Perl.

 Instances of the Matcher class are used to match
character sequences against a given pattern.  Input is provided to matchers via
the CharSequence interface in order to support matching
against characters from a wide variety of input sources. 
 Unless otherwise noted, passing a null argument to a method
in any class or interface in this package will cause a
NullPointerException to be thrown.

Related Documentation
 An excellent tutorial and overview of regular expressions is Mastering Regular
Expressions, Jeffrey E. F. Friedl, O'Reilly and Associates, 1997.",Package
10055,java.util.spi,Service provider classes for the classes in the java.util package.,Package
10056,java.util.zip,"Provides classes for reading and writing the standard ZIP and GZIP
file formats.  Also includes classes for compressing and decompressing
data using the DEFLATE compression algorithm, which is used by the
ZIP and GZIP file formats. Additionally, there are utility classes
for computing the CRC-32 and Adler-32 checksums of arbitrary
input streams.


Package Specification


      Info-ZIP Application Note 970311
       - a detailed description of the Info-ZIP format upon which
      the java.util.zip classes are based.


An implementation may optionally support the ZIP64(tm) format extensions
      defined by the 
      
      PKWARE ZIP File Format Specification. The ZIP64(tm) format extensions
      are used to overcome the size limitations of the original ZIP format.


APPENDIX D of 
      PKWARE ZIP File Format Specification - Language Encoding Flag (EFS) to
      encode ZIP entry filename and comment fields using UTF-8.


      ZLIB Compressed Data Format Specification version 3.3
       
      (pdf)
      (RFC 1950)


      DEFLATE Compressed Data Format Specification version 1.3
       
      (pdf)
      (RFC 1951)


      GZIP file format specification version 4.3
       
      (pdf)
      (RFC 1952)

CRC-32 checksum is described in RFC 1952 (above)

Adler-32 checksum is described in RFC 1950 (above)",Package
10057,javax.accessibility,"Defines a contract between user-interface components and an assistive technology
that provides access to those components. If a Java application fully supports
the Java Accessibility API, then it should be compatible with, and friendly
toward, assistive technologies such as screen readers, screen magnifiers,
etc. With a Java application that fully supports the Java Accessibility
API, no screen reader off screen model would be necessary because the API
provides all of the information normally contained in an off screen model.

The Java Accessibility API package consists of 8 Java programming language
interfaces, and 6 Java programming language classes. These are described
below.

Interface Accessible
Interface Accessible is the main interface
of the Java Accessibility API. All components that support the Java Accessibility
API must implement this interface. It contains a single method, getAccessibleContext,
that returns an instance of the class AccessibleContext.
Sun thinks that implementing this interface is the absolute minimum requirement
of every object that is part of the user interface of a Java application,
if that program is to be compatible with assistive technologies.

Class
AccessibleContext
AccessibleContext represents the minimum
information all accessible objects return and is obtained by calling the
getAccessibleContext method on an object that implements the Accessible
interface. This information includes the accessible name, description,
role, and state
of the object, as well as information about the parent and children of
the object.  In addition, JavaBeans TM
property change support is also included to allow assisitive technologies
learn when the values of the accessible properties change. AccessibleContext
also contains methods for obtaining more specific accessibility information
about a component. If the component supports it, these methods will return
an object that implements one or more of the following interfaces:


AccessibleAction - the object can
perform one or more actions. This interface provides the standard mechanism
for an assistive technology to determine what those actions are and tell
the object to perform those actions. Any object that can be manipulated
should return an object that implements this interface when the getAccessibleAction
method is called on an AccessibleContext.

AccessibleComponent - the object
has a graphical representation. This interface provides the standard mechanism
for an assistive technology to determine and set the graphical representation
of the object. Any object that is rendered on the screen should return
an object that implements this interface when the getAccessibleComponent
method is called on an AccessibleContext.

AccessibleSelection - the object
allows its children to be selected. This interface provides the standard
mechanism for an assistive technology to determine the currently selected
children as well as modify the selection set. Any object that has children
that can be selected should return an object that implements this interface
when the getAccessibleSelection method is called on an AccessibleContext.

AccessibleText - the object presents
editable textual information on the display. This interface provides the
standard mechanism for an assistive technology to access that text via
its content, attributes, and spatial location. Any object that contains
editable text should return an object that implements this interface when
the getAccessibleText method is called on an AccessibleContext.

AccessibleHypertext - the object
presents hypertext information on the display. This interface provides
the standard mechanism for an assistive technology to access that hypertext
via its content, attributes, and spatial location. Any object that contains
hypertext should return an object that implements this interface when the
getAccessibleText method is called on an AccessibleContext.

AccessibleValue - the object supports
a numerical value. This interface provides the standard mechanism for an
assistive technology to determine and set the current value of the object,
as well as the minimum and maximum values. Any object that supports a numerical
value should return an object that implements this interface when the getAccessibleValue
method is called on an AccessibleContext.


Class AccessibleRole
This class encapsulates the Accessible object's role in the user interface
and is obtained by calling the getAccessibleRole method on an
AccessibleContext. Accessible roles include
""Check box"", ""Menu Item"", ""Panel"", etc. These roles are identified by the
constants in this class such as AccessibleRole.CHECK_BOX, AccessibleRole.MENU_ITEM,
and AccessibleRole.PANEL. The constants in this class present
a strongly typed enumeration of common object roles. A public constructor
for this class has been purposely omitted and applications should use one
of the constants from this class. Although this class pre-defines a large
list of standard roles, it is extensible so additional programmer-defined
roles can be added in the future without needing to modify the base class.


Class AccessibleState
This class encapsulates a particular state of the Accessible object. Accessible
states include things like ""Armed"", ""Busy"", ""Checked"", ""Focused"", etc.
These roles are identified by the constants in this class such as AccessibleState.ARMED,
AccessibleState.BUSY, AccessibleState.CHECKED, and AccessibleState.FOCUSED.
The sum of all the states of an Accessible object is called the AccessibleStateSet,
and can be obtained by calling the getAccessibleStateSet method
on an AccessibleContext.

The constants in this class present a strongly typed enumeration of
common object roles. A public constructor for this class has been purposely
omitted and applications should use one of the constants from this class.
Although this class pre-defines a large list of standard roles, it is extensible
so additional, programmer-defined roles can be added in the future without
needing to modify the base class.


Class
AccessibleStateSet
This class encapsulates a collection of states of the Accessible object
and is obtained by calling the getAccessibleStateSet method on
an AccessibleContext. Since an object
might have multiple states (e.g. it might be both ""Checked"" and ""Focused""),
this class is needed to encapsulate a collection of these states. Methods
in the class provide for retrieving the individual AccessibleStates
on the state set.

Class AccessibleBundle
This class is used to maintain a strongly typed enumeration. It is the
super class of both the AccessibleRole and
AccessibleState classes. Programmers normally
do not interact with this class directly, but will instead use the AccessibleRole
and AccessibleState classes.


Interface
AccessibleAction
The AccessibleAction interface should
be supported by any object that can perform one or more actions. This interface
provides the standard mechanism for an assistive technology to determine
what those actions are as well as tell the object to perform those actions.
Any object that can be manipulated should support this interface.

Applications can determine if an object supports the AccessibleAction
interface by first obtaining its AccessibleContext
(see Accessible) and then calling the getAccessibleAction
method of AccessibleContext. If the return
value is not null, the object supports this interface.

Interface
AccessibleComponent
The AccessibleComponent interface
should be supported by any object that is rendered on the screen. This
interface provides the standard mechanism for an assistive technology to
determine and set the graphical representation of an object.

Applications can determine if an object supports the AccessibleComponent
interface by first obtaining its AccessibleContext
(see Accessible) and then calling the getAccessibleComponent
method of AccessibleContext. If the return
value is not null, the object supports this interface.

Interface
AccessibleSelection
The AccessibleSelection interface
provides the standard mechanism for an assistive technology to determine
what the current selected children are, as well as modify the selection
set. Any object that has children that can be selected should support this
the AccessibleSelection interface.

Applications can determine if an object supports the AccessibleSelection
interface by first obtaining its AccessibleContext
(see Accessible) and then calling the getAccessibleSelection
method of AccessibleContext. If the return
value is not null, the object supports this interface.

Interface AccessibleText
Interface AccessibleText is the contract
for making rich, editable text Accessible. Not all text displayed on the
screen is rich and editable (e.g. text contained in buttons, labels, menus,
etc., which users aren't expected to manipulate). However, objects containing
editable text must implement interface AccessibleText if they are to interoperate
with assistive technologies.

This interface provides support for going between pixel coordinates
and the text at a given pixel coordinate, for retrieving the letter, word,
and sentence at, before, or after a given position in the text. This interface
provides support for retrieving the attributes of the character at a given
position in the text (font, font size, style, etc.), as well as getting
the selected text (if any), the length of the text, and the location of
the text caret.

Applications can determine if an object supports the AccessibleText
interface by first obtaining its AccessibleContext
(see Accessible) and then calling the getAccessibleText
method of AccessibleContext. If the return
value is not null, the object supports this interface.

Interface AccessibleHypertext
The AccessibleHypertext interface
should be supported by any object that presents hypertext information on
the display. This interface provides the standard mechanism for an assistive
technology to access that text via its content, attributes, and spatial
location. It also provides standard mechanisms for manipulating hyperlinks.
Applications can determine if an object supports the AccessibleHypertext
interface by first obtaining its AccessibleContext
(see Accessible) and then calling the AccessibleContext.getAccessibleText()
method of AccessibleContext. If the return
value is a class which extends AccessibleHypertext, then that object supports
AccessibleHypertext.

Interface
AccessibleHyperlink
An object that is a hyperlink should support the AccessibleHyperlink
interface.  An object that implements this interface will be returned
by calling the getLink method on an AccessibleHypertext
object.

Interface
AccessibleValue
The AccessibleValue interface should
be supported by any object that supports a numerical value (e.g., a scroll
bar). This interface provides the standard mechanism for an assistive technology
to determine and set the numerical value as well as get the minimum and
maximum values.

Applications can determine if an object supports the AccessibleValue
interface by first obtaining its AccessibleContext
(see Accessible) and then calling the getAccessibleValue
method of AccessibleContext. If the return
value is not null, the object supports this interface.",Package
10058,javax.activation,"Signals that the requested operation does not support the
 requested data type.",Package
10059,javax.activity,"Contains Activity service related exceptions thrown by the ORB machinery during
unmarshalling.",Package
10060,javax.annotation,This class is used to allow multiple resources declarations.,Package
10061,javax.annotation.processing,"Facilities for declaring annotation processors and for
 allowing annotation processors to communicate with an annotation processing
 tool environment.

  Unless otherwise specified in a particular implementation, the
 collections returned by methods in this package should be expected
 to be unmodifiable by the caller and unsafe for concurrent access.

  Unless otherwise specified, methods in this package will throw
 a NullPointerException if given a null argument.",Package
10062,javax.crypto,"Provides the classes and interfaces for cryptographic operations. The
cryptographic operations defined in this package include encryption,
key generation and key agreement, and Message Authentication Code
(MAC) generation.

Support for encryption includes symmetric, asymmetric, block, and
stream ciphers. This package also supports secure streams and sealed
objects.

Many of the classes provided in this package are provider-based.  The
class itself defines a programming interface to which applications may
write.  The implementations themselves may then be written by
independent third-party vendors and plugged in seamlessly as needed.
Therefore application developers may take advantage of any number of
provider-based implementations without having to add or rewrite code.

Package Specification


JavaTM
    Cryptography Architecture Standard Algorithm Name
    Documentation

Related Documentation

For further documentation, please see:



JavaTM
       Cryptography Architecture (JCA) Reference Guide
      


How to Implement a Provider in the
      JavaTM Cryptography Architecture",Package
10063,javax.crypto.interfaces,"Provides interfaces for Diffie-Hellman keys as defined in
RSA Laboratories' PKCS #3.

Note that these interfaces are intended only
for key implementations whose key material
is accessible and available. These
interfaces are not intended for key
implementations whose key material resides
in inaccessible, protected storage (such as
in a hardware device).

For more developer information on how to use
these interfaces, including information on
how to design Key classes
for hardware devices, please refer to the
cryptographic provider developer guide:


How to Implement a Provider for the
    JavaTM Cryptography Architecture
    

Package Specification

PKCS #3: Diffie-Hellman Key-Agreement Standard, Version 1.4,
      November 1993.

Related Documentation

For further documentation, please see:



JavaTM
      Cryptography Architecture API Specification and Reference",Package
10064,javax.crypto.spec,"Provides classes and interfaces for key specifications and algorithm
parameter specifications.

A key specification is a transparent representation of the key
material that constitutes a key. A key may be specified in an
algorithm-specific way, or in an algorithm-independent encoding format
(such as ASN.1).  This package contains key specifications for
Diffie-Hellman public and private keys, as well as key specifications for DES,
Triple DES, and PBE secret keys.

An algorithm parameter specification is a transparent representation
of the sets of parameters used with an algorithm. This package contains
algorithm parameter specifications for parameters used with the
Diffie-Hellman, DES, Triple DES, PBE, RC2 and RC5 algorithms.

Package Specification

PKCS #3: Diffie-Hellman Key-Agreement Standard, Version 1.4,
  November 1993.
PKCS #5: Password-Based Encryption Standard, Version 1.5,
  November 1993.
Federal Information Processing Standards Publication (FIPS PUB) 46-2:
  Data Encryption Standard (DES) 

Related Documentation

For documentation that includes information about algorithm parameter
and key specifications, please see:



JavaTM
      Cryptography Architecture API Specification and Reference
      


How to Implement a Provider for the
      JavaTM Cryptography Architecture",Package
10065,javax.imageio,"The main package of the Java Image I/O API.



Many common image I/O operations may be performed using the static
methods of the ImageIO class.



This package contains the basic classes and interfaces for describing
the contents of image files, including metadata and thumbnails
(IIOImage); for controlling the image reading process
(ImageReader, ImageReadParam, and
ImageTypeSpecifier) and image writing process
(ImageWriter and ImageWriteParam); for
performing transcoding between formats (ImageTranscoder),
and for reporting errors (IIOException).


All implementations of javax.imageio provide the following standard
image format plug-ins:




  Reading Writing
Notes Metadata



 JPEG
yes
yes
none

    JPEG metadata format



PNG
yes
yes
none

    PNG metadata format



BMP
yes
yes
none

    BMP metadata format



WBMP
yes
yes
none

    WBMP metadata format



GIF
yes
yes

    GIF plug-in notes

    GIF metadata format






 Standard Plug-in Notes
Standard plug-in for GIF image format

ImageIO provides ImageReader and ImageWriter
plug-ins for the 
Graphics Interchange Format (GIF) image format.

These are the ""standard"" GIF plug-ins, meaning those that are included in the
JRE, as distinct from those included in standard extensions, or 3rd party
plug-ins. The following notes and metadata specification apply to the
standard plug-ins.

Writing GIF images
 The GIF image writer plug-in guarantees lossless writing for images which meet
 the following requirements:

the number of bands is 1;
the number of bits per sample is not greater than 8;
the size of a color component is not greater than 8;


 By default the GIF writer plug-in creates version ""89a"" images. This can be
 changed to ""87a"" by explicitly setting the version in the
 stream metadata (see 
 GIF Stream Metadata Format Specification).



 The GIF writer plug-in supports the creation of animated GIF images through
 the standard sequence writing methods defined in the
 ImageWriter class.
 
 



 A global color table is written to the output stream if one of the
 following conditions is met:
 
 stream metadata containing a GlobalColorTable element is
  supplied; 
 a sequence is being written and image metadata containing a
  LocalColorTable element is supplied for the first image in the
  sequence;
image metadata is not supplied or does not contain a LocalColorTable
  element. 


 In the first case the global color table in the stream metadata is
  used, in the second the local color table in the image metadata is
  used, and in the third a global color table is created from the
  ColorModel or SampleModel of the (first) image.
 

 A local color table is written to the output stream only if image
  metadata containing a LocalColorTable element is supplied to the
  writer, or no image metadata is supplied to the writer and the local
  color table which would be generated from the image itself is not
  equal to the global color table.
 

 A Graphic Control Extension block is written to the output stream only
  if image metadata containing a GraphicControlExtension element is
  supplied to the writer, or no image metadata is supplied and the
  local color table generated from the image requires a transparent
  index. Application, Plain Text, and Comment Extension blocks are
  written only if they are supplied to the writer via image metadata. 
 
 


 
  The writing of interlaced images can be controlled by the progressive
  mode of the provided ImageWriteParam instance.
  If progressive mode is
  MODE_DISABLED then a non-interlaced image will be written. If
  progressive mode is MODE_DEFAULT then an interlaced image will
  be written. If progressive mode is MODE_COPY_FROM_METADATA, then
  the metadata setting is used (if it is provided, otherwise an interlaced
  image will be written).
 

 The GIF image writer plug-in supports setting output stream metadata from
 metadata supplied to the writer in either the native GIF stream
 metadata format 
 javax_imageio_gif_stream_1.0  or the standard metadata format
 
 javax_imageio_1.0, and setting
 output image metadata from metadata supplied to the writer in either
 the native GIF image metadata format 
 javax_imageio_gif_image_1.0  or the standard metadata format
 javax_imageio_1.0.
  
 The mapping of standard metadata format to the GIF native stream and
 image metadata formats is given in the tables  here .",Package
10066,javax.imageio.event,"A package of the Java Image I/O API dealing with synchronous
notification of events during the reading and writing of images.



The IIOReadProgressListener interface allows for
notification of the percentage of an image that has been read
successfully.



The IIOReadUpdateListener interface allows for
notification of the portions of an image that have been read.  This is
useful, for example, for implementing dynamic display of an image as
it is loaded.



The IIOReadWarningListener interface allows for
notification of non-fatal errors during reading.



The IIOWriteWarningListener and
IIOWriteProgressListener interfaces perform analogous
functions for writers.",Package
10067,javax.imageio.metadata,"A package of the Java Image I/O API dealing with reading and writing
metadata.



When reading an image, its per-stream and per-image metadata is made
available as an IIOMetadata object.  The internals of
this object are specific to the plug-in that created it.  Its contents
may be accessed in the form of an XML Document, which is
implemented as a tree of IIOMetadataNode objects.



When writing an image, its metadata may be set by defining or
modifying an IIOMetadata object.  Such an object may be
obtained from an ImageWriter or
ImageTranscoder (from the
javax.imageio package).  Once such an object has
been obtained, its contents may be set of modified via a
Document consisting of IIOMetadataNodes.
The document format may optionally be described using an
IIOMetadataFormat object.



The format of the metadata contained in the XML Document
is identified by a string which appears as the root node of the tree
of IIOMetadataNode objects.  This string contains a version
number, e.g. ""javax_imageio_jpeg_image_1.0"".  Readers and writers may
support multiple versions of the same basic format and the Image I/O
API has methods that allow specifying which version to use by passing
the string to the method/constructor used to obtain an IIOMetadata
object.  In some cases, a more recent version may not be strictly
compatible with a program written expecting an older version (for
an example, see the Native Metadata Format section of the JPEG Metadata
Usage Notes below).



Plug-ins may choose to support a standard (plug-in neutral)
format.  This format does not provide lossless encoding of
metadata, but allows a portion of the metadata to be accessed in a
generic manner.



Each of the standard plug-ins supports a so-called ""native"" metadata
format, which encodes its metadata losslessly:




GIF metadata



JPEG metadata



PNG metadata



BMP metadata



WBMP metadata",Package
10068,javax.imageio.plugins.bmp,Package containing the public classes used by the built-in BMP plug-in.,Package
10069,javax.imageio.plugins.jpeg,"Classes supporting the built-in JPEG plug-in.



This package contains some support classes for the built-in JPEG
reader and writer plug-ins.  Classes are provided for representing
quantization and Huffman tables, and extensions of
ImageReadParam and ImageWriteParam are
provided to supply tables during the reading and writing process.  For
more information about the operation of the built-in JPEG plug-ins,
see the JPEG
metadata format specification and usage notes.",Package
10070,javax.imageio.spi,"A package of the Java Image I/O API containing the plug-in interfaces
for readers, writers, transcoders, and streams, and a runtime
registry.




The javax.imageio.spi package contains service
provider interfaces for reading, writing, and transcoding images, and
obtaining input and output streams, as well as a run-time registry
that discovers installed service provider instances and allows new
instances to be registered dynamically.",Package
10071,javax.imageio.stream,"A package of the Java Image I/O API dealing with low-level I/O from
files and streams.



The ImageInputStream interface unifies streaming and
file-based operations.  An abstract base class,
ImageInputStreamImpl is provided to simplify writing
a new ImageInputStream class.  Concrete implementation
classes (FileImageInputStream,
FileCacheImageInputStream, and
MemoryCacheImageInputStream) are provided that allow
input to come from a File or InputStream
with or without the use of a temporary cache file.



The ImageOutputStream interface performs an analogous
function for output.  An abstract base class,
ImageOutputStreamImpl is provided, along with
concrete implementation classes (FileImageOutputStream,
FileCacheImageOutputStream, and
MemoryCacheImageOutputStream) are provided that allow
output to go to a File or OutputStream with
or without the use of a temporary cache file.



The IIOByteBuffer class provides an alternative way to
perform reads of sequences of bytes that reduces the amount of
internal data copying.",Package
10072,javax.jws,"Marks a Java class as implementing a Web Service, or a Java interface as defining a Web Service interface.",Package
10073,javax.jws.soap,As of JSR-181 2.0 with no replacement.,Package
10074,javax.lang.model,"Classes and hierarchies of packages used to model the Java
 programming language.

 The members of this package and its subpackages are for use in
 language modeling and language processing tasks and APIs including,
 but not limited to, the annotation processing framework.

  This language model follows a mirror-based design; see

 
 Gilad Bracha and David Ungar. Mirrors: Design Principles for
 Meta-level Facilities of Object-Oriented Programming Languages.
 In Proc. of the ACM Conf. on Object-Oriented Programming, Systems,
 Languages and Applications, October 2004.
 

 In particular, the model makes a distinction between static
 language constructs, like the element representing java.util.Set, and the family of
 types that may be associated
 with an element, like the raw type java.util.Set, java.util.Set<String>, and java.util.Set<T>.

  Unless otherwise specified, methods in this package will throw
 a NullPointerException if given a null argument.",Package
10075,javax.lang.model.element,"Interfaces used to model elements of the Java programming language.

 The term ""element"" in this package is used to refer to program
 elements, the declared entities that make up a program.  Elements
 include classes, interfaces, methods, constructors, and fields.
 The interfaces in this package do not model the structure of a
 program inside a method body; for example there is no
 representation of a for loop or try-finally
 block.  However, the interfaces can model some structures only
 appearing inside method bodies, such as local variables and
 anonymous classes.

 When used in the context of annotation processing, an accurate
 model of the element being represented must be returned.  As this
 is a language model, the source code provides the fiducial
 (reference) representation of the construct in question rather than
 a representation in an executable output like a class file.
 Executable output may serve as the basis for creating a modeling
 element.  However, the process of translating source code to
 executable output may not permit recovering some aspects of the
 source code representation.  For example, annotations with
 source
retention cannot be
 recovered from class files and class files might not be able to
 provide source position information.  The modifiers on an element may
 differ in some cases including

 
 strictfp on a class or interface
  final on a parameter
  protected, private, and static on classes and interfaces
 

 Additionally, synthetic constructs in a class file, such as
 accessor methods used in implementing nested classes and bridge
 methods used in implementing covariant returns, are translation
 artifacts outside of this model.

 During annotation processing, operating on incomplete or
 erroneous programs is necessary; however, there are fewer
 guarantees about the nature of the resulting model.  If the source
 code is not syntactically well-formed or has some other
 irrecoverable error that could not be removed by the generation of
 new types, a model may or may not be provided as a quality of
 implementation issue.
 If a program is syntactically valid but erroneous in some other
 fashion, any returned model must have no less information than if
 all the method bodies in the program were replaced by ""throw
 new RuntimeException();"".  If a program refers to a missing type XYZ,
 the returned model must contain no less information than if the
 declaration of type XYZ were assumed to be ""class XYZ {}"",
 ""interface XYZ {}"", ""enum XYZ {}"", or ""@interface XYZ {}"". If a program refers to a missing type XYZ<K1, ... ,Kn>, the returned model must contain no less
 information than if the declaration of XYZ were assumed to be
 ""class XYZ<T1, ... ,Tn> {}"" or ""interface XYZ<T1,
 ... ,Tn> {}""
 Unless otherwise specified in a particular implementation, the
 collections returned by methods in this package should be expected
 to be unmodifiable by the caller and unsafe for concurrent access.

  Unless otherwise specified, methods in this package will throw
 a NullPointerException if given a null argument.",Package
10076,javax.lang.model.type,"Interfaces used to model Java programming language types.

  Unless otherwise specified in a particular implementation, the
 collections returned by methods in this package should be expected
 to be unmodifiable by the caller and unsafe for concurrent access.

  Unless otherwise specified, methods in this package will throw
 a NullPointerException if given a null argument.",Package
10077,javax.lang.model.util,"Utilities to assist in the processing of
 program elements and
 types.

  Unless otherwise specified in a particular implementation, the
 collections returned by methods in this package should be expected
 to be unmodifiable by the caller and unsafe for concurrent access.

  Unless otherwise specified, methods in this package will throw
 a NullPointerException if given a null argument.",Package
10078,javax.management,"Provides the core classes for the Java Management Extensions.
The Java Management Extensions
            (JMXTM) API is a standard
        API for management and monitoring.  Typical uses include:

consulting and changing application configuration
accumulating statistics about application behavior and
            making them available
notifying of state changes and erroneous conditions.

The JMX API can also be used as part of a solution for
        managing systems, networks, and so on.
The API includes remote access, so a remote management
            program can interact with a running application for these
        purposes.
MBeans
The fundamental notion of the JMX API is the MBean.
            An MBean is a named managed object representing a
            resource.  It has a management interface consisting
        of:

named and typed attributes that can be read and/or
            written
named and typed operations that can be invoked
typed notifications that can be emitted by the MBean.

For example, an MBean representing an application's
            configuration could have attributes representing the different
            configuration items.  Reading the CacheSize
            attribute would return the current value of that item.
            Writing it would update the item, potentially changing the
            behavior of the running application.  An operation such as
            save could store the current configuration
            persistently.  A notification such as
            ConfigurationChangedNotification could be sent
        every time the configuration is changed.
In the standard usage of the JMX API, MBeans are implemented
            as Java objects.  However, as explained below, these objects are
        not usually referenced directly.
Standard MBeans
To make MBean implementation simple, the JMX API includes the
            notion of Standard MBeans.  A Standard MBean is one
            whose attributes and operations are deduced from a Java
            interface using certain naming patterns, similar to those used
            by JavaBeansTM.  For
        example, consider an interface like this:

    public interface ConfigurationMBean {
         public int getCacheSize();
         public void setCacheSize(int size);
         public long getLastChangedTime();
         public void save();
    }
        
The methods getCacheSize and
            setCacheSize define a read-write attribute of
            type int called CacheSize (with an
        initial capital, unlike the JavaBeans convention).
The method getLastChangedTime defines an
            attribute of type long called
            LastChangedTime.  This is a read-only attribute,
        since there is no method setLastChangedTime.
The method save defines an operation called
            save.  It is not an attribute, since its name
            does not begin with get, set, or
        is.
The exact naming patterns for Standard MBeans are detailed in
        the JMX Specification.
There are two ways to make a Java object that is an MBean
            with this management interface.  One is for the object to be
            of a class that has exactly the same name as the Java
            interface but without the MBean suffix.  So in
            the example the object would be of the class
            Configuration, in the same Java package as
            ConfigurationMBean.  The second way is to use the
            StandardMBean
        class.
MXBeans
An MXBean is a variant of Standard MBean where complex
            types are mapped to a standard set of types defined in the
            javax.management.openmbean package.  MXBeans are appropriate
            if you would otherwise need to reference application-specific
            classes in your MBean interface.  They are described in detail
        in the specification for MXBean.
Dynamic MBeans
A Dynamic MBean is an MBean that defines its
            management interface at run-time.  For example, a configuration
            MBean could determine the names and types of the attributes it
        exposes by parsing an XML file.
Any Java object of a class that implements the DynamicMBean interface is a
        Dynamic MBean.
Open MBeans
An Open MBean is a kind of Dynamic MBean where the
            types of attributes and of operation parameters and return
            values are built using a small set of predefined Java classes.
            Open MBeans facilitate operation with remote management programs
            that do not necessarily have access to application-specific
            types, including non-Java programs.  Open MBeans are defined by
            the package 
        javax.management.openmbean.
Model MBeans
A Model MBean is a kind of Dynamic MBean that acts
            as a bridge between the management interface and the
            underlying managed resource.  Both the management interface and
            the managed resource are specified as Java objects.  The same
            Model MBean implementation can be reused many times with
            different management interfaces and managed resources, and it can
            provide common functionality such as persistence and caching.
            Model MBeans are defined by the package
            
        javax.management.modelmbean.
MBean Server
To be useful, an MBean must be registered in an MBean
            Server.  An MBean Server is a repository of MBeans.
            Usually the only access to the MBeans is through the MBean
            Server.  In other words, code no longer accesses the Java
            object implementing the MBean directly, but instead accesses
            the MBean by name through the MBean Server.  Each MBean has a
            unique name within the MBean Server, defined by the ObjectName class.
An MBean Server is an object implementing the interface
            MBeanServer.
            The most convenient MBean Server to use is the
            Platform MBean Server.  This is a
            single MBean Server that can be shared by different managed
            components running within the same Java Virtual Machine.  The
            Platform MBean Server is accessed with the method ManagementFactory.getPlatformMBeanServer().
Application code can also create a new MBean Server, or
            access already-created MBean Servers, using the MBeanServerFactory class.
Creating MBeans in the MBean Server
There are two ways to create an MBean.  One is to construct a
            Java object that will be the MBean, then use the registerMBean
            method to register it in the MBean Server.  The other is to
            create and register the MBean in a single operation using one
            of the createMBean methods.
The registerMBean method is simpler for local
            use, but cannot be used remotely.  The
            createMBean method can be used remotely, but
        sometimes requires attention to class loading issues.
An MBean can perform actions when it is registered in or
            unregistered from an MBean Server if it implements the MBeanRegistration
        interface.
Accessing MBeans in the MBean Server
Given an ObjectName name and an
            MBeanServer mbs, you can access
        attributes and operations as in this example:

    int cacheSize = mbs.getAttribute(name, ""CacheSize"");
    Attribute newCacheSize =
         new Attribute(""CacheSize"", new Integer(2000));
    mbs.setAttribute(name, newCacheSize);
    mbs.invoke(name, ""save"", new Object[0], new Class[0]);
        
Alternatively, if you have a Java interface that
            corresponds to the management interface for the MBean, you can use an
        MBean proxy like this:

    ConfigurationMBean conf =
        JMX.newMBeanProxy(mbs, name, ConfigurationMBean.class);
    int cacheSize = conf.getCacheSize();
    conf.setCacheSize(2000);
    conf.save();
        
Using an MBean proxy is just a convenience.  The second
            example ends up calling the same MBeanServer
        operations as the first one.
An MBean Server can be queried for MBeans whose names match
            certain patterns and/or whose attributes meet certain
            constraints.  Name patterns are constructed using the ObjectName class and constraints
            are constructed using the Query
            class.  The methods queryNames and queryMBeans then
        perform the query.
MBean lifecycle
An MBean can implement the MBeanRegistration interface in order to be told when it is registered
            and unregistered in the MBean Server. Additionally, the preRegister method
            allows the MBean to get a reference to the MBeanServer
            object and to get its ObjectName within the MBean
        Server.
Notifications
A notification is an instance of the Notification class or a
            subclass.  In addition to its Java class, it has a
            type string that can distinguish it from other
        notifications of the same class.
An MBean that will emit notifications must implement the
            NotificationBroadcaster or NotificationEmitter
            interface.  Usually, it does this by subclassing
            NotificationBroadcasterSupport or delegating to an instance of
        that class. Here is an example:

    public class Configuration extends NotificationBroadcasterSupport
            implements ConfigurationMBean {
        ...
        private void updated() {
            Notification n = new Notification(...);
            sendNotification(n);
        }
    }
        
Notifications can be received by a listener, which
            is an object that implements the NotificationListener
            interface.  You can add a listener to an MBean with the method
            MBeanServer.addNotificationListener(ObjectName,
            NotificationListener, NotificationFilter, Object).
            You can optionally supply a filter to this method, to
            select only notifications of interest.  A filter is an object
            that implements the NotificationFilter interface.
An MBean can be a listener for notifications emitted by other
            MBeans in the same MBean Server.  In this case, it implements
            NotificationListener and the method MBeanServer.addNotificationListener(ObjectName,
        ObjectName, NotificationFilter, Object) is used to listen.
Remote Access to MBeans
An MBean Server can be accessed remotely through a
            connector.  A connector allows a remote Java
            application to access an MBean Server in essentially the same
            way as a local one.  The package
            
        javax.management.remote defines connectors.
The JMX specification also defines the notion of an
            adaptor.  An adaptor translates between requests in a
            protocol such as SNMP or HTML and accesses to an MBean Server.
            So for example an SNMP GET operation might result in a
        getAttribute on the MBean Server.
Interoperability between versions of the JMX
          specification
When a client connects to a server using the JMX Remote
            API, it is possible that they do not have the same version
            of the JMX specification.  The version of the JMX
            specification described here is version 1.4.  Previous
            versions were 1.0, 1.1, and 1.2.  (There was no 1.3.)
            The standard JMX Remote API is defined to work with version
            1.2 onwards, so in standards-based deployment the only
            interoperability questions that arise concern version 1.2
        onwards.
Every version of the JMX specification continues to
            implement the features of previous versions.  So when the
            client is running an earlier version than the server, there
            should not be any interoperability concerns.
When the client is running a later version than the server,
            certain newer features may not be available, as detailed in
            the next sections.  The client can determine the server's
            version by examining the SpecificationVersion attribute of the MBeanServerDelegate.
If the remote MBean Server is 1.2

You cannot use wildcards in a key property of an
                ObjectName, for
                example domain:type=Foo,name=*. Wildcards that
                match whole properties are still allowed, for example
            *:* or *:type=Foo,*.
You cannot use Query.isInstanceOf
            in a query.
You cannot use dot syntax such as HeapMemoryUsage.used in the observed attribute of a monitor, as described in the
                documentation for the javax.management.monitor
            package.",Package
10079,javax.management.loading,"Provides the classes which implement advanced dynamic
        loading.  See the chapter Advanced Dynamic Loading in
        the JMX Specification.
An MBean that is of a subclass of ClassLoader can be used as a class loader to create
        other MBeans via the method MBeanServer.createMBean(String, ObjectName,
	ObjectName, Object[], String[]), and to instantiate arbitrary
        objects via the method MBeanServer.instantiate(String, ObjectName,
	Object[], String[]).  The MLet class is an example of
        such an MBean.  It is a URLClassLoader, so the list of URLs to load classes from can
        be configured.
Additionally, an MLet can read a configuration
        file that specifies a set of MBeans to be registered in the same
        MBean Server as the MLet.
Every MBean Server has a class loader repository
        containing all MBeans registered in that MBean Server that
        are of a subclass of ClassLoader.  The class
        loader repository is used by the forms of the
        createMBean and instantiate methods
        in the MBeanServer
        interface that do not have an explicit loader parameter.  It
        is also used by the MLet class when it does not
        find a class in its own set of URLs.
If an MBean implements the interface PrivateClassLoader,
        then it is not added to the class loader repository.  The class
        PrivateMLet is a
        subclass of MLet that implements
        PrivateClassLoader.",Package
10080,javax.management.modelmbean,"Provides the definition of the ModelMBean classes.  A Model
      MBean is an MBean that acts as a bridge between the management
      interface and the underlying managed resource.  Both the
      management interface and the managed resource are specified as
      Java objects.  The same Model MBean implementation can be
      reused many times with different management interfaces and
      managed resources, and it can provide common functionality
      such as persistence and caching.
A Model MBean implements the ModelMBean interface.
      It is a DynamicMBean
      whose getMBeanInfo method returns an object implementing ModelMBeanInfo.
Every MBean has an MBeanInfo with information about the MBean itself, and its
      attributes, operations, constructors, and notifications.  A
      Model MBean augments this MBeanInfo with Descriptors that encode
      additional information in the form of (key,value) pairs.
      Usually, Descriptors are instances of DescriptorSupport.
The class RequiredModelMBean provides a standard Model MBean
      implementation.
The following example shows a Model MBean being used to make
      the get method of a HashMap
      available for management through an MBean server.  No other
      methods are available through the MBean server.  There is
      nothing special about HashMap here.  Public
      methods from any public class can be exposed for management in
      the same way.

import java.lang.reflect.Method;
import java.util.HashMap;
import javax.management.*;
import javax.management.modelmbean.*;

// ...

MBeanServer mbs = MBeanServerFactory.createMBeanServer();
// The MBean Server

HashMap map = new HashMap();
// The resource that will be managed

// Construct the management interface for the Model MBean
Method getMethod = HashMap.class.getMethod(""get"", new Class[] {Object.class});
ModelMBeanOperationInfo getInfo =
    new ModelMBeanOperationInfo(""Get value for key"", getMethod);
ModelMBeanInfo mmbi =
    new ModelMBeanInfoSupport(HashMap.class.getName(),
                              ""Map of keys and values"",
                              null,  // no attributes
                              null,  // no constructors
                              new ModelMBeanOperationInfo[] {getInfo},
                              null); // no notifications

// Make the Model MBean and link it to the resource
ModelMBean mmb = new RequiredModelMBean(mmbi);
mmb.setManagedResource(map, ""ObjectReference"");

// Register the Model MBean in the MBean Server
ObjectName mapName = new ObjectName("":type=Map,name=whatever"");
mbs.registerMBean(mmb, mapName);

// Resource can evolve independently of the MBean
map.put(""key"", ""value"");

// Can access the ""get"" method through the MBean Server
mbs.invoke(mapName, ""get"", new Object[] {""key""}, new String[] {Object.class.getName()});
// returns ""value""
    
Package Specification

See the JMX 1.4 Specification
             PDF document available from the 
             
             Java Platform documentation on JMX technology",Package
10081,javax.management.monitor,"Provides the definition of the monitor classes.  A Monitor is
      an MBean that periodically observes the value of an attribute in
      one or more other MBeans.  If the attribute meets a certain
      condition, the Monitor emits a MonitorNotification. When the monitor MBean periodically calls
      getAttribute
      to retrieve the value of the attribute being monitored it does
      so within the access control context of the
      Monitor.start() caller.
The value being monitored can be a simple value
      contained within a complex type. For example, the MemoryMXBean defined in
      java.lang.management has an attribute
      HeapMemoryUsage of type MemoryUsage. To monitor the
      amount of used memory, described by the used
      property of MemoryUsage, you could monitor
      ""HeapMemoryUsage.used"". That string would be the
      argument to setObservedAttribute.
The rules used to interpret an ObservedAttribute like
      ""HeapMemoryUsage.used"" are as follows. Suppose the string is
      A.e (so A would be ""HeapMemoryUsage"" and e
      would be ""used"" in the example).
First the value of the attribute A is obtained. Call it
      v. A value x is extracted from v as follows:

If v is a CompositeData and if v.get(e)
      returns a value then x is that value.
If v is an array and e is the string ""length""
      then x is the length of the array.
If the above rules do not produce a value, and if Introspector.getBeanInfo
      for the class of v (v.getClass()) contains a
      PropertyDescriptor with the name
      e, then x is the result of calling the property's read method on
      v.

The third rule means for example that if the attribute
      HeapMemoryUsage is a MemoryUsage, monitoring
      ""HeapMemoryUsage.used"" will obtain the observed value by
      calling MemoryUsage.getUsed().
If the ObservedAttribute contains more than one period,
      for example ""ConnectionPool.connectionStats.length"", then the
      above rules are applied iteratively. Here, v would initially be
      the value of the attribute ConnectionPool, and x would
      be derived by applying the above rules with e equal to
      ""connectionStats"". Then v would be set to this x
      and a new x derived by applying the rules again with e
      equal to ""length"".
Although it is recommended that attribute names be valid Java
      identifiers, it is possible for an attribute to be called
      HeapMemoryUsage.used. This means that an
      ObservedAttribute that is HeapMemoryUsage.used
      could mean that the value to observe is either an attribute of that
      name, or the property used within an attribute called
      HeapMemoryUsage. So for compatibility reasons, when the
      ObservedAttribute contains a period (.), the monitor
      will check whether an attribute exists whose name is the full
      ObservedAttribute string (HeapMemoryUsage.used in the
      example). It does this by calling getMBeanInfo for the observed MBean and looking for a contained MBeanAttributeInfo with the given
      name. If one is found, then that is what is monitored. If more than one
      MBean is being observed, the behavior is unspecified if some of them have
      a HeapMemoryUsage.used attribute and others do not. An
      implementation may therefore call getMBeanInfo on just one of
      the MBeans in this case. The behavior is also unspecified if the result
      of the check changes while the monitor is active.
The exact behavior of monitors is detailed in the
        JMX Specification.  What follows is a
        summary.
There are three kinds of Monitors:


A CounterMonitor observes attributes of integer
            type.  The attributes are assumed to be non-negative, and
            monotonically increasing except for a possible
            roll-over at a specified modulus.  Each
            observed attribute has an associated threshold
            value.  A notification is sent when the attribute exceeds
            its threshold.
An offset value can be specified.  When an
            observed value exceeds its threshold, the threshold is
            incremented by the offset, or by a multiple of the offset
            sufficient to make the threshold greater than the new
            observed value.
A CounterMonitor can operate in
            difference mode.  In this mode, the value
            compared against the threshold is the difference between
            two successive observations of an attribute.


A GaugeMonitor observes attributes of numerical type.  Each
            observed attribute has an associated high
              threshold and low threshold.
When an observed attribute crosses the high threshold, if
            the notify high flag is true, then a notification
            is sent.  Subsequent crossings of the high threshold value
            will not trigger further notifications until the gauge value
            becomes less than or equal to the low threshold.
When an observed attribute crosses the low threshold, if
            the notify low flag is true, then a notification
            is sent.  Subsequent crossings of the low threshold value
            will not trigger further notifications until the gauge
            value becomes greater than or equal to the high
            threshold.
Typically, only one of the notify high and notify low
            flags is set.  The other threshold is used to provide a
            hysteresis mechanism to avoid the repeated
            triggering of notifications when an attribute makes small
            oscillations around the threshold value.
A GaugeMonitor can operate in difference
              mode.  In this mode, the value compared against the
            high and low thresholds is the difference between two
            successive observations of an attribute.


A StringMonitor observes attributes of type
            String.  A notification is sent when an
            observed attribute becomes equal and/or not equal to a
            given string.",Package
10082,javax.management.openmbean,"Provides the open data types and Open MBean descriptor classes.
      An Open MBean is an MBean where the types of attributes
      and of operation parameters and return values are built using a
      small set of predefined Java classes.  Open MBeans facilitate
      operation with remote management programs that do not necessarily
      have access to application-specific types, including non-Java
      programs.
Every MBean has an MBeanInfo with information about the MBean itself, and its
      attributes, operations, constructors, and notifications.  In an
      Open MBean, this MBeanInfo implements the OpenMBeanInfo
      interface, usually by being an instance of OpenMBeanInfoSupport.
The attribute information returned by MBeanInfo.getAttributes for an Open MBean is an array of
      objects implementing OpenMBeanAttributeInfo, usually instances of OpenMBeanAttributeInfoSupport.  In addition to the usual
      information about attributes, an
      OpenMBeanAttributeInfo specifies the OpenType of the attribute.
      The possible OpenType values are predefined, which
      is what ensures that remote managers will understand them.
Similar remarks apply to the parameter types of operations and
      constructors, and to the return types of operations.
There is a distinction between an attribute's Java language
      type, as returned by getType(), and
      its OpenType, as returned by getOpenType().  For example, if the Java language type is
      java.lang.String, the OpenType will be
      SimpleType.String.  If the Java language type is CompositeData, the
      OpenType will be a CompositeType that
      describes the items in the CompositeData instances
      for the attribute.
Default values and constraints
In Open MBeans, attributes and parameters can have default values
      and/or constraints associated with them in the OpenMBeanAttributeInfo or OpenMBeanParameterInfo.
      There are two ways to specify these constraints.  Either the
      values are directly specified as parameters to one of the
      constructors of OpenMBeanAttributeInfoSupport or
      OpenMBeanParameterInfoSupport, for example
      OpenMBeanParameterInfoSupport.OpenMBeanParameterInfoSupport(
      String, String, OpenType, Object, Object[]); or the values are
      specified in a Descriptor given
      as a parameter to one of the constructors.
When a Descriptor is used, the fields of interest are
      these:

defaultValue defines the value returned by
        getDefaultValue();

      minValue defines the value returned by getMinValue();

      maxValue defines the value returned by getMaxValue();

      legalValues defines the values returned by getLegalValues().

    
For defaultValue, minValue, and maxValue, the associated value must either be of the Java type
      corresponding to openType, or be a string that can be
      converted into that type.  The conversion uses the static method
      valueOf(String) if it finds one; otherwise a constructor
      with a single String parameter if it finds one; otherwise
      it fails.
For legalValues, the associated value must be either
      an array or a Set, and the elements of the array or set
      must be convertible as described for defaultValue etc.
The following conditions must be met for these fields:

the values must be of the appropriate type, or be strings
        that can be converted to the appropriate type as explained
        above;

      if legalValues is present then neither minValue nor maxValue must be present;

      if defaultValue is present then it must satisfy the
        constraints defined by legalValues, minValue, or
        maxValue when any of these is also present;

      if minValue and maxValue are both present
        then minValue must not be greater than maxValue.",Package
10083,javax.management.relation,"Provides the definition of the Relation Service.  The
        Relation Service is used to record relationships between
        MBeans in an MBean Server.  The Relation Service is itself an
        MBean.  More than one instance of a RelationService
        MBean can be registered in an MBean Server.
A relation type defines a relationship between MBeans.
        It contains roles that the MBeans play in the
        relationship.  Usually there are at least two roles in a
        relation type.
A relation is a named instance of a relation type,
        where specific MBeans appear in the roles, represented by
        their ObjectNames.
For example, suppose there are Module MBeans,
        representing modules within an application.  A
        DependsOn relation type could express the
        relationship that some modules depend on others, which could
        be used to determine the order in which the modules are
        started or stopped.  The DependsOn relation type
        would have two roles, dependent and
        dependedOn.
Every role is typed, meaning that an MBean that
        appears in that role must be an instance of the role's type.
        In the DependsOn example, both roles would be of
        type Module.
Every role has a cardinality, which provides lower
        and upper bounds on the number of MBeans that can appear in
        that role in a given relation instance.  Usually, the lower
        and upper bounds are both 1, with exactly one MBean appearing
        in the role.  The cardinality only limits the number of MBeans
        in the role per relation instance.  The same MBean can appear
        in the same role in any number of instances of a relation
        type.  In the DependsOn example, a given module
        can depend on many other modules, and be depended on by many
        others, but any given relation instance links exactly one
        dependent module with exactly one
        dependedOn module.
A relation type can be created explicitly, as an object
        implementing the RelationType interface, typically a RelationTypeSupport.  Alternatively, it can be created
        implicitly using the Relation Service's createRelationType method.
A relation instance can be created explicitly, as an object
        implementing the Relation interface, typically a RelationSupport.
        (A RelationSupport is itself a valid MBean, so it
        can be registered in the MBean Server, though this is not
        required.)  Alternatively, a relation instance can be created
        implicitly using the Relation Service's createRelation method.
The DependsOn example might be coded as follows.

import java.util.*;
import javax.management.*;
import javax.management.relation.*;

// ...
MBeanServer mbs = ...;

// Create the Relation Service MBean
ObjectName relSvcName = new ObjectName("":type=RelationService"");
RelationService relSvcObject = new RelationService(true);
mbs.registerMBean(relSvcObject, relSvcName);

// Create an MBean proxy for easier access to the Relation Service
RelationServiceMBean relSvc =
    MBeanServerInvocationHandler.newProxyInstance(mbs, relSvcName,
                                                  RelationServiceMBean.class,
                                                  false);

// Define the DependsOn relation type
RoleInfo[] dependsOnRoles = {
    new RoleInfo(""dependent"", Module.class.getName()),
    new RoleInfo(""dependedOn"", Module.class.getName())
};
relSvc.createRelationType(""DependsOn"", dependsOnRoles);

// Now define a relation instance ""moduleA DependsOn moduleB""

ObjectName moduleA = new ObjectName("":type=Module,name=A"");
ObjectName moduleB = new ObjectName("":type=Module,name=B"");

Role dependent = new Role(""dependent"", Collections.singletonList(moduleA));
Role dependedOn = new Role(""dependedOn"", Collections.singletonList(moduleB));
Role[] roleArray = {dependent, dependedOn};
RoleList roles = new RoleList(Arrays.asList(roleArray));
relSvc.createRelation(""A-DependsOn-B"", ""DependsOn"", roles);

// Query the Relation Service to find what modules moduleA depends on
Map<ObjectName,List<String>> dependentAMap =
    relSvc.findAssociatedMBeans(moduleA, ""DependsOn"", ""dependent"");
Set<ObjectName> dependentASet = dependentAMap.keySet();
// Set of ObjectName containing moduleB",Package
10084,javax.management.remote,"Interfaces for remote access to
        JMX MBean servers.
        This package defines the essential interfaces for making a JMX
        MBean server manageable remotely. The specification of this 
        functionality is completed by Part III of the 
       
        JMX Specification, version 1.4 PDF document.
The JMX specification defines the notion of connectors.
        A connector is attached to a JMX API MBean server and makes it
        accessible to remote Java clients. The client end of a
        connector exports essentially the same interface as the MBean
        server, specifically the MBeanServerConnection
        interface.
A connector makes an MBean server remotely accessible through
        a given protocol. The JMX Remote API allows the use of different 
        type of connectors:

      
The JMX Remote API defines a standard connector,
        the RMI Connector, which provides remote access to an
        MBeanServer through RMI.

       The JMX Remote API also defines an optional connector called 
        JMXMP Connector implementing the JMX Message Protocol 
        (JMXMP). As it is optional, it is not part of this bundle (see
        note below).

       User-defined connector protocols are also possible using the 
        JMXConnectorFactory and, optionally, the Generic Connector
        (not part of this bundle, see note below).
      
Note: the optional packages implementing
        the optional part of the JMX Remote API
        are not included in the Java SE Platform 
        but are available from the JMX Remote API 
        
        Reference Implementation.
Connector addresses
Typically, a connector server has an address, represented by the
        class JMXServiceURL.  An address for the RMI Connector can look
        like this:

      service:jmx:rmi:///jndi/rmi://myhost:1099/myname
      
In this JMXServiceURL, the first rmi:
        specifies the RMI connector, while the second rmi: 
        specifies the RMI registry into which the RMI connector server 
        has stored its stub.

      The example above shows only one form of address.
        An address for the RMI Connector can take several forms,
        as detailed in the documentation for the package
        javax.management.remote.rmi.
Creating a connector server
A connector server is created by constructing an instance of
        a subclass of JMXConnectorServer.  Usually, this instance is created
        using the method JMXConnectorServerFactory.newJMXConnectorServer.
Typically, a connector server is associated with an MBean
        server either by registering it in that MBean server, or by
        supplying the MBean server as a parameter when creating the
        connector server.
Creating a connector client
A connector client is usually created by supplying the
        JMXServiceURL of the connector server to connect to 
        to the JMXConnectorFactory.connect method.
For more specialized uses, a connector client can be created
        by directly instantiating a class that implements the JMXConnector interface,
        for example the class RMIConnector.
Additional client or server parameters
When creating a connector client or server, it is possible to
        supply an object of type Map that defines
        additional parameters.  Each entry in this Map has a key that is
        a string and an associated value whose type is appropriate for
        that key.  The standard keys defined by the JMX Remote API all
        begin with the string ""jmx.remote."".  The document
        JMX Remote API lists these standard keys.
Connection identifiers
Every connection opened by a connector server has a string
        identifier, called its connection id.  This identifier
        appears in the JMXConnectionNotification events emitted by the connector
        server, in the list returned by getConnectionIds(), and in the value
        returned by the client's getConnectionId() method.
As an example, a connection ID can look something like this:

rmi://192.18.1.9 username 1
      
The formal grammar for connection ids that follow this
         convention is as follows (using the grammar notation from section 2.4 of 
         The Java™ Language Specification):

ConnectionId:
    Protocol : ClientAddressopt Space ClientIdopt Space ArbitraryText

ClientAddress:
    // HostAddress ClientPortopt

ClientPort
    : HostPort
      
The Protocol is a protocol that would
        be recognized by JMXConnectorFactory.
The ClientAddress is the
        address and port of the connecting client, if these can be
        determined, otherwise nothing.  The
        HostAddress is the Internet address of
        the host that the client is connecting from, in numeric or DNS
        form.  Numeric IPv6 addresses are enclosed in square brackets
        [].  The HostPort is the
        decimal port number that the client is connecting from.
The ClientId is the identity of the
        client entity, typically a string returned by JMXPrincipal.getName().  This string must not contain
        spaces.
The ArbitraryText is any additional
        text that the connector server adds when creating the client id.
        At a minimum, it must be enough to distinguish this connection
        ID from the ID of any other connection currently opened by this
        connector server.",Package
10085,javax.management.remote.rmi,"The RMI connector is a connector for the JMX Remote API that
      uses RMI to transmit client requests to a remote MBean server.
      This package defines the classes that the user of an RMI
      connector needs to reference directly, for both the client and
      server sides.  It also defines certain classes that the user
      will not usually reference directly, but that must be defined so
      that different implementations of the RMI connector can
      interoperate.
The RMI connector supports both the JRMP and the IIOP transports
      for RMI.
Like most connectors in the JMX Remote API, an RMI connector
      usually has an address, which
      is a JMXServiceURL.  The protocol part of this address is
      rmi for a connector that uses the default RMI
      transport (JRMP), or iiop for a connector that
      uses RMI/IIOP.
There are two forms for RMI connector addresses:


        In the JNDI form, the URL indicates where to find
        an RMI stub for the connector.  This RMI stub is a Java
        object of type RMIServer that gives remote access to the connector server.
        With this address form, the RMI stub is obtained from an
        external directory entry included in the URL.  An external
        directory is any directory recognized by JNDI, typically the RMI registry, LDAP, or COS Naming.

      
        In the encoded form, the URL directly includes the
        information needed to connect to the connector server.  When
        using RMI/JRMP, the encoded form is the serialized RMI stub
        for the server object, encoded using BASE64 without embedded
        newlines.  When using RMI/IIOP, the encoded form is the CORBA
        IOR for the server object.
    
Addresses are covered in more detail below.
Creating an RMI connector server
The usual way to create an RMI connector server is to supply an
      RMI connector address to the method JMXConnectorServerFactory.newJMXConnectorServer.  The MBean
      server to which the connector server is attached can be
      specified as a parameter to that method.  Alternatively, the
      connector server can be registered as an MBean in that MBean
      server.
An RMI connector server can also be created by constructing an
      instance of RMIConnectorServer, explicitly or through the MBean server's
      createMBean method.
Choosing the RMI transport
You can choose the RMI transport (JRMP or IIOP) by specifying
      rmi or iiop in the
      protocol part of the
      serviceURL when creating the connector server.  You
      can also create specialised connector servers by instantiating
      an appropriate subclass of RMIServerImpl and
      supplying it to the RMIConnectorServer
      constructor.
Connector addresses generated by the
        server
If the serviceURL you specify has an empty URL
      path (after the optional host and port), or if you do not
      specify a serviceURL, then the connector server
      will fabricate a new JMXServiceURL that clients can
      use to connect:

If the serviceURL looks like:

        service:jmx:rmi://host:port
        
then the connector server will generate an RMIJRMPServerImpl and the returned JMXServiceURL
        looks like:

        service:jmx:rmi://host:port/stub/XXXX
        
where XXXX is the serialized form of the
        stub for the generated object, encoded in BASE64 without
        newlines.
If the serviceURL looks like:

        service:jmx:iiop://host:port
        
then the connector server will generate an RMIIIOPServerImpl and the returned
        JMXServiceURL looks like:

        service:jmx:iiop://host:port/ior/IOR:XXXX
        
where IOR:XXXX is the standard CORBA
        encoding of the Interoperable Object Reference for the
        generated object.
If there is no serviceURL, there must be a
        user-provided RMIServerImpl.  If the toStub
        method on this object returns an instance of Stub, then the connector server will generate
        a JMXServiceURL using the iiop
        form above.  Otherwise, it will generate a
        JMXServiceURL using the rmi
        form.

The host in a user-provided
      serviceURL is optional.  If present, it is copied
      into the generated JMXServiceURL but otherwise
      ignored.  If absent, the generated JXMServiceURL
      will have the local host name.
The port in a user-provided
      serviceURL is also optional.  If present, it is
      also copied into the generated JMXServiceURL;
      otherwise, the generated JMXServiceURL has no port.
      For an serviceURL using the rmi
      protocol, the port, if present, indicates
      what port the generated remote object should be exported on.  It
      has no other effect.
If the user provides an RMIServerImpl rather than a
      JMXServiceURL, then the generated
      JMXServiceURL will have the local host name in its
      host part and no
      port.
Connector addresses based on directory
        entries
As an alternative to the generated addresses just described,
      the serviceURL address supplied when creating a
      connector server can specify a directory address in
      which to store the provided or generated RMIServer
      stub.  This directory address is then used by both client and
      server.
In this case, the serviceURL has one of these two
      forms:

    service:jmx:rmi://host:port/jndi/jndi-name
    service:jmx:iiop://host:port/jndi/jndi-name
    
Here, jndi-name is a string that can be
      supplied to javax.naming.InitialContext.bind.
As usual, the host and
      :port can be omitted.
The connector server will generate an
      RMIServerImpl based on the protocol
      (rmi or iiop) and, for
      rmi, the port if any.  When
      the connector server is started, it will derive a stub from this
      object using its toStub method
      and store the object using the given
      jndi-name.  The properties defined by the
      JNDI API are consulted as usual.
For example, if the JMXServiceURL is:

      
      service:jmx:rmi://ignoredhost/jndi/rmi://myhost/myname
      

      then the connector server will generate an
      RMIJRMPServerImpl and store its stub using the JNDI
      name

      
      rmi://myhost/myname
      

      which means entry myname in the RMI registry
      running on the default port of host myhost.  Note
      that the RMI registry only allows registration from the local
      host.  So, in this case, myhost must be the name
      (or a name) of the host that the connector server is running
      on.

    In this JMXServiceURL, the first rmi:
      specifies the RMI
      connector, while the second rmi: specifies the RMI
      registry.
As another example, if the JMXServiceURL is:

      
      service:jmx:iiop://ignoredhost/jndi/ldap://dirhost:9999/cn=this,ou=that
      

      then the connector server will generate an
      RMIIIOPServerImpl and store its stub using the JNDI
      name

      
      ldap://dirhost:9999/cn=this,ou=that
      

      which means entry cn=this,ou=that in the LDAP
      directory running on port 9999 of host dirhost.

    If the JMXServiceURL is:

      
      service:jmx:iiop://ignoredhost/jndi/cn=this,ou=that
      

      then the connector server will generate an
      RMIIIOPServerImpl and store its stub using the JNDI
      name

      
      cn=this,ou=that
      

      For this case to work, the JNDI API must have been configured
      appropriately to supply the information about what directory to
      use.

    In these examples, the host name ignoredhost is
      not used by the connector server or its clients.  It can be
      omitted, for example:

      service:jmx:iiop:///jndi/cn=this,ou=that
      
However, it is good practice to use the name of the host
      where the connector server is running.  This is often different
      from the name of the directory host.
Connector server attributes
When using the default JRMP transport, RMI socket factories can
      be specified using the attributes
      jmx.remote.rmi.client.socket.factory and
      jmx.remote.rmi.server.socket.factory in the
      environment given to the
      RMIConnectorServer constructor.  The values of these
      attributes must be of type RMIClientSocketFactory and RMIServerSocketFactory, respectively.  These
      factories are used when creating the RMI objects associated with
      the connector.
Creating an RMI connector client
An RMI connector client is usually constructed using JMXConnectorFactory, with a
      JMXServiceURL that has rmi or
      iiop as its protocol.
If the JMXServiceURL was generated by the server,
      as described above under ""connector
      addresses generated by the server"", then the client will
      need to obtain it directly or indirectly from the server.
      Typically, the server makes the JMXServiceURL
      available by storing it in a file or a lookup service.
If the JMXServiceURL uses the directory syntax, as
      described above under ""connector addresses
      based on directory entries"", then the client may obtain it
      as just explained, or client and server may both know the
      appropriate directory entry to use.  For example, if the
      connector server for the Whatsit agent uses the entry
      whatsit-agent-connector in the RMI registry on host
      myhost, then client and server can both know
      that the appropriate JMXServiceURL is:

    service:jmx:rmi:///jndi/rmi://myhost/whatsit-agent-connector
    
If you have an RMI stub of type RMIServer, you can
      construct an RMI connection directly by using the appropriate
      constructor of RMIConnector.
Specifying an ORB for the RMI/IIOP connector
When using the IIOP transport, the client and server can
      specify what ORB to use
      with the attribute java.naming.corba.orb.
      Connection to the ORB happens at start time 
      for the connector server, and at connect time for the connector client.
      If the java.naming.corba.orb attribute is contained
      in the environment Map, then its value (an ORB), is used to connect the IIOP Stubs. 
      Otherwise, a new org.omg.CORBA.ORB is created by calling org.omg.CORBA.ORB.init((String[])null,(Properties)null).  A
      later RMI connector client or server in the same JVM can reuse
      this ORB, or it can create another one in the same way.
If the java.naming.corba.orb attribute is 
      specified and does not point to an ORB,
      then an IllegalArgumentException 
      will be thrown.
The mechanism described here does not apply when the IIOP
      Remote objects (Stubs or Servers) are created and connected to
      an ORB manually before being passed to the RMIConnector and
      RMIConnectorServer.
Dynamic code downloading
If an RMI connector client or server receives from its peer an
      instance of a class that it does not know, and if dynamic code
      downloading is active for the RMI connection, then the class can
      be downloaded from a codebase specified by the peer.  The
      article Dynamic
    code downloading using Java RMI explains this in more
    detail.",Package
10086,javax.management.timer,"Provides the definition of the Timer MBean.  A Timer MBean
      maintains a list of scheduled notifications and, because it is a
      NotificationBroadcaster, a list of listeners for those
      notifications.  Whenever the time for one of the scheduled
      notifications is reached, each listener receives the
      notification.  Notifications can be repeated at a fixed
      interval, and the number of repetitions can be bounded.
A listener for a Timer MBean can itself be an MBean, using
      the method MBeanServer.addNotificationListener(ObjectName,
      ObjectName, NotificationFilter, Object).  In this way, a
      management application can create an MBean representing a task,
      then schedule that task using a Timer MBean.",Package
10087,javax.naming,"Provides the classes and interfaces for accessing naming services.


This package defines the naming operations of the Java Naming and
Directory InterfaceTM (JNDI).  
JNDI provides naming and directory functionality to applications
written in the Java programming language.  It is designed to be
independent of any specific naming or directory service
implementation.  Thus a variety of services--new, emerging, and
already deployed ones--can be accessed in a common way.


Context

This package defines the notion of a context, represented
by the Context interface.
A context consists of a set of name-to-object bindings.
Context is the core interface for looking up, binding, unbinding, 
and renaming objects, and for creating and destroying subcontexts.

lookup() is the most commonly used operation.
You supply lookup()
the name of the object you want
to look up, and it returns the object bound to that name.
For example, the following code fragment looks up 
a printer and sends a document to the printer object
to be printed:



Printer printer = (Printer)ctx.lookup(""treekiller"");
printer.print(report);


Names

Every naming method in the Context
interface has two
overloads: one that accepts a 
Name argument and one that accepts a string name.
Name is an interface that represents a generic 
name--an ordered sequence of zero of more components.
For these methods, Name can be used to represent a
composite name (CompositeName)
so that you can name an object using a name which spans multiple namespaces.

The overloads that accept Name
are useful for applications that need to manipulate names: composing
them, comparing components, and so on.
The overloads that accept string names are likely to be more useful
for simple applications, such as those that simply read in a name
and look up the corresponding object.

Bindings

The Binding class represents a name-to-object binding.
It is a tuple containing the name of the bound object,
the name of the object's class, and the object itself.

The Binding class is actually a subclass of
NameClassPair, which consists
simply of the object's name and the object's class name.
The NameClassPair is useful when you only want
information about the object's class and do not want to
pay the extra cost of getting the object.

References
Objects are stored in naming and directory services in different ways.
If an object store supports storing Java objects, 
it might support storing an object in its serialized form.
However, some naming and directory services do not support the
storing of Java objects. Furthermore, for some
objects in the directory, Java programs are but one group of applications 
that access them. In this case, a serialized Java object might
not be the most appropriate representation.
JNDI defines a reference, represented by the Reference
class, which contains information on how to construct a copy of the object.
JNDI will attempt to turn references looked up from the directory
into the Java objects they represent, so that
JNDI clients have the illusion that what
is stored in the directory are Java objects. 


The Initial Context

In JNDI, all naming and directory operations are performed relative
to a context. There are no absolute roots.
Therefore JNDI defines an initial context, 
InitialContext,
which provides a starting point for naming and directory operations.
Once you have an initial context, you can use it to
look up other contexts and objects.

Exceptions

JNDI defines a class hierarchy for exceptions that can be thrown in
the course of performing naming and directory operations.  The root of
this class hierarchy is NamingException.
Programs interested in dealing with a particular exception
can catch the corresponding subclass of the exception.
Otherwise, programs should catch NamingException.


Package Specification

The JNDI API Specification and related documents can be found in the
JNDI documentation.",Package
10088,javax.naming.directory,"Extends the javax.naming package to provide functionality
for accessing directory services.


This package defines the directory operations of the Java Naming and
Directory InterfaceTM (JNDI).  
JNDI provides naming and directory functionality to applications
written in the Java programming language.  It is designed to be
independent of any specific naming or directory service
implementation.  Thus a variety of services--new, emerging, and
already deployed ones--can be accessed in a common way.


This package allows applications to retrieve and update attributes
associated with objects stored in a directory, and to search for
objects using specified attributes.

The Directory Context

The DirContext
interface represents a directory context.
It defines methods for examining and updating attributes associated with a
directory object, or directory entry as it is sometimes
called.

You use getAttributes() to retrieve the attributes 
associated with a directory object (for which you supply the name).
Attributes are modified using modifyAttributes(). 
You can add, replace, or remove attributes and/or attribute values
using this operation.

DirContext also behaves as a naming context
by extending the Context interface in the javax.naming package.
This means that any directory object can also provide
a naming context. 
For example, the directory object for a person might contain
the attributes of that person, and at the same time provide
a context for naming objects relative to that person
such as his printers and home directory.

Searches
DirContext contains methods for 
performing content-based searching of the directory.
In the simplest and most common form of usage, the application
specifies a set of attributes--possibly with specific 
values--to match, and submits this attribute set, to the 
search() method.
There are other overloaded forms of search()
that support more sophisticated search filters.


Package Specification

The JNDI API Specification and related documents can be found in the
JNDI documentation.",Package
10089,javax.naming.event,"Provides support for event notification when accessing naming and
directory services.


This package defines the event notification operations of the Java Naming
and Directory InterfaceTM (JNDI).  
JNDI provides naming and directory functionality to applications
written in the Java programming language.  It is designed to be
independent of any specific naming or directory service
implementation.  Thus a variety of services--new, emerging, and
already deployed ones--can be accessed in a common way.

Naming Events

This package defines a NamingEvent class to represent an event
that is generated by a naming/directory service.
It also defines subinterfaces of Context and DirContext,
called EventContext and EventDirContext,
through which applications can register their interest in events
fired by the context.

NamingEvent represents an event that occurs in a 
naming or directory service. There are two categories of naming events:

Those that affect the namespace (add/remove/rename an object)
Those that affect the objects' contents.

Each category of events is handled by a corresponding listener:
NamespaceChangeListener, ObjectChangeListener.

An application, for example, can register its interest in changes to
objects in a context as follows:


EventContext src = 
    (EventContext)(new InitialContext()).lookup(""o=wiz,c=us"");
src.addNamingListener(""ou=users"", EventContext.ONELEVEL_SCOPE,
    new ChangeHandler());
...
class ChangeHandler implements ObjectChangeListener {
    public void objectChanged(NamingEvent evt) {
        System.out.println(evt.getNewBinding());
    }
    public void namingExceptionThrown(NamingExceptionEvent evt) {
        System.out.println(evt.getException());
    }
}



Threading Issues

When an event is dispatched to a listener, the listener method (such
as objectChanged()) may be executed in a thread other than the
one in which the call to addNamingListener() was executed.
The choice of which thread to use is made by the service provider.
When an event is dispatched to multiple listeners, the service provider
may choose (and is generally encouraged) to execute the listener methods
concurrently in separate threads.

When a listener instance invokes NamingEvent.getEventContext(),
it must take into account the possibility that other threads will be
working with that context concurrently.  Likewise, when a listener is
registered via addNamingListener(), the registering thread
must take into account the likely possibility that the service provider
will later invoke the listeners in newly-created threads.  As Context
instances are not guaranteed to be thread-safe in general, all context
operations must be synchronized as needed.

Exception Handling

When a listener registers for events with a context, the context might
need to do some internal processing in order to collect information
required to generate the events.  The context, for example, might need
to make a request to the server to register interest in changes
on the server that will eventually be translated into events.
If an exception occurs that prevents information about the events from
being collected, the listener will never be notified of the events.
When such an exception occurs, a NamingExceptionEvent is
fired to notify the listener. The listener's
namingExceptionThrown() method is invoked, as shown in the 
sample code above,
and the listener is automatically deregistered.

Package Specification


The JNDI API Specification and related documents can be found in the
JNDI documentation.",Package
10090,javax.naming.ldap,"Provides support for LDAPv3 extended operations and controls.


This package extends the directory operations of the Java Naming and
Directory InterfaceTM (JNDI).  
JNDI provides naming and directory functionality to applications
written in the Java programming language.  It is designed to be
independent of any specific naming or directory service
implementation.  Thus a variety of services--new, emerging, and
already deployed ones--can be accessed in a common way.


This package is for applications and service providers that deal with
LDAPv3 extended operations and controls, as defined by
RFC 2251.
The core interface in this package is LdapContext, which defines
methods on a context for performing extended operations and handling
controls.

Extended Operations

This package defines the interface ExtendedRequest
to represent the argument to an extended operation,
and the interface ExtendedResponse to represent the result
of the extended operation.
An extended response is always paired with an extended request
but not necessarily vice versa. That is, you can have an extended request
that has no corresponding extended response.

An application typically does not deal directly with these interfaces.
Instead, it deals with classes that implement these
interfaces.  
The application gets these classes either as part of a
repertoire of extended operations standardized through the IETF, or
from directory vendors for vendor-specific extended operations.
The request classes should have constructors that accept
arguments in a type-safe and user-friendly manner, while the
response classes should have access methods for getting the data
of the response in a type-safe and user-friendly manner.
Internally, the request/response classes deal with encoding and decoding
BER values.

For example, suppose an LDAP server supports a ""get time"" extended operation.
It would supply classes such as
GetTimeRequest and GetTimeResponse,
so that applications can use this feature.
An application would use these classes as follows:

GetTimeResponse resp =
    (GetTimeResponse) ectx.extendedOperation(new GetTimeRequest());
long time = resp.getTime();


The GetTimeRequest and GetTimeResponse classes might
be defined as follows:

public class GetTimeRequest implements ExtendedRequest {
    // User-friendly constructor 
    public GetTimeRequest() {
    };

    // Methods used by service providers
    public String getID() {
        return GETTIME_REQ_OID;
    }
    public byte[] getEncodedValue() {
        return null;  // no value needed for get time request
    }
    public ExtendedResponse createExtendedResponse(
        String id, byte[] berValue, int offset, int length) throws NamingException {
        return new GetTimeResponse(id, berValue, offset, length);
    }
}
public class GetTimeResponse() implements ExtendedResponse {
    long time;
    // called by GetTimeRequest.createExtendedResponse()
    public GetTimeResponse(String id, byte[] berValue, int offset, int length) 
        throws NamingException {
        // check validity of id
        long time =  ... // decode berValue to get time
    }

    // Type-safe and User-friendly methods
    public java.util.Date getDate() { return new java.util.Date(time); }
    public long getTime() { return time; }

    // Low level methods
    public byte[] getEncodedValue() {
        return // berValue saved;
    }
    public String getID() {
        return GETTIME_RESP_OID;
    }
}

Controls

This package defines the interface Control to represent an LDAPv3
control. It can be a control that is sent to an LDAP server
(request control) or a control returned by an LDAP server
(response control).  Unlike extended requests and responses,
there is not necessarily any pairing between request controls and
response controls.  You can send request controls and expect no
response controls back, or receive response controls without sending
any request controls.

An application typically does not deal directly with this interface.
Instead, it deals with classes that implement this interface.
The application gets control classes either as part of a repertoire of
controls standardized through the IETF, or from directory vendors for
vendor-specific controls.  The request control classes should have
constructors that accept arguments in a type-safe and user-friendly
manner, while the response control classes should have access methods
for getting the data of the response in a type-safe and user-friendly
manner.  Internally, the request/response control classes deal with
encoding and decoding BER values.

For example, suppose an LDAP server supports a ""signed results""
request control, which when sent with a request, asks the
server to digitally sign the results of an operation. 
It would supply a class SignedResultsControl  so that applications
can use this feature.
An application  would use this class as follows:


Control[] reqCtls = new Control[] {new SignedResultsControl(Control.CRITICAL)};
ectx.setRequestControls(reqCtls);
NamingEnumeration enum = ectx.search(...);


The SignedResultsControl class might be defined as follows:

public class SignedResultsControl implements Control {
    // User-friendly constructor 
    public SignedResultsControl(boolean criticality) {
        // assemble the components of the request control
    };

    // Methods used by service providers
    public String getID() {
        return // control's object identifier
    }
    public byte[] getEncodedValue() {
        return // ASN.1 BER encoded control value
    }
    ...
}


When a service provider receives response controls, it uses
the ControlFactory class to produce specific classes 
that implement the Control interface.

An LDAP server can send back response controls with an LDAP operation
and also with enumeration results, such as those returned
by a list or search operation.
The LdapContext provides a method (getResponseControls())
for getting the response controls sent with an LDAP operation,
while the HasControls interface is used to retrieve
response controls associated with enumeration results.

For example, suppose an LDAP server sends back a ""change ID"" control in response
to a successful modification. It would supply a class ChangeIDControl
so that the application can use this feature.
An application would perform an update, and then try to get the change ID.

// Perform update
Context ctx = ectx.createSubsubcontext(""cn=newobj"");

// Get response controls
Control[] respCtls = ectx.getResponseControls();
if (respCtls != null) {
    // Find the one we want
    for (int i = 0; i < respCtls; i++) {
        if(respCtls[i] instanceof ChangeIDControl) {
            ChangeIDControl cctl = (ChangeIDControl)respCtls[i];
            System.out.println(cctl.getChangeID());
        }
    }
}

The vendor might supply the following ChangeIDControl and
VendorXControlFactory classes. The VendorXControlFactory
will be used by the service provider when the provider receives response
controls from the LDAP server.

public class ChangeIDControl implements Control {
    long id;

    // Constructor used by ControlFactory
    public ChangeIDControl(String OID, byte[] berVal) throws NamingException {
        // check validity of OID
        id = // extract change ID from berVal
    };

    // Type-safe and User-friendly method
    public long getChangeID() {
        return id;
    }

    // Low-level methods
    public String getID() {
        return CHANGEID_OID;
    }
    public byte[] getEncodedValue() {
        return // original berVal
    }
    ...
}
public class VendorXControlFactory extends ControlFactory {
    public VendorXControlFactory () {
    }

    public Control getControlInstance(Control orig) throws NamingException {
        if (isOneOfMyControls(orig.getID())) {
            ... 

            // determine which of ours it is and call its constructor
            return (new ChangeIDControl(orig.getID(), orig.getEncodedValue()));
        }
        return null;  // not one of ours
    }
}


Package Specification

The JNDI API Specification and related documents can be found in the
JNDI documentation.",Package
10091,javax.naming.spi,This class represents the result of resolution of a name.,Package
10092,javax.net,"Provides classes for networking applications. These classes include
factories for creating sockets. Using socket factories you can encapsulate
socket creation and configuration behavior.",Package
10093,javax.net.ssl,"Provides classes for the secure socket package. Using the secure socket
classes, you can communicate using SSL or a related security protocol
to reliably detect any errors introduced into the network byte stream
and to optionally encrypt the data and/or authenticate the communicating peers.

Package Specification


JavaTM
    Cryptography Architecture Standard Algorithm Name
    Documentation",Package
10094,javax.print,"Provides the principal classes and interfaces for the 
JavaTM Print Service API.
The Java Print Service API enables client and server applications to:

Discover and select print services based on their capabilities 
Specify the format of print data
Submit print jobs to services that support the document type to 
be printed.

Print Service Discovery

An application invokes the static methods of the abstract class 
PrintServiceLookup to locate print 
services that have the capabilities to satisfy the application's print 
request.  For example, to print a double-sided document, the application 
first needs to find printers that have the double-sided printing capability.

The JDK includes PrintServiceLookup implementations that
can locate the standard platform printers.  To locate other types of printers,
such as IPP printers or JINI printers, a print-service provider can write 
implementations of PrintServiceLookup.  The print-service provider 
can dynamically install these PrintServiceLookup implementations 
using the 

SPI JAR file specification.

Attribute Definitions

The javax.print.attribute and javax.print.attribute.standard 
packages define print attributes, which describe the capabilities of a print 
service, specify the requirements of a print job, and track the progress of 
a print job.

The javax.print.attribute package describes the types of attributes and
how they can be collected into sets.  The javax.print.attribute.standard
package enumerates all of the standard attributes supported by the API, most
of which are implementations of attributes specified in the IETF Specification, 

RFC 2911 Internet Printing Protocol, 1.1: Model and Semantics, dated 
September 2000.  The attributes specified in javax.print.attribute.standard
include common capabilites, such as: resolution, copies, media sizes, 
job priority, and page ranges.

Document Type Specification

The DocFlavor class represents the print data 
format, such as JPEG or PostScript.  A DocFlavor object 
consists of a MIME type, which describes the format, and a document 
representation class name that indicates how the document is delivered 
to the printer or output stream.  An application uses the 
DocFlavor and an attribute set to find printers that can 
print the document type specified by the DocFlavor and have 
the capabilities specified by the attribute set.  

Using the API

A typical application using the Java Print Service API performs these steps
to process a print request:

Chooses a DocFlavor.
Creates a set of attributes.
Locates a print service that can handle the print request as specified
by the DocFlavor and the attribute set.
Creates a Doc object encapsulating the 
DocFlavor
and the actual print data, which can take many forms including: a Postscript 
file, a JPEG image, a URL, or plain text.
Gets a print job, represented by DocPrintJob,
 from the print service.
Calls the print method of the print job.

The following code sample demonstrates a typical use of the Java Print 
Service API: locating printers that can print five double-sided copies
of a Postscript document on size A4 paper, creating a print job from 
one of the returned print services, and calling print.




FileInputStream psStream;
try {
   psStream = new FileInputStream(""file.ps"");
} catch (FileNotFoundException ffne) {
}
if (psStream == null) {
    return;
}

DocFlavor psInFormat = DocFlavor.INPUT_STREAM.POSTSCRIPT;
Doc myDoc = new SimpleDoc(psStream, psInFormat, null);  
PrintRequestAttributeSet aset = 
        new HashPrintRequestAttributeSet();
aset.add(new Copies(5));
aset.add(MediaSize.A4);
aset.add(Sides.DUPLEX);
PrintService[] services = 
  PrintServiceLookup.lookupPrintServices(psInFormat, aset);
if (services.length > 0) {
   DocPrintJob job = services[0].createPrintJob();
   try {
        job.print(myDoc, aset);
   } catch (PrintException pe) {}
}



Please note: In the javax.print APIs, a null reference parameter to methods 
is incorrect unless explicitly documented on the method as having a meaningful
interpretation. Usage to the contrary is incorrect coding and may result
in a run time exception either immediately or at some later time.
IllegalArgumentException and NullPointerException are examples of
typical and acceptable run time exceptions for such cases.",Package
10095,javax.print.attribute,"Provides classes and interfaces
that describe the types of JavaTM Print
Service attributes and how they can be collected into attribute sets.

What is an Attribute?
When setting up a print job,
a client specifies two things:
print data and processing instructions.
The print data is the actual content to be printed.
The processing instructions tell the printer how to print the print data,
such as: what media to use, how many copies to print, and 
whether to print on one or both sides of a sheet.  The client specifies
these processing instructions with the attribute definitions of the Java 
Print Service API.

The print data and the processing instructions
are separate entities.  This means that:

You can print the same print data
at different times using different processing instructions.

For example, you can print a slide presentation
on US letter-sized white paper,
double-sided, stapled, 20 copies
to make handouts for a talk;
and you could print the same slide presentation
on US letter-sized transparencies,
single-sided, one copy
to make the actual slides for the talk.
You can use the same processing instructions
at different times to print different data.
For example, you could set your default processing 
instructions to: US letter-sized paper, double sided, stapled.
Whenever you print a job, it prints with these settings,
unless you explicitly override them.



The processing instruction does not specify how the print job 
processes the request; each processing instruction is only a description 
of the results of a print job.  The print job determines the manner in
which it achieves the results specified by the processing instructions.
Representing processing instructions as descriptive items
provides more flexibility for implementing print jobs.

Attribute Categories and Values
Each printer has a set of capabilities, such as the ability to print on
different paper sizes or the ability to print more than one copy.  Each of 
the capabilities has a range of values.  For example, a printer's orientation 
capability might have this range of values: [landscape, portrait]. 
For each print request, the capability is set to one of these values.  The 
Java Print Service API uses the term attribute category to refer to
a printer capability and the term attribute value to refer to the value
of the capability.

In the Java Print Service API, an attribute category is represented by a Java 
class implementing the Attribute interface.  
Attribute values are instances of such a class or 
one of its subclasses.  For example, to specify the number of copies, an 
application constructs an instance of the 
Copies class with the 
number of desired copies and uses the Copies instance as part of 
the print request.  In this case, the Copies class represents the 
attribute category, and the Copies instance represents the 
attribute value.

Attribute Roles

When submitting a print job to a printer, the client provides the
attributes describing the characteristics of the print data, such as
the document name, and how the print data should be printed, such as
double-sided, five copies.  If a print job consists of multiple
pieces of print data, different pieces might have different processing
instructions, such as 8 x 11 inch media for the first document, and
11 x 17 inch media for another document.

Once the printer starts processing the print job,
additional information about the job becomes available, which might include:
the job state (such as completed or queued) and
the number of pages printed so far.  These pieces of information are also
attributes.  Attributes can also describe the printer itself, such as:
the printer name, the printer location, and the number of jobs queued. 


The Java Print Service API defines these different kinds of attributes 
with five subinterfaces of Attribute: 

DocAttribute specifies a characteristic
of an individual document and the print job settings to be applied to an
individual document.
PrintRequestAttribute specifies 
a setting applied to a whole print job and to all the documents in 
the print job. 
PrintJobAttribute reports the status
of a print job.
PrintServiceAttribute reports the
status of a print service.
SupportedValuesAttribute gives
the supported values for another attribute.

Each attribute class
implements one or more of these tagging subinterfaces
to indicate where the attribute can be used in the API.
If an attribute class implements multiple tagging subinterfaces,
the attribute can be used in multiple contexts.  For example, the media
attribute can apply to one document in a print job as a DocAttribute
or to an entire print job as a PrintRequestAttribute.
Certain low-level attributes
are never used on their own
but are always aggregated into higher-level attributes.
These low-level attribute classes only
implement interface Attribute,
not any of the tagging subinterfaces.

The Java Print Service API defines a group of
standard attribute classes modeled upon the attributes in
the Internet Printing Protocol (IPP) version 1.1. The
standard attribute classes are in the subpackage
javax.print.attribute.standard to keep the actual
attribute classes conceptually separate from the generic
apparatus defined in package javax.print.attribute. 

Attribute Sets
A client usually needs to provide more than one processing 
instruction when submitting a print job.  For example, the client might need to
specify a media size of A4 and a landscape orientation.  To send more than one
processing instruction, the client collects the attributes into an 
attribute set, which the Java Print Service API represents with the 
AttributeSet
 interface.

The AttributeSet interface is similar to the 
Map interface: it provides a map of 
key to values, in which each key is unique and can contain no more than one 
value.  However, the AttributeSet interface is designed to 
specifically support the needs of the Java Print Service API.  An 
AttributeSet requires that:

Each key in an AttributeSet corresponds to a category, and
the value of the key can only be one of the attribute values that belong
to the category represented by the key.  Thus, unlike a Map, an 
AttributeSet restricts the possible values of a key: an 
attribute category cannot be set to an attribute value that does not belong to
that category.
No two attributes from the same category can exist in the same set.
For example, an attribute collection
must not contain both a ""one-sided"" attribute and a ""two-sided"" attribute
because these two attributes give the printer conflicting instructions.
Only attributes implementing the Attribute interface can
be added to the set.


The javax.print.attribute package includes 
HashAttributeSet
as a concrete implementation of the attribute set interface.
HashAttributeSet provides an attribute set based on a hash map.
You can use this implementation or provide your own implementation
of interface AttributeSet.

The Java Print Service API provides four specializations of an attribute set 
that are restricted to contain just one of the four kinds of attributes, 
as discussed in the Attribute Roles section:

DocAttributeSet
PrintRequestAttributeSet
PrintJobAttributeSet
PrintServiceAttributeSet

Notice that only four kinds of attribute sets are listed here, but there are
five kinds of attributes.  Interface 
SupportedValuesAttribute
denotes an attribute that gives the supported values for another attribute.
Supported-values attributes are never aggregated into attribute sets,
so there is no attribute set subinterface defined for them.


In some contexts, an attribute set is read-only, which means that the 
client is only allowed to examine an attribute set's 
contents but not change them. In other contexts, the attribute set is read-write,
which means that the client is allowed both to examine and to change an 
attribute set's contents. For a read-only attribute set, calling a mutating 
operation throws an UnmodifiableSetException. 

Package javax.print.attribute includes
one concrete implementation of each of the attribute set subinterfaces:

HashDocAttributeSet
HashPrintRequestAttributeSet,
HashPrintJobAttributeSet,
HashPrintServiceAttributeSet.

All of these classes extend HashAttributeSet
and enforce the restriction that the attribute set is only allowed to contain
the corresponding kind of attribute.

Attribute Class Design
An attribute value is a small, atomic data item,
such as an integer or an enumerated value.  The Java Print Service API 
does not use primitive data types, such as int, to represent attribute 
values for these reasons:

Primitive data types are not type-safe.  For example, a compiler
should not allow a ""copies"" attribute value to 
be used for a ""sides"" attribute. 
Some attributes must be represented as a record of several
values.  One example is printer resolution, which requires two 
numbers, such as 600 and 300 representing 600 x 300 dpi.

For type-safety and to represent all attributes uniformly, the Java 
Print Service API defines each attribute category as a class, such as 
class Copies, class Sides, and class 
PrinterResolution.  Each 
attribute class wraps one or more primitive data items containing the 
attribute's value.  Attribute set operations perform frequent
comparisons between attribute category objects when adding attributes,
finding existing attributes in the same category, and looking
up an attribute given its category.  Because an attribute category is 
represented by a class, fast attribute-value comparisons can be performed 
with the Class.equals method.

Even though the Java Print Service API includes a large number of
different attribute categories, there are only a few different types
of attribute values.  Most attributes can be represented by a small
number of data types, such as: integer values, integer ranges, text,
or an enumeration of integer values.  The type of the attribute value that
a category accepts is called the attribute's abstract syntax.  To
provide consistency and reduce code duplication, the Java Print Service
API defines abstract syntax classes to represent each 
abstract syntax, and these classes are used as the parent of standard
attributes whenever possible.  The abstract syntax classes are:

EnumSyntax 
provides a type-safe enumeration in which enumerated
values are represented as singleton objects.  Each enumeration 
singleton is an instance of the enumeration class that wraps a hidden
int value.
IntegerSyntax
 is the abstract syntax for integer-valued attributes.
TextSyntax is 
the abstract syntax for text-valued attributes, and
includes a locale giving the text string's natural language.
SetOfIntegerSyntax
 is the abstract syntax for attributes 
representing a range or set of integers
ResolutionSyntax
 is the abstract syntax for attributes representing
 resolution values, such as 600x300 dpi.
Size2DSyntax
 is the abstract syntax for attributes representing a 
two-dimensional size, such as a paper size of 8.5 x 11 inches.
DateTimeSyntax
 is the abstract syntax for attributes whose value is a date and time.
URISyntax is the 
abstract syntax for attributes whose value is a Uniform Resource
Indicator.

The abstract syntax classes are independent of the attributes that
use them.  In fact, applications that have nothing to do with
printing can use the abstract syntax classes.  Although most of the
standard attribute classes extend one of the abstract syntax classes, 
no attribute class is required to extend one of these classes.  The 
abstract syntax classes merely provide a convenient implementation that
can be shared by many attribute classes.

Each attribute class implements the Attribute interface, either
directly or indirectly, to mark it as a printing attribute.  An
attribute class that can appear in restricted attribute sets in
certain contexts also implements one or more subinterfaces of 
Attribute.  Most attribute classes also extend the appropriate 
abstract syntax class to get the implementation.  Consider the 
Sides attribute class:


public class Sides
  extends EnumSyntax
  implements DocAttribute, PrintRequestAttribute, PrintJobAttribute
  {
  public final Object getCategory()
    {
    return Sides.class;
    }
  ...
  }
  


Since every attribute class implements Attribute, every attribute
class must provide an implementation for the 
getCategory method,
which returns the attribute category.  In the case of Sides, the
getCategory method returns Sides.class.  The 
getCategory method is final to ensure that any vendor-defined 
subclasses of a standard attribute class appear in the same category.  
Every attribute object is immutable once constructed so that attribute object 
references can be passed around freely.  To get a different attribute 
value, construct a different attribute object.  

Attribute Vendors

The Java Print Service API is designed so that vendors can:

define new vendor-specific values for any standard attribute 
defined in 
javax.print.attribute.standard.
define new attribute categories representing the vendor printer's
proprietary capabilities not already supported by the standard
attributes.

To define a new value for an attribute, a client can construct 
instances of such attributes with arbitrary values at runtime.
However, an enumerated attribute using an abstract syntax class
of EnumSyntax specifies all the possible attribute values 
at compile time as singleton instances of the attribute class.  This 
means that new enumerated values cannot be constructed at run time.  
To define new vendor-specific values for a standard enumerated 
attribute, the vendor must define a new attribute class specifying 
the new singleton instances.  To ensure that the new attribute values 
fall in the same category as the standard attribute values, the new 
attribute class must be a subclass of the standard attribute class.

To define a new attribute category, a vendor defines a new attribute
class.  This attribute class, like the standard attribute classes, 
implements Attribute or one of its subinterfaces and extends an
abstract syntax class.  The vendor can either use an existing 
abstract syntax class or define a new one.  The new vendor-defined
attribute can be used wherever an Attribute is used, such as in an
AttributeSet.

Using Attributes

A typical printing application uses the PrintRequestAttributeSet
because print-request attributes are the types of attributes that
client usually specifies.  This example demonstrates creating an attribute
set of print-request attributes and locating a printer that can
print the document according to the specified attributes:




FileInputStream psStream;
try {
   psstream = new FileInputStream(""file.ps"");
} catch (FileNotFoundException ffne) {
}
if (psstream == null) {
    return;
}
//Set the document type.  See the DocFlavor documentation for
//more information.
DocFlavor psInFormat = DocFlavor.INPUT_STREAM.POSTSCRIPT;
Doc myDoc = new SimpleDoc(pstream, psInFormat, null);  
PrintRequestAttributeSet aset = new HashPrintRequestAttributeSet();
aset.add(new Copies(5));
aset.add(MediaSize.A4);
aset.add(Sides.DUPLEX);

PrintService[] services = 
                PrintServiceLookup.lookupPrintServices(psInFormat, aset);
if (services.length > 0) {
   DocPrintJob job = services[0].createPrintJob();
   try {
        job.print(myDoc, aset);
   } catch (PrintException pe) {}
}



Please note: In the javax.print APIs, a null reference parameter to methods 
is incorrect unless explicitly documented on the method as having a meaningful
interpretation. Usage to the contrary is incorrect coding and may result
in a run time exception either immediately or at some later time.
IllegalArgumentException and NullPointerException are examples of
typical and acceptable run time exceptions for such cases.",Package
10096,javax.print.attribute.standard,"Package javax.print.attribute.standard
contains classes for specific printing attributes.
The parent package,

javax.print.attribute,
provides classes and interfaces that describe the types of Java
Print Service attributes and how they can be collected into attribute
sets.

An attribute represents a printing feature
that a print service can provide.
For each attribute,
a print service either does or does not support the attribute.
For each possible value of a supported attribute,
a print service either does or does not support the value.

The API requires every print service
to support certain attributes;
other attributes are optional
and the service can choose whether or not to support them.
Each attribute has a set of values that it accepts.  The API 
requires every print service to support certain values for
certain attributes;
other attribute values are optional
and the service can choose whether or not to support them.
These support requirements are recorded in the documentation
for each attribute class.

Package javax.print.attribute.standard
contains standard printing attributes
and standard printing attribute values
that are widely used in the printing domain.
A print service vendor
can provide new vendor-specific printing attributes
in addition to the standard ones.
A vendor can also provide
vendor-specific extensions (subclasses)
of the standard printing attributes --
for example,
to provide additional vendor-specific values
for an existing standard attribute.
Of course,
if a vendor wants clients
to be able to use any added or extended attributes,
the vendor must publish the new attribute classes.

Many of the standard attribute classes extend one of 
the abstract syntax classes of the javax.print.attribute package.
These abstract syntax classes each represent a 
different type.  The 
EnumSyntax class, for example, represents a type-safe
enumeration.  The abstract syntax class provides a wrapper for the attribute 
value.  

If an attribute class extends EnumSyntax, and the value of the 
attribute is an IPP-compatible value, the attribute's toString 
method returns the IPP string representation of the attribute value, such as
""processing-stopped"" for the 
JobState attribute.  However, because the 
EnumSyntax class is extensible, vendors can define their own 
attribute values.  If an attribute uses the EnumSyntax class 
and is set to one of these vendor-defined values then the toString
 method will not return the IPP string representation of the value.

A printing client application
will typically not need to use
all the printing attribute classes
in package javax.print.attribute.standard,
just the ones that pertain to the application.

The attribute classes in package javax.print.attribute.standard
are based on the Internet Printing Protocol (IPP) attributes
as defined in the Internet RFC document,
RFC 2911 Internet Printing Protocol/1.1: Model and Semantics
dated September 2000.
See RFC 2911
for more information.
The descriptive text for each attribute class
was taken largely from the above documents.
The above authors' contribution to the API
is gratefully acknowledged.

Attribute Organization
There are five kinds of printing attributes:
doc attributes,
print request attributes,
print job attributes,
print service attributes,
and supported-values attributes.

Doc Attributes
Doc attributes specify the characteristics of an individual doc
and the print job settings to be applied to an individual doc.
A doc attribute class implements interface
DocAttribute.
A doc attribute can appear in a 

DocAttributeSet.

Print Request Attributes
Print request attributes
specify the settings to be applied to a whole print job
and to all the docs in the print job. 
A print request attribute class implements interface

PrintRequestAttribute.
A print request attribute can appear in a   

PrintRequestAttributeSet.


Some attributes are doc attributes
but not print request attributes
and may only be specified at the doc level.
Some attributes are print request attributes
but not doc attributes
and may only be specified at the Print Request level.
Some attributes are both doc attributes
and print request attributes
and may be specified either at the doc level
or at the Print Request level.

When specified at the doc level,
an attribute applies just to that one doc.
When specified at the Print Request level,
an attribute applies to the whole job,
including all the docs in the job.
However, an attribute specified at the doc level
overrides an attribute in the same category
specified at the Print Request level.

Print Job Attributes
Print job attributes report the status of a Print Job.
A print job attribute class implements interface
PrintJobAttribute.
A print job attribute
can appear in a 
PrintJobAttributeSet.

Some attributes are both print request attributes
and print job attributes;
a client may include such attributes in a Print Request
to specify characteristics for the ensuing Print Job,
and those attributes then also appear
in the Print Job's attribute set.
Some attributes are print job attributes
but not print request attributes;
the print service itself
adds these attributes to the Print Job's attribute set.

Print Service Attributes
Print service attributes report the status
of a print service.
A print service attribute class implements interface

PrintServiceAttribute.
A print service attribute
can appear in a 
PrintServiceAttributeSet.

Supported-Values Attributes
A supported-value attribute
indicates the legal values for another attribute
that a print service supports.
A supported-values attribute class implements interface

SupportedValuesAttribute.
However, supported-values attributes
never appear in attribute sets,
so there is no restricted 
AttributeSet
subinterface for them.

Attribute Table
The table below lists all the printing attributes.
The table shows the tagging interfaces
each attribute class implements
in addition to interface 
Attribute,
thus indicating how each attribute is used in the API.
For each doc attribute and print request attribute,
the column marked ""SupportedValuesAttribute""
lists the supported-values attribute class, if any,
with which a print service 
indicates the supported values for that attribute category.



Attribute Class
DocAttribute
PrintRequestAttribute
PrintJobAttribute
PrintServiceAttribute
SupportedValuesAttribute

CompressionX    
DocumentNameX    
ChromaticityXXX  
Copies XX CopiesSupported
FinishingsXXX  
JobHoldUntil XX  
JobImpressions XX JobImpressionsSupported
JobKOctets XX JobKOctetsSupported
JobMediaSheets XX JobMediaSheetsSupported
JobName XX  
JobPriority XX JobPrioritySupported
JobSheets XX  
MediaXXX  
MediaSize     
MultipleDocumentHandling XX  
NumberUpXXX NumberUpSupported
OrientationRequestedXXX  
PageRangesXXX  
PresentationDirectionXXX  
PrinterResolutionXXX  
PrintQualityXXX  
RequestingUserName XX  
SheetCollateXXX  
SidesXXX  
DateTimeAtCompleted  X  
DateTimeAtCreation  X  
DateTimeAtProcessing  X  
JobImpressionsCompleted  X  
JobKOctetsProcessed  X  
JobMediaSheetsCompleted  X  
JobMessageFromOperator  X  
JobOriginatingUserName  X  
JobState  X  
JobStateReasonsContains zero or more --  X  
-- JobStateReason     
NumberOfDocuments  X  
NumberOfInterveningJobs  X  
OutputDeviceAssigned  X  
ColorSupported   X 
PagesPerMinute   X 
PagesPerMinuteColor   X 
PDLOverrideSupported   X 
PrinterIsAcceptingJobs   X 
PrinterInfo   X 
PrinterLocation   X 
PrinterMessageFromOperator   X 
PrinterMakeAndModel   X 
PrinterMoreInfo   X 
PrinterMoreInfoManufacturer   X 
PrinterName   X 
PrinterState   X 
PrinterStateReasonsContains zero or more --   X 
-- PrinterStateReason     
-- Severity     
QueuedJobCount   X 
ReferenceUriSchemesSupported     


Please note: In the javax.print APIs, a null reference parameter to methods 
is incorrect unless explicitly documented on the method as having a meaningful
interpretation. Usage to the contrary is incorrect coding and may result
in a run time exception either immediately or at some later time.
IllegalArgumentException and NullPointerException are examples of
typical and acceptable run time exceptions for such cases.",Package
10097,javax.print.event,"Package javax.print.event contains event classes  and listener interfaces.

They may be used to monitor both print services (such as printers going
on-line & off-line), and the progress of a specific print job.

Please note: In the javax.print APIs, a null reference parameter to methods 
is incorrect unless explicitly documented on the method as having a meaningful
interpretation. Usage to the contrary is incorrect coding and may result
in a run time exception either immediately or at some later time.
IllegalArgumentException and NullPointerException are examples of
typical and acceptable run time exceptions for such cases.",Package
10098,javax.rmi,"Contains user APIs for RMI-IIOP.  These APIs are
provided for use by RMI-IIOP applications, and provide equivalent
semantics when running over either IIOP or JRMP.  See also the
javax.rmi.CORBA package.",Package
10099,javax.rmi.CORBA,"Contains portability APIs for RMI-IIOP.  These APIs 
provide a standard interface between the generated stubs and ties and the 
RMI-IIOP runtime.  They also allow third party ORBs to be used for RMI over IIOP
as an alternative to the ORB supplied by Sun.  They are not intended to be called
directly from RMI-IIOP applications.  See also the javax.rmi package.",Package
10100,javax.rmi.ssl,"Provides implementations of RMIClientSocketFactory 
and RMIServerSocketFactory over 
the Secure Sockets Layer (SSL) or Transport Layer Security (TLS) protocols.",Package
10101,javax.script,"The scripting API consists of interfaces and classes that define
Java TM Scripting Engines and provides
a framework for their use in Java applications. This API is intended
for use by application programmers who wish to execute programs
written in scripting languages in their Java applications. The
scripting language programs are usually provided by the end-users of
the applications. 

The main areas of functionality of javax.script
package include 


Script execution: Scripts
        are streams of characters used as sources for  programs executed by
        script engines. Script execution uses 
        eval methods of
        ScriptEngine and methods of the 
        Invocable interface. 
        
Binding: This facility
        allows Java objects to be exposed to script programs as named
        variables. Bindings and 
        ScriptContext
        classes are used for this purpose. 
        
Compilation: This
        functionality allows the intermediate code generated by the
        front-end of a script engine to be stored and executed repeatedly.
        This benefits applications that execute the same script multiple
        times. These applications can gain efficiency since the engines'
        front-ends only need to execute once per script rather than once per
        script execution. Note that this functionality is optional and
        script engines may choose not to implement it. Callers need to check
        for availability of the Compilable
        interface using an instanceof check. 
        
Invocation: This
        functionality allows the reuse of intermediate code generated by a
        script engine's front-end. Whereas Compilation allows entire scripts
        represented by intermediate code to be re-executed, Invocation
        functionality allows individual procedures/methods in the scripts to
        be re-executed. As in the case with compilation, not all script
        engines are required to provide this facility. Caller has to check
        for Invocable availability. 
        
Script engine discovery and Metadata: Applications
        written to the Scripting API might have specific requirements on
        script engines. Some may require a specific scripting language
        and/or version while others may require a specific implementation
        engine and/or version. Script engines are packaged in a specified
        way so that engines can be discovered at runtime and queried for
        attributes. The Engine discovery mechanism is based on the Service
        discovery mechanism described in the Jar File Specification.
        Script engine implementing classes are packaged in jar files that
        include a  text resource named
        META-INF/services/javax.script.ScriptEngineFactory. This
        resource must include a line for each 
        ScriptEngineFactory
        that is packaged in the jar file. 
        ScriptEngineManager
        includes 
        getEngineFactories method to get all
        ScriptEngineFactory instances 
        discovered using this mechanism. ScriptEngineFactory has 
        methods to query attributes about script engine.",Package
10102,javax.security.auth,"This package provides a framework for authentication and
    authorization. The framework allows
    authentication to be performed in pluggable fashion. Different
    authentication modules can be plugged under an application without
    requiring modifications to the application itself. The
    authorization component allows specification of access controls
    based on code location, code signers and code executors
    (Subjects).",Package
10103,javax.security.auth.callback,"This package provides the classes necessary for services
        to interact with applications in order to retrieve 
        information (authentication data including usernames
        or passwords, for example) or to display information
        (error and warning messages, for example).",Package
10104,javax.security.auth.kerberos,"This package contains utility classes related to the Kerberos network
    authentication protocol. They do not provide much Kerberos support
    themselves.

    The Kerberos network authentication protocol is defined in 
    RFC 4120. The Java
    platform contains support for the client side of Kerberos via the 
    org.ietf.jgss package. There might also be 
    a login module that implements
    LoginModule to authenticate 
    Kerberos principals.

    You can provide the name of your default realm and Key Distribution
    Center (KDC) host for that realm using the system properties
    java.security.krb5.realm and java.security.krb5.kdc. Alternatively, you 
    can provide an MIT style configuration file called krb5.conf in
    <java-home>/lib/security. If you place this file elsewhere, you can
    indicate that location via the system property java.security.krb5.conf.",Package
10105,javax.security.auth.login,"This package provides a pluggable authentication framework.
Package Specification


JavaTM
    Cryptography Architecture Standard Algorithm Name
    Documentation",Package
10106,javax.security.auth.spi,"This package provides the interface to be used for
        implementing pluggable authentication modules.",Package
10107,javax.security.auth.x500,"This package contains the classes that should be used to store 
    X500 Principal and X500 Private Crendentials in a
    Subject.",Package
10108,javax.security.cert,"Provides classes for public key certificates.



These classes include a simplified version of the
java.security.cert package.  These classes were developed
as part of the Java Secure Socket
Extension (JSSE).  When JSSE was added to the J2SE version 1.4, this
package was added for backward-compatibility reasons only.



New applications should not use this package, but rather
java.security.cert.",Package
10109,javax.security.sasl,"Contains class and interfaces for supporting SASL.

This package defines classes and interfaces for SASL mechanisms.
It is used by developers to add authentication support for 
connection-based protocols that use SASL. 

SASL Overview


Simple Authentication and Security Layer (SASL) specifies a
challenge-response protocol in which data is exchanged between the
client and the server for the purposes of
authentication and (optional) establishment of a security layer on
which to carry on subsequent communications.  It is used with
connection-based protocols such as LDAPv3 or IMAPv4.  SASL is
described in
RFC 2222.


There are various mechanisms defined for SASL.
Each mechanism defines the data that must be exchanged between the
client and server in order for the authentication to succeed.
This data exchange required for a particular mechanism is referred to
to as its protocol profile.
The following are some examples of mechanims that have been defined by 
the Internet standards community.

DIGEST-MD5 (RFC 2831).
This mechanism defines how HTTP Digest Authentication can be used as a SASL
mechanism.
Anonymous (RFC 2245).
This mechamism is anonymous authentication in which no credentials are
necessary.
External (RFC 2222).
This mechanism obtains authentication information 
from an external source (such as TLS or IPsec).
S/Key (RFC 2222).
This mechanism uses the MD4 digest algorithm to exchange data based on
a shared secret.
GSSAPI (RFC 2222).
This mechanism uses the 
GSSAPI
for obtaining authentication information.


Some of these mechanisms provide both authentication and establishment
of a security layer, others only authentication.  Anonymous and
S/Key do not provide for any security layers.  GSSAPI and DIGEST-MD5
allow negotiation of the security layer.  For External, the
security layer is determined by the external protocol.

Usage

Users of this API are typically developers who produce
client library implementations for connection-based protocols,
such as LDAPv3 and IMAPv4,
and developers who write servers (such as LDAP servers and IMAP servers).
Developers who write client libraries use the
SaslClient and SaslClientFactory interfaces.
Developers who write servers use the
SaslServer and SaslServerFactory interfaces.

Among these two groups of users, each can be further divided into two groups:
those who produce the SASL mechanisms and those 
who use the SASL mechanisms.
The producers of SASL mechanisms need to provide implementations
for these interfaces, while users of the SASL mechanisms use 
the APIs in this package to access those implementations.

Related Documentation

Please refer to the 
Java 
SASL Programming Guide for information on how to use this API.",Package
10110,javax.sound.midi,"Provides interfaces and classes for I/O, sequencing, and synthesis of MIDI 
(Musical Instrument Digital Interface) data.

Related Documentation

For overviews, tutorials, examples, and guides,
please see:

Sound",Package
10111,javax.sound.midi.spi,"Supplies interfaces for service providers to implement when
offering new MIDI devices, MIDI file readers and writers, or sound bank readers.


Related Documentation

For overviews, tutorials, examples, and guides,
please see:

Sound",Package
10112,javax.sound.sampled,"Provides interfaces and classes for capture, processing, and playback of sampled audio data.



Related Documentation

For overviews, tutorials, examples, and guides,
please see:

Sound",Package
10113,javax.sound.sampled.spi,"Supplies abstract classes for service providers to subclass when
offering new audio devices, sound file readers and writers, or audio format converters.


Related Documentation

For overviews, tutorials, examples, and guides,
please see:

Sound",Package
10114,javax.sql,"Provides the API for server side data source access and processing from
the JavaTM programming language.
This package supplements the java.sql
package and, as of the version 1.4 release, is included in the 
Java Platform, Standard Edition
(Java SETM).
It remains an essential part of the Java Platform, Enterprise Edition
(Java EETM).

The javax.sql package provides for the following:

The DataSource interface as an alternative to the 
      DriverManager for establishing a 
      connection with a data source
  Connection pooling and Statement pooling
  Distributed transactions
  Rowsets


Applications use the DataSource and RowSet
APIs directly, but the connection pooling and distributed transaction
APIs are used internally by the middle-tier infrastructure.

Using a DataSource Object to Make a Connection

The javax.sql package provides the preferred
way to make a connection with a data source.  The DriverManager
class, the original mechanism, is still valid, and code using it will
continue to run.  However, the newer DataSource mechanism
is preferred because it offers many advantages over the 
DriverManager mechanism.

These are the main advantages of using a DataSource object to 
make a connection:

Changes can be made to a data source's properties, which means
      that it is not necessary to make changes in application code when
      something about the data source or driver changes.
  Connection  and Statement pooling and distributed transactions are available
      through a DataSource object that is
      implemented to work with the middle-tier infrastructure.
      Connections made through the DriverManager
      do not have connection and statement pooling or distributed transaction
      capabilities.


Driver vendors provide DataSource implementations. A
particular DataSource object represents a particular
physical data source, and each connection the DataSource object
creates is a connection to that physical data source. 

A logical name for the data source is registered with a naming service that
uses the Java Naming and Directory InterfaceTM  
(JNDI) API, usually by a system administrator or someone performing the 
duties of a system administrator. An application can retrieve the
DataSource object it wants by doing a lookup on the logical
name that has been registered for it.  The application can then use the 
DataSource object to create a connection to the physical data
source it represents.

A DataSource object can be implemented to work with the 
middle tier infrastructure so that the connections it produces will be
pooled for reuse. An application that uses such a DataSource 
implementation will automatically get a connection that participates in
connection pooling.  
A DataSource object can also be implemented to work with the 
middle tier infrastructure so that the connections it produces can be
used for distributed transactions without any special coding.

Connection Pooling and Statement Pooling

Connections made via a DataSource
object that is implemented to work with a middle tier connection pool manager
will participate in connection pooling.  This can improve performance
dramatically because creating new connections is very expensive. 
Connection pooling allows a connection to be used and reused, 
thus cutting down substantially on the number of new connections 
that need to be created.

Connection pooling is totally transparent.  It is done automatically
in the middle tier of a Java EE configuration, so from an application's 
viewpoint, no change in code is required. An application simply uses
the DataSource.getConnection method to get the pooled
connection and uses it the same way it uses any Connection
object.

The classes and interfaces used for connection pooling are:

ConnectionPoolDataSource
PooledConnection
ConnectionEvent
ConnectionEventListener
StatementEvent
StatementEventListener

The connection pool manager, a facility in the middle tier of
a three-tier architecture, uses these classes and interfaces
behind the scenes.  When a ConnectionPoolDataSource object
is called on to create a PooledConnection object, the
connection pool manager will register as a ConnectionEventListener
object with the new PooledConnection object.  When the connection
is closed or there is an error, the connection pool manager (being a listener)
gets a notification that includes a ConnectionEvent object.

If the connection pool manager supports Statement pooling, for
PreparedStatements, which can be determined by invoking the method 
DatabaseMetaData.supportsStatementPooling,  the
connection pool manager will register as a StatementEventListener
object with the new PooledConnection object.  When the 
PreparedStatement is closed or there is an error, the connection 
pool manager (being a listener)
gets a notification that includes a StatementEvent object.

Distributed Transactions

As with pooled connections, connections made via a DataSource
object that is implemented to work with the middle tier infrastructure
may participate in distributed transactions.  This gives an application
the ability to involve data sources on multiple servers in a single
transaction.

The classes and interfaces used for distributed transactions are:

XADataSource
XAConnection

These interfaces are used by the transaction manager; an application does
not use them directly.

The XAConnection interface is derived from the
PooledConnection interface, so what applies to a pooled connection
also applies to a connection that is part of a distributed transaction.  
A transaction manager in the middle tier handles everything transparently.
The only change in application code is that an application cannot do anything
that would interfere with the transaction manager's handling of the transaction.
Specifically, an application cannot call the methods Connection.commit 
or Connection.rollback, and it cannot set the connection to be in 
auto-commit mode (that is, it cannot call 
Connection.setAutoCommit(true)).  

An application does not need to do anything special to participate in a
distributed transaction.
It simply creates connections to the data sources it wants to use via
the DataSource.getConnection method, just as it normally does.
The transaction manager manages the transaction behind the scenes.  The
XADataSource interface creates XAConnection objects, and
each XAConnection object creates an XAResource object 
that the transaction manager uses to manage the connection.


Rowsets
The RowSet interface works with various other classes and
interfaces behind the scenes. These can be grouped into three categories.

Event Notification 

RowSetListener
A RowSet object is a JavaBeansTM
component because it has properties and participates in the JavaBeans
event notification mechanism. The RowSetListener interface 
is implemented by a component that wants to be notified about events that 
occur to a particular RowSet object.  Such a component registers
itself as a listener with a rowset via the RowSet.addRowSetListener
method.

When the RowSet object changes one of its rows, changes all of
it rows, or moves its cursor, it also notifies each listener that is registered 
with it.  The listener reacts by carrying out its implementation of the 
notification method called on it.

RowSetEvent
As part of its internal notification process, a RowSet object
creates an instance of RowSetEvent and passes it to the listener.
The listener can use this RowSetEvent object to find out which rowset
had the event.


Metadata 

RowSetMetaData
This interface, derived from the
ResultSetMetaData interface, provides information about
the columns in a RowSet object.  An application can use
RowSetMetaData methods to find out how many columns the
rowset contains and what kind of data each column can contain.

The RowSetMetaData interface provides methods for
setting the information about columns, but an application would not
normally use these methods.  When an application calls the RowSet 
method execute, the RowSet object will contain
a new set of rows, and its RowSetMetaData object will have been
internally updated to contain information about the new columns.


The Reader/Writer Facility
A RowSet object that implements the RowSetInternal
interface can call on the RowSetReader object associated with it
to populate itself with data.  It can also call on the RowSetWriter
object associated with it to write any changes to its rows back to the
data source from which it originally got the rows.
A rowset that remains connected to its data source does not need to use a 
reader and writer because it can simply operate on the data source directly.


RowSetInternal
By implementing the RowSetInternal interface, a 
RowSet object gets access to
its internal state and is able to call on its reader and writer. A rowset
keeps track of the values in its current rows and of the values that immediately
preceded the current ones, referred to as the original values.  A rowset
also keeps track of (1) the parameters that have been set for its command and 
(2) the connection that was passed to it, if any.  A rowset uses the 
RowSetInternal methods behind the scenes to get access to
this information.  An application does not normally invoke these methods directly.

RowSetReader
A disconnected RowSet object that has implemented the 
RowSetInternal interface can call on its reader (the 
RowSetReader object associated with it) to populate it with 
data.  When an application calls the RowSet.execute method, 
that method calls on the rowset's reader to do much of the work. Implementations
can vary widely, but generally a reader makes a connection to the data source,
reads data from the data source and populates the rowset with it, and closes
the connection. A reader may also update the RowSetMetaData object
for its rowset.  The rowset's internal state is also updated, either by the
reader or directly by the method RowSet.execute.


  RowSetWriter
A disconnected RowSet object that has implemented the 
RowSetInternal interface can call on its writer (the 
RowSetWriter object associated with it) to write changes
back to the underlying data source.  Implementations may vary widely, but
generally, a writer will do the following:



Make a connection to the data source 
  Check to see whether there is a conflict, that is, whether
      a value that has been changed in the rowset has also been changed 
      in the data source
  Write the new values to the data source if there is no conflict 
  Close the connection




The RowSet interface may be implemented in any number of
ways, and anyone may write an implementation. Developers are encouraged 
to use their imaginations in coming up with new ways to use rowsets.

IMPORTANT NOTE: Code that uses API marked ""Since 1.6"" must be run using a 
JDBC technology driver that implements the JDBC 4.0 API.
You must check your driver documentation to be sure that it implements
the particular features you want to use.

Package Specification

Specification of the 
      JDBC 4.0 API

Related Documentation

The Java Series book published by Addison-Wesley Longman provides detailed
information about the classes and interfaces in the javax.sql
package: 


JDBCTM
      API Tutorial and Reference, Third Edition:",Package
10115,javax.sql.rowset,"Standard interfaces and base classes for JDBC RowSet
implementations. This package contains interfaces and classes 
that a standard RowSet implementation either implements or extends.


Table of Contents

1.0 Package Specification
2.0 Standard RowSet Definitions
3.0 Implementater's Guide
4.0 Related Specifications
5.0 Related Documentation

1.0 Package Specification
This package specifies five standard JDBC RowSet interfaces.
 All five extend the 
RowSet interface described in the JDBC 3.0
specification.  It is anticipated that additional definitions
of more specialized JDBC RowSet types will emerge as this technology 
matures. Future definitions should be specified as subinterfaces using 
inheritance similar to the way it is used in this specification.

Note: The interface definitions provided in this package form the basis for
all compliant JDBC RowSet implementations. Vendors and more advanced
developers who intend to provide their own compliant RowSet implementations 
should pay particular attention to the assertions detailed in specification
interfaces. 

2.0 Standard RowSet Definitions

JdbcRowSet - A wrapper around 
a ResultSet object that makes it possible to use the result set as a 
JavaBeansTM component. Thus,
a JdbcRowSet object can be a Bean that any tool
makes available for assembling an application as part of a component based
architecture . A JdbcRowSet object is a connected RowSet
object, that is, it 
must continually maintain its connection to its data source using a JDBC
technology-enabled driver (""JDBC driver""). In addition, a JdbcRowSet
object provides a fully updatable and scrollable tabular 
data structure as defined in the JDBC 3.0 specification.


CachedRowSet™
 - A CachedRowSet object is a JavaBeansTM
 component that is scrollable, updatable, serializable, and generally disconnected from
 the source of its data. A CachedRowSet object
typically contains rows from a result set, but it can also contain rows from any
file with a tabular format, such as a spreadsheet. CachedRowSet implementations 
must use the SyncFactory to manage and obtain pluggable
SyncProvider objects to provide synchronization between the
disconnected RowSet object and the originating data source. 
Typically a SyncProvider implementation relies upon a JDBC
driver to obtain connectivity to a particular data source.
Further details on this mechanism are discussed in the javax.sql.rowset.spi package
specification.

WebRowSet - A 
WebRowSet object is an extension of CachedRowSet
that can read and write a RowSet object in a well formed XML format.
This class calls an XmlReader object 
(an extension of the RowSetReader
interface) to read a rowset in XML format. It calls an 
XmlWriter object (an extension of the 
RowSetWriter interface) 
to write a rowset in XML format. The reader and writer required by
WebRowSet objects are provided by the
SyncFactory in the form of SyncProvider
implementations. In order to ensure well formed XML usage, a standard generic XML
Schema is defined and published at

http://java.sun.com/xml/ns/jdbc/webrowset.xsd.

FilteredRowSet - A
FilteredRowSet object provides filtering functionality in a programmatic
and extensible way. There are many instances when a RowSet object
has a need to provide filtering in its contents without sacrificing the disconnected
environment, thus saving the expense of having to create a connection to the data source.
Solutions to this need vary from providing heavyweight full scale 
SQL query abilities, to portable components, to more lightweight 
approaches. A FilteredRowSet object consumes
an implementation of the Predicate 
interface, which may define a filter at run time. In turn, a
FilteredRowSet object is tasked with enforcing the set filter for both
inbound and outbound read and write operations. That is, all filters can be
considered as bi-directional. No standard filters are defined;
however, sufficient mechanics are specified to permit any required filter to be
implemented.

JoinRowSet - The JoinRowSet
interface  describes a mechanism by which relationships can be established between 
two or more standard RowSet implementations. Any number of RowSet
 objects can be added to a JoinRowSet object provided  the RowSetobjects 
can be related  in a SQL JOIN like fashion. By definition, the SQL JOIN 
statement  is used to combine the data contained in two (or more) relational
database tables based upon a common attribute. By establishing and then enforcing
column matches, a JoinRowSet object establishes relationships between
RowSet instances without the need to touch the originating data source.     

3.0 Implementer's Guide
Compliant implementations of JDBC RowSet Implementations 
must follow the assertions described in this specification. In accordance
with the terms of the Java Community Process, a
Test Compatibility Kit (TCK) can be licensed to ensure compatibility with the
specification. The following paragraphs outline a number of starting points for
implementers of the standard JDBC RowSet definitions. Implementers
should also consult the Implementer's Guide in the javax.sql.rowset.spi package for guidelines
on SyncProvider implementations.


3.1 Constructor

    All RowSet implementations must provide a
no-argument constructor.

3.2 Role of the BaseRowSet Class

A compliant JDBC RowSet implementation must implement one or more 
standard interfaces specified in this package and and may extend the 
BaseRowSet abstract class. For example, a 
CachedRowSet implementation must implement the CachedRowSet
interface and extend the BaseRowSet abstract class. The
BaseRowSet class provides the standard architecture on which all
RowSet implementations should be built, regardless of whether the
RowSet objects exist in a connected or disconnected environment.
The BaseRowSet abstract class provides any RowSet implementation
with its base functionality, including property manipulation and event notification
that is fully compliant with JavaBeans 
component requirements. As an example, all implementations provided in the
reference implementations (contained in the com.sun.rowset package) use
the BaseRowSet class as a basis for their implementations.            

The following table illustrates the features that the BaseRowSet
abstract class provides.
  



Feature

Details



Properties

Provides standard JavaBeans property manipulation
  mechanisms to allow applications to get and set RowSet command and
property  values. Refer to the   documentation of the javax.sql.RowSet
interface  (available in the JDBC 3.0 specification) for more details on
the standard  RowSet properties.



Event notification

Provides standard JavaBeans event notifications
  to registered event listeners. Refer to the documentation of javax.sql.RowSetEvent
            interface (available in the JDBC 3.0 specification) for
more  details on how  to register and handle standard RowSet events generated
by  compliant implementations.



Setters for a RowSet object's command

Provides a complete set of setter methods
                 for setting RowSet command parameters.



Streams

Provides fields for storing of stream instances
  in addition to providing a set of constants for stream type designation.






3.3 Connected RowSet Requirements

The JdbcRowSet describes a RowSet object that must always
be connected to the originating data source. Implementations of the JdbcRowSet
should ensure that this connection is provided solely by a JDBC driver. 
Furthermore, RowSet objects that are implementations of the 
JdbcRowSet interface and are therefore operating in a connected environment
do not use the SyncFactory to obtain a RowSetReader object
or a RowSetWriter object. They can safely rely on the JDBC driver to
supply their needs by virtue of the presence of an underlying updatable and scrollable
ResultSet implementation.


3.4 Disconnected RowSet Requirements
 
A disconnected RowSet object, such as a CachedRowSet object, 
should delegate  
connection management to a SyncProvider object provided by the 
SyncFactory. To ensure fully disconnected semantics, all 
disconnected RowSet objects must ensure
that the original connection made to the data source to populate the RowSet 
object is closed to permit the garbage collector to recover and release resources. The
SyncProvider object ensures that the critical JDBC properties are 
maintained in order to re-establish a connection to the data source when a 
synchronization is required. A disconnected RowSet object should 
therefore ensure that no 
extraneous references remain on the Connection object.

3.5 Role of RowSetMetaDataImpl

The RowsetMetaDataImpl class is a utility class that provides an implementation of the
RowSetMetaData interface, supplying standard setter
method implementations for metadata for both connected and disconnected 
RowSet objects. All implementations are free to use this standard
implementation but are not required to do so.

3.6 RowSetWarning Class

The RowSetWarning class provides warnings that can be set
on RowSet implementations.
Similar to SQLWarning objects,
RowSetWarning  objects are silently chained to the object whose method
caused the warning to be thrown. All RowSet implementations should  
ensure that this chaining occurs if a warning is generated and also ensure that the
warnings are available via the getRowSetWarnings method defined in either
the JdbcRowSet interface or the CachedRowSet interface. 
After a warning has been retrieved with one of the
getRowSetWarnings methods, the RowSetWarning method
getNextWarning can be called on it to retrieve any warnings that might
be chained on it.  If a warning is returned, getNextWarning can be called
on it, and so on until there are no more warnings.



3.7 The Joinable Interface

The Joinable interface provides both connected and disconnected 
RowSet objects with the capability to be added to a 
JoinRowSet object in an SQL JOIN operation.
A RowSet object that has  implemented the Joinable 
interface can set a match column, retrieve a match column, or unset a match column.
A JoinRowSet object can then use the RowSet object's
match column as a basis for adding the RowSet object.

3.8 The RowSetFactory Interface

        A RowSetFactory implementation must
        be provided.


4.0 Related Specifications

JDBC 3.0 Specification
XML Schema
SyncML

5.0 Related Documentation


JDBC RowSet Tutorial",Package
10116,javax.sql.rowset.serial,"Provides utility classes to allow serializable mappings between SQL types
and data types in the Java programming language.
 Standard JDBC RowSet implementations may use these utility 
classes to
assist in the serialization of disconnected RowSet objects. 
This is useful
when  transmitting a disconnected RowSet object over the wire to
a different VM or across layers within an application.

1.0 SerialArray
A serializable mapping in the Java programming language of an SQL ARRAY 
value. 

The SerialArray class provides a constructor for creating a SerialArray
instance from an Array object, methods for getting the base type and
the SQL name for the base type, and methods for copying all or part of a
SerialArray object. 
2.0 SerialBlob
A serializable mapping in the Java programming language of an SQL BLOB
value.  

The SerialBlob class provides a constructor for creating an instance
from a Blob object. Note that the Blob object should have brought the SQL
BLOB value's data over to the client before a SerialBlob object
is constructed from it. The data of an SQL BLOB value can be materialized
on the client as an array of bytes (using the method Blob.getBytes)
or as a stream of uninterpreted bytes (using the method Blob.getBinaryStream).


SerialBlob methods make it possible to make a copy of a SerialBlob
object as an array of bytes or as a stream. They also make it possible
to locate a given pattern of bytes or a Blob object within a SerialBlob
object. 
3.0 SerialClob
A serializable mapping in the Java programming language of an SQL CLOB
value.  

The SerialClob class provides a constructor for creating an instance
from a Clob object. Note that the Clob object should have
brought the SQL CLOB value's data over to the client before a SerialClob
object is constructed from it. The data of an SQL CLOB value can be
materialized on the client as a stream of Unicode characters. 

SerialClob methods make it possible to get a substring from a 
SerialClob object or to locate the start of a pattern of characters. 

5.0 SerialDatalink
A serializable mapping in the Java programming language of an SQL DATALINK
value. A DATALINK value references a file outside of the underlying data source
that the the originating data source manages. 

RowSet implementations can use the method RowSet.getURL() to retrieve
a java.net.URL object, which can be used to manipulate the external data.


      java.net.URL url = rowset.getURL(1);
6.0 SerialJavaObject
A serializable mapping in the Java programming language of an SQL JAVA_OBJECT
value. Assuming the Java object instance implements the Serializable interface,
this simply wraps the serialization process. 

If however, the serialization is not possible in the case where the Java
object is not immediately serializable, this class will attempt to serialize
all non static members to permit the object instance state to be serialized.
Static or transient fields cannot be serialized and attempting to do so 
will result in a SerialException being thrown. 
7.0 SerialRef
A serializable mapping between the SQL REF type and the Java programming
language. 

The SerialRef class provides a constructor for creating a SerialRef
instance from a Ref type and provides methods for getting
and setting the Ref object type. 
8.0 SerialStruct
A serializable mapping in the Java programming language of an SQL structured
type. Each attribute that is not already serializable is mapped to a serializable
form, and if an attribute is itself a structured type, each of its attributes
that is not already serializable is mapped to a serializable form. 

In addition, if a Map object is passed to one of the constructors or
to the method getAttributes, the structured type is custom mapped 
according to the mapping specified in the Map object.
  
  The SerialStruct class provides a constructor for creating an
instance  from a Struct object, a method for retrieving the SQL
type name of the SQL structured type in the database, and methods for retrieving
its attribute values. 
9.0 SQLInputImpl
  An input stream used for custom mapping user-defined types (UDTs). An 
  SQLInputImpl object is an input stream that contains a stream of 
  values that are
the attributes of a UDT. This class is used by the driver behind the scenes
when the method getObject is called on an SQL structured or distinct
type that has a custom mapping; a programmer never invokes SQLInputImpl
 methods directly. 

  The SQLInputImpl class provides a set of reader methods
 analogous to the ResultSet getter methods. These methods make it
 possible to read the values in an SQLInputImpl object. The method
wasNull is used to determine whether the the last value read was SQL NULL.
 

  When a constructor or getter method that takes a Map object is called, 
the JDBC driver calls the method
SQLData.getSQLType to determine the SQL type of the UDT being custom
mapped. The driver  creates an instance of SQLInputImpl, populating it with
the attributes of  the UDT. The driver then passes the input stream to the
method SQLData.readSQL,  which in turn calls the SQLInputImpl
methods to read the  attributes from the input stream. 
10.0 SQLOutputImpl
  The output stream for writing the attributes of a custom mapped user-defined
 type (UDT) back to the database. The driver uses this interface internally,
 and its methods are never directly invoked by an application programmer.


  When an application calls the method PreparedStatement.setObject, the
 driver checks to see whether the value to be written is a UDT with a custom
 mapping. If it is, there will be an entry in a type map containing the Class
 object for the class that implements SQLData for this UDT. If the
 value to be written is an instance of SQLData, the driver will
create  an instance of SQLOutputImpl and pass it to the method 
SQLData.writeSQL.
 The method writeSQL in turn calls the appropriate SQLOutputImpl
writer methods to write data from the SQLData object to the 
SQLOutputImpl
output  stream as the representation of an SQL user-defined type.       
   
Custom Mapping
The JDBC API provides mechanisms for mapping an SQL structured type or DISTINCT 
type to the Java programming language.  Typically, a structured type is mapped 
to a class, and its attributes are mapped to fields in the class.
(A DISTINCT type can thought of as having one attribute.)  However, there are
many other possibilities, and there may be any number of different mappings.

A programmer defines the mapping by implementing the interface SQLData.
For example, if an SQL structured type named AUTHORS has the attributes NAME,
TITLE, and PUBLISHER, it could be mapped to a Java class named Authors.  The
Authors class could have the fields name, title, and publisher, to which the
attributes of AUTHORS are mapped.  In such a case, the implementation of 
SQLData could look like the following:

   public class Authors implements SQLData {
       public String name;
       public String title;
       public String publisher;

       private String sql_type;
       public String getSQLTypeName() {
           return sql_type;
       }

       public void readSQL(SQLInput stream, String type)
                                  throws SQLException  {
           sql_type = type;
           name = stream.readString();
           title = stream.readString();
           publisher = stream.readString();
       }

       public void writeSQL(SQLOutput stream) throws SQLException {
           stream.writeString(name);
           stream.writeString(title);
           stream.writeString(publisher);
       }
   } 


A java.util.Map object is used to associate the SQL structured
type with its mapping to the class Authors. The following code fragment shows
how a Map object might be created and given an entry associating
AUTHORS and Authors.  

    java.util.Map map = new java.util.HashMap();
    map.put(""SCHEMA_NAME.AUTHORS"", Class.forName(""Authors"");

 
The Map object map now contains an entry with the 
fully qualified name of the SQL structured type and the Class
 object for the class Authors.  It can be passed to a method
to tell the driver how to map AUTHORS to Authors.  

For a disconnected RowSet object, custom mapping can be done
only when a Map object is passed to the method or constructor
that will be doing the custom mapping.  The situation is different for
connected RowSet objects because they maintain a connection
with the data source.  A method that does custom mapping and is called by 
a disconnected RowSet object may use the Map
object that is associated with the Connection object being
used. So, in other words, if no map is specified, the connection's type 
map can be used by default.",Package
10117,javax.sql.rowset.spi,"The standard classes and interfaces that a third party vendor has to
use in its implementation of a synchronization provider. These classes and 
interfaces are referred to as the Service Provider Interface (SPI). A vendor may 
have its implementation included on the JDBC web page that lists available
SyncProvider implementations by sending email to jdbc@sun.com.
Doing this helps make developers aware of the implementation. To make it possible
for a RowSet object to use an implementation, the vendor must register
it with the SyncFactory singleton. (See the class comment for
SyncProvider for a full explanation of the registration process and 
the naming convention to be used.)

Table of Contents

1.0 Package Specification
2.0 Service Provider Architecture
3.0 Implementer's Guide
4.0 Resolving Synchronization Conflicts
5.0 Related Specifications
6.0 Related Documentation

1.0 Package Specification

The following classes and interfaces make up the javax.sql.rowset.spi
package:

SyncFactory
SyncProvider
SyncFactoryException
SyncProviderException
SyncResolver
XmlReader
XmlWriter
TransactionalWriter

The following interfaces, in the javax.sql package, are also part of the SPI:

RowSetReader
RowSetWriter


A SyncProvider implementation provides a disconnected RowSet
object with the mechanisms for reading data into it and for writing data that has been
modified in it
back to the underlying data source.  A reader, a RowSetReader or
XMLReader object, reads data into a RowSet object when the 
CachedRowSet methods execute or populate 
are called.  A writer, a RowSetWriter or XMLWriter
object, writes changes back to the underlying data source when the 
CachedRowSet method acceptChanges is called.

The process of writing changes in a RowSet object to its data source
is known as synchronization.  The SyncProvider implementation that a
RowSet object is using determines the level of synchronization that the
RowSet object's writer uses. The various levels of synchronization are
referred to as grades.

The lower grades of synchronization are
known as optimistic concurrency levels because they optimistically
assume that there will be no conflicts or very few conflicts.  A conflict exists when
the same data modified in the RowSet object has also been modified 
in the data source. Using the optimistic concurrency model means that if there
is a conflict, modifications to either the data source or the RowSet 
object will be lost.

Higher grades of synchronization are called pessimistic because they assume
that others will be accessing the data source and making modifications.  These
grades set varying levels of locks to increase the chances that no conflicts
occur.

The lowest level of synchronization is simply writing any changes made to the 
RowSet object to its underlying data source.  The writer does
nothing to check for conflicts. 
If there is a conflict and the data
source values are overwritten, the changes other parties have made by to the data
source are lost. 

The RIXMLProvider implementation uses the lowest level 
of synchronization and just writes RowSet changes to the data source.
This is true because  typically XML data sources do not enable transaction
techniques for maintaining the integrity of data. However, specific standards 
groups have considered offering XML-based synchronization.  For details, see

     http://www.syncml.org


For the the next level up, the
writer checks to see if there are any conflicts, and if there are, 
it does not write anything to the data source.  The problem with this concurrency
level is that if another party has modified the corresponding data in the data source 
since the RowSet object got its data,
the changes made to the RowSet object are lost. The
RIOptimisticProvider implementation uses this level of synchronization.

At higher levels of synchronization, referred to as pessimistic concurrency,
the writer take steps to avoid conflicts by setting locks. Setting locks
can vary from setting a lock on a single row to setting a lock on a table 
or the entire data source. The level of synchronization is therefore a tradeoff 
between the ability of users to access the data source concurrently and the  ability
of the writer to keep the data in the RowSet object and its data source
synchronized.

It is a requirement that all disconnected RowSet objects 
(CachedRowSet, FilteredRowSet, JoinRowSet, 
and WebRowSet objects) obtain their SyncProvider objects
from the SyncFactory mechanism.  

The reference implementation (RI) provides two synchronization providers.
        
RIOptimisticProvider 
           The default provider that the SyncFactory instance will
           supply to a disconnected RowSet object when no provider
           implementation is specified.
           This synchronization provider uses an optimistic concurrency model,
           assuming that there will be few conflicts among users 
           who are accessing the same data in a database.  It avoids
           using locks; rather, it checks to see if there is a conflict
           before trying to synchronize the RowSet object and the
           data source. If there is a conflict, it does nothing, meaning that
                   changes to the RowSet object are not persisted to the data
           source.
       RIXMLProvider 
            A synchronization provider that can be used with a
            WebRowSet object, which is a rowset that can be written 
            in XML format or read from XML format. The 
            RIXMLProvider implementation does no checking at all for
            conflicts and simply writes any updated data in the
            WebRowSet object to the underlying data source.
            WebRowSet objects use this provider when they are 
            dealing with XML data.
        

These SyncProvider implementations
are bundled with the reference implementation, which makes them always available to
RowSet implementations. 
SyncProvider implementations make themselves available by being
registered with the SyncFactory singleton.  When a RowSet 
object requests a provider, by specifying it in the constructor or as an argument to the
CachedRowSet method setSyncProvider, 
the SyncFactory singleton
checks to see if the requested provider has been registered with it.
If it has, the SyncFactory creates an instance of it and passes it to the
requesting RowSet object.  
If the SyncProvider implementation that is specified has not been registered,
the SyncFactory singleton causes a SyncFactoryException object
to be thrown.  If no provider is specified,
the SyncFactory singleton will create an instance of the default
provider implementation, RIOptimisticProvider,
and pass it to the requesting RowSet object.


If a WebRowSet object does not specify a provider in its constructor, the
SyncFactory will give it an instance of RIOptimisticProvider.
However, the constructor for WebRowSet is implemented to set the provider 
to the RIXMLProvider, which reads and writes a RowSet object
in XML format.

See the SyncProvider class
specification for further details.

Vendors may develop a SyncProvider implementation with any one of the possible
levels of synchronization, thus giving RowSet objects a choice of
synchronization mechanisms.  A vendor can make its implementation available by 
registering the fully qualified class name with Oracle Corporation at
jdbc@sun.com. This process is discussed in further detail below. 

2.0 Service Provider Interface Architecture

2.1 Overview

The Service Provider Interface provides a pluggable mechanism by which
SyncProvider implementations can be registered and then generated when
required. The lazy reference mechanism employed by the SyncFactory limits
unnecessary resource consumption by not creating an instance until it is 
required by a disconnected
RowSet object. The SyncFactory class also provides
a standard API to configure logging options and streams that may be provided
by a particular SyncProvider implementation.

2.2 Registering with the SyncFactory

A third party SyncProvider implementation must be registered with the 
SyncFactory in order for a disconnected RowSet object 
to obtain it and thereby use its javax.sql.RowSetReader and 
javax.sql.RowSetWriter
implementations. The following registration mechanisms are available to all 
SyncProvider implementations:

System properties - Properties set at the command line. These
properties are set at run time and apply system-wide per invocation of the Java
application. See the section ""Related Documentation""
further related information.

Property Files - Properties specified in a standard property file.
This can be specified using a System Property or by modifying a standard
property file located in the platform run-time. The
reference implementation of this technology includes a standard property
file than can be edited to add additional SyncProvider objects.

JNDI Context - Available providers can be registered on a JNDI
context. The SyncFactory will attempt to load SyncProvider
objects bound to the context and register them with the factory. This
context must be supplied to the SyncFactory for the mechanism to 
function correctly.


Details on how to specify the system properties or properties in a property file
and how to configure the JNDI Context are explained in detail in the
SyncFactory class description.

2.3 SyncFactory Provider Instance Generation Policies

The SyncFactory generates a requested SyncProvider
object if the provider has been correctly registered.  The
following policies are adhered to when either a disconnected RowSet object
is instantiated with a specified SyncProvider implementation or is 
reconfigured at runtime with an alternative SyncProvider object.

 If a SyncProvider object is specified and the SyncFactory
contains no reference to the provider, a SyncFactoryException is 
thrown.

 If a SyncProvider object is specified and the SyncFactory
contains a reference to the provider, the requested provider is supplied.

 If no SyncProvider object is specified, the reference
implementation provider RIOptimisticProvider is supplied.


These policies are explored in more detail in the 
SyncFactory class.

3.0 SyncProvider Implementer's Guide

3.1 Requirements

A compliant SyncProvider implementation that is fully pluggable
into the SyncFactory must extend and implement all
abstract methods in the SyncProvider
class. In addition, an implementation must determine the 
grade, locking and updatable view capabilities defined in the
SyncProvider class definition. One or more of the
SyncProvider description criteria must be supported. It
is expected that vendor implementations will offer a range of grade, locking, and
updatable view capabilities.

Furthermore, the SyncProvider naming convention must be followed as
detailed in the SyncProvider class
description.

3.2 Grades

JSR 114 defines a set of grades to describe the quality of synchronization
a SyncProvider object can offer a disconnected RowSet
object. These grades are listed from the lowest quality of service to the highest.

GRADE_NONE - No synchronization with the originating data source is
provided. A SyncProvider implementation returning this grade will simply
attempt to write any data that has changed in the RowSet object to the
underlying data source, overwriting whatever is there. No attempt is made to compare 
original values with current values to see if there is a conflict. The 
RIXMLProvider is implemented with this grade.

GRADE_CHECK_MODIFIED_AT_COMMIT - A low grade of optimistic synchronization.
A SyncProvider implementation returning this grade
will check for conflicts in rows that have changed between the last synchronization 
and the current synchronization under way. Any changes in the originating data source
that have been modified will not be reflected in the disconnected RowSet
object. If there are no conflicts, changes in the RowSet object will be
written to the data source. If there are conflicts, no changes are written.
The RIOptimisticProvider implementation uses this grade.

GRADE_CHECK_ALL_AT_COMMIT - A high grade of optimistic synchronization.
A SyncProvider implementation   returning this grade
will check all rows, including rows that have not changed in the disconnected
RowSet object. In this way, any changes to rows in the underlying
data source will be reflected in the disconnected RowSet object
when the synchronization finishes successfully.

GRADE_LOCK_WHEN_MODIFIED - A pessimistic grade of synchronization.
SyncProvider implementations returning this grade will lock
the row in the originating  data source that corresponds to the row being changed
in the RowSet object to reduce the possibility of other
processes modifying the same data in the data source.

GRADE_LOCK_WHEN_LOADED - A higher pessimistic synchronization grade.
A SyncProvider implementation returning this grade will lock
the entire view and/or  table affected by the original query used to
populate a RowSet object.


3.3 Locks

JSR 114 defines a set of constants that specify whether any locks have been
placed on a RowSet object's underlying data source and, if so,
on which constructs the locks are placed.  These locks will remain on the data
source while the RowSet object is disconnected from the data source.

These constants should be considered complementary to the 
grade constants. The default setting for the majority of grade settings requires
that no data source locks remain when a RowSet object is disconnected 
from its data source.
The grades GRADE_LOCK_WHEN_MODIFIED and
GRADE_LOCK_WHEN_LOADED allow a disconnected RowSet object
to have a fine-grained control over the degree of locking.

DATASOURCE_NO_LOCK - No locks remain on the originating data source. 
This is the default lock setting for all SyncProvider implementations 
unless otherwise directed by a RowSet object.

DATASOURCE_ROW_LOCK - A lock is placed on the rows that are touched by
the original SQL query used to populate the RowSet object.

DATASOURCE_TABLE_LOCK - A lock is placed on all tables that are touched
by the query that was used to populate the RowSet object.

DATASOURCE_DB_LOCK
A lock is placed on the entire data source that is used by the RowSet
object.


3.4 Updatable Views

A RowSet object may be populated with data from an SQL VIEW.
The following constants indicate whether a SyncProvider object can
update data in the table or tables from which the VIEW was derived.

UPDATABLE_VIEW_SYNC
Indicates that a SyncProvider implementation  supports synchronization
to the table or tables from which the SQL VIEW used to populate  a
a RowSet object is derived.

NONUPDATABLE_VIEW_SYNC
Indicates that a SyncProvider implementation  does not support
synchronization to the table or tables from which the SQL VIEW 
used to populate  a RowSet object is derived.


3.5 Usage of SyncProvider Grading and Locking

In the example below, the reference CachedRowSetImpl implementation
reconfigures its current SyncProvider object by calling the 
setSyncProvider method.

    CachedRowSetImpl crs = new CachedRowSetImpl();
    crs.setSyncProvider(""com.foo.bar.HASyncProvider"");

    An application can retrieve the SyncProvider object currently in use
by a disconnected RowSet object. It can also retrieve the
grade of synchronization with which the provider was implemented and the degree of
locking currently in use.  In addition, an application has the flexibility to set
the degree of locking to be used, which can increase the possibilities for successful
synchronization.  These operation are shown in the following code fragment.

    SyncProvider sync = crs.getSyncProvider();

    switch (sync.getProviderGrade()) {
    case: SyncProvider.GRADE_CHECK_ALL_AT_COMMIT
         //A high grade of optimistic synchronization
    break;
    case: SyncProvider.GRADE_CHECK_MODIFIED_AT_COMMIT 
         //A low grade of optimistic synchronization 
    break;
    case: SyncProvider.GRADE_LOCK_WHEN_LOADED 
         // A pessimistic synchronization grade 
    break;
    case: SyncProvider.GRADE_LOCK_WHEN_MODIFIED 
         // A pessimistic synchronization grade 
    break;
    case: SyncProvider.GRADE_NONE 
      // No synchronization with the originating data source provided
    break;
    }
          
    switch (sync.getDataSourcLock() {
      case: SyncProvider.DATASOURCE_DB_LOCK
       // A lock is placed on the entire datasource that is used by the
       // RowSet object 
       break;

      case: SyncProvider.DATASOURCE_NO_LOCK
       // No locks remain on the  originating data source.
      break;

      case: SyncProvider.DATASOURCE_ROW_LOCK
       // A lock is placed on the rows that are  touched by the original 
       // SQL statement used to populate
       // the RowSet object that is using the SyncProvider
       break;

      case: DATASOURCE_TABLE_LOCK
       // A lock is placed on  all tables that are touched by the original 
       // SQL statement used to populated
       // the RowSet object that is using the SyncProvider
       break;


    It is also possible using the static utility method in the
SyncFactory class to determine the list of SyncProvider
implementations currently registered with the SyncFactory.
       

        Enumeration e = SyncFactory.getRegisteredProviders();

4.0 Resolving Synchronization Conflicts

The interface SyncResolver provides a way for an application to
decide manually what to do when a conflict occurs. When the CachedRowSet
method acceptChanges finishes and has detected one or more conflicts,
it throws a SyncProviderException object.  An application can
catch the exception and
have it retrieve a SyncResolver object by calling the method
SyncProviderException.getSyncResolver(). 

A SyncResolver object, which is a special kind of 
CachedRowSet object or
a JdbcRowSet object that has implemented the SyncResolver 
interface,  examines the conflicts row by row. It is a duplicate of the 
RowSet object being synchronized except that it contains only the data
from the data source this is causing a conflict. All of the other column values are
set to null. To navigate from one conflict value to another, a
SyncResolver object provides the methods nextConflict and
previousConflict.

The SyncResolver interface also
provides methods for doing the following:

finding out whether the conflict involved an update, a delete, or an insert
 getting the value in the data source that caused the conflict
 setting the value that should be in the data source if it needs to be changed
     or setting the value that should be in the RowSet object if it needs
     to be changed


When the CachedRowSet method acceptChanges is called, it 
delegates to the RowSet object's  SyncProvider object.
How the writer provided by that SyncProvider object is implemented
determines what level (grade) of checking for conflicts will be done.  After all 
checking for conflicts is completed and one or more conflicts has been found, the method
acceptChanges throws a SyncProviderException object. The
application can catch the exception and use it to obtain a SyncResolver object.  

The application can then use SyncResolver methods to get information
about each conflict and decide what to do.  If the application logic or the user
decides that a value in the RowSet object should be the one to
persist, the application or user can overwrite the data source value with it.  

The comment for the SyncResolver interface has more detail.

5.0 Related Specifications

JNDI 1.3
Java Logging
APIs

6.0 Related Documentation

System
properties
Resource Files
DataSource for JDBC
Connections",Package
10118,javax.swing,"Provides a set of ""lightweight""
(all-Java language) components that,
to the maximum degree possible, work the same on all platforms.
For a programmer's guide to using these components, see
Creating
a GUI with JFC/Swing, a trail in The Java Tutorial.
For other resources, see 
Related Documentation.

Swing's Threading Policy

In general Swing is not thread safe. All Swing components and related
classes, unless otherwise documented, must be accessed on the event
dispatching thread.

Typical Swing applications do processing in response to an event
generated from a user gesture. For example, clicking on a JButton notifies all ActionListeners added to the JButton. As all events generated from a user gesture are
dispatched on the event dispatching thread, most developers are not
impacted by the restriction.

Where the impact lies, however, is in constructing and showing a
Swing application. Calls to an application's main method,
or methods in Applet, are not invoked on the event
dispatching thread. As such, care must be taken to transfer control
to the event dispatching thread when constructing and showing an
application or applet. The preferred way to transfer control and begin
working with Swing is to use invokeLater. The invokeLater method schedules a Runnable to be processed on
the event dispatching thread. The following two examples work equally
well for transferring control and starting up a Swing application:

public class MyApp implements Runnable {
    public void run() {
        // Invoked on the event dispatching thread.
        // Construct and show GUI.
    }

    public static void main(String[] args) {
        SwingUtilities.invokeLater(new MyApp(args));
    }
}

Or:

public class MyApp {
    MyApp(String[] args) {
        // Invoked on the event dispatching thread. Do any initialization
        // here.
    }

    public void show() {
        // Show the UI.
    }

    public static void main(final String[] args) {
        // Schedule a job for the event-dispatching thread:
        // creating and showing this application's GUI.
        SwingUtilities.invokeLater(new Runnable() {
            public void run() {
                new MyApp(args).show();
            }
        });
    }
}

This restriction also applies to models attached to Swing components.
For example, if a TableModel is attached to a JTable, the TableModel should only be modified on the
event dispatching thread. If you modify the model on a separate
thread you run the risk of exceptions and possible display
corruption.

As all events are delivered on the event dispatching thread, care must
be taken in event processing. In particular, a long running task, such
as network io or computational intensive processing, executed on the
event dispatching thread blocks the event dispatching thread from
dispatching any other events. While the event dispatching thread is
blocked the application is completely unresponsive to user
input. Refer to SwingWorker for the preferred way to do such
processing when working with Swing.

More information on this topic can be found in the
Swing tutorial,
in particular the section on
How to Use Threads.



Related Documentation

For overviews, tutorials, examples, guides, and other documentation, please see:


The Swing Connection
The Java Tutorial
Online Training at the Java Developer ConnectionSM
Java Foundation Classes (JFC) home page",Package
10119,javax.swing.border,"Provides classes and interface for drawing
specialized borders around a Swing component.
You can subclass these classes to create customized borders
for your components instead of using the default borders
provided by the look-and-feel being used.


Note:
Most of the Swing API is not thread safe.
For details, see
Threads and Swing,
a section in
The Java Tutorial.


Related Documentation

For overviews, tutorials, examples, guides, and tool documentation, please see:

How to Use Borders,
      a section in The Java Tutorial",Package
10120,javax.swing.colorchooser,"Contains classes and interfaces used by the JColorChooser
component.


Note:
Most of the Swing API is not thread safe.
For details, see
Threads and Swing,
a section in
The Java Tutorial.


Related Documentation 

This document forms the complete API specification.  For overviews, tutorials, 
examples, guides, and tool documentation, please see:

How to Use Color Choosers, 
      a section in The Java Tutorial
Internationalization Documentation
Input Method Framework Documentation",Package
10121,javax.swing.event,"Provides for events fired by Swing components.  It contains
event classes and corresponding event listener interfaces for events
fired by Swing components in addition to those events in the
java.awt.event package.


Note:
Most of the Swing API is not thread safe.
For details, see
Threads and Swing,
a section in
The Java Tutorial.

Related Documentation

For overviews, tutorials, examples, guides, and tool documentation, please see:

Writing Event Listeners,
      a section in The Java Tutorial",Package
10122,javax.swing.filechooser,"Contains classes and interfaces used by the JFileChooser component.


Note:
Most of the Swing API is not thread safe.
For details, see
Threads and Swing,
a section in
The Java Tutorial.


Related Documentation 

This document forms the complete API specification.  For overviews, tutorials,
examples, guides, and tool documentation, please see:

How to Use File Choosers,
      a section in The Java Tutorial
Internationalization Documentation
Input Method Framework Documentation",Package
10123,javax.swing.plaf,"Provides one interface and many abstract classes that
Swing uses to provide its pluggable look-and-feel capabilities.  Its
classes are subclassed and implemented by look and feel UIs 
such as Basic and the Java look and feel (Metal).
This package is only used by developers who
cannot create a new look and feel by subclassing existing
look-and-feel components (such as those provided
by the javax.swing.plaf.basic and
javax.swing.plaf.metal packages).


Note:
Most of the Swing API is not thread safe.
For details, see
Threads and Swing,
a section in
The Java Tutorial.",Package
10124,javax.swing.plaf.basic,"Provides user interface objects built according to the
Basic look and feel. The Basic look and feel provides default 
behavior used by many look and feel packages. 
It contains components, layout managers,
events, event listeners, and adapters. 
You can subclass the classes in
this package to create your own customized look and feel.

These classes are designed to be used while the
corresponding LookAndFeel class has been
installed
(UIManager.setLookAndFeel(new XXXLookAndFeel())).
Using them while a different LookAndFeel is installed
may produce unexpected results, including exceptions.
Additionally, changing the LookAndFeel
maintained by the UIManager without updating the
corresponding ComponentUI of any
JComponents may also produce unexpected results,
such as the wrong colors showing up, and is generally not
encouraged.


Note:
Most of the Swing API is not thread safe.
For details, see
Threads and Swing,
a section in
The Java Tutorial.",Package
10125,javax.swing.plaf.metal,"Provides user interface objects built according to
the Java look and feel (once codenamed Metal),
which is the default look and feel.

These classes are designed to be used while the
corresponding LookAndFeel class has been
installed
(UIManager.setLookAndFeel(new XXXLookAndFeel())).
Using them while a different LookAndFeel is installed
may produce unexpected results, including exceptions.
Additionally, changing the LookAndFeel
maintained by the UIManager without updating the
corresponding ComponentUI of any
JComponents may also produce unexpected results,
such as the wrong colors showing up, and is generally not
encouraged.


Note:
Most of the Swing API is not thread safe.
For details, see
Threads and Swing,
a section in
The Java Tutorial.",Package
10126,javax.swing.plaf.multi,"Provides user interface objects that combine two or more look and feels.
When a component asks
for its UI, this look and feel returns a 
multiplexing UI that handles all communications with both the 
default look and feel and one or more auxiliary look and feels. 
For example, if
a user combines an auxiliary audio look and feel 
with the Motif look and feel,
the JButton.getUI method
would return an instance of MultiButtonUI,
which would handle both a
MotifButtonUI and an AudioButtonUI. 
   


For more information, see
Using
the Multiplexing Look and Feel.

Note:
Most of the Swing API is not thread safe.
For details, see
Threads and Swing,
a section in
The Java Tutorial.",Package
10127,javax.swing.plaf.nimbus,"Provides user interface objects built according to the cross-platform
Nimbus look and feel.

Nimbus uses instances of the Painter interface to paint
components. With each Swing component it associates a foreground and a
background Painter, and there may be several painters for different
component states.

Nimbus allows customizing many of its properties, including painters, by
altering the UIDefaults table. Here's an example:

    UIManager.put(""ProgressBar.tileWidth"", myTileWidth);
    UIManager.put(""ProgressBar[Enabled].backgroundPainter"", myBgPainter);
    UIManager.put(""ProgressBar[Enabled].foregroundPainter"", myFgPainter);

Per-component customization is also possible. When rendering a component,
Nimbus checks its client property named ""Nimbus.Overrides"". The value of this
property should be an instance of UIDefaults. Settings from that table
override the UIManager settings, but for that particular component instance
only. An optional client property, ""Nimbus.Overrides.InheritDefaults"" of type
Boolean, specifies whether the overriding settings should be merged with
default ones (true), or replace them (false). By default they
are merged:

    JProgressBar bar = new JProgressBar();
    UIDefaults overrides = new UIDefaults();
    overrides.put(""ProgressBar.cycleTime"", 330);
    ...
    bar.putClientProperty(""Nimbus.Overrides"", overrides);
    bar.putClientProperty(""Nimbus.Overrides.InheritDefaults"", false);

Colors in Nimbus are derived from a core set of
primary colors. There are also
secondary colors, which are
derived from primary ones, but serve themselves as base colors for other
derived colors. The derivation mechanism allows for runtime customization,
i.e. if a primary or secondary color is changed, all colors that are derived
from it are automatically updated. The method
NimbusLookAndFeel.getDerivedColor(java.lang.String, float, float, float, int, boolean)
may be used to create a derived color.

These classes are designed to be used while the
corresponding LookAndFeel class has been
installed
(UIManager.setLookAndFeel(new XXXLookAndFeel())).
Using them while a different LookAndFeel is installed
may produce unexpected results, including exceptions.
Additionally, changing the LookAndFeel
maintained by the UIManager without updating the
corresponding ComponentUI of any
JComponents may also produce unexpected results,
such as the wrong colors showing up, and is generally not
encouraged.

Note:
Most of the Swing API is not thread safe.
For details, see
Concurrency in Swing,
a section in
The Java Tutorial.",Package
10128,javax.swing.plaf.synth,"Synth is a skinnable look and feel in which all painting is
      delegated. Synth does not provide a default look. In
      order to use Synth you need to specify a
      file, or 
      provide a SynthStyleFactory. Both 
      configuration options require an 
      understanding of the synth architecture, which is described
      below, as well as an understanding of Swing's architecture.
    

      Unless otherwise specified null is not a legal value to any of
      the methods defined in the synth package and if passed in will
      result in a NullPointerException.
      

    Synth

      Each ComponentUI implementation in Synth associates
      itself with one SynthStyle per Region, most
      Components only have one Region and
      therefor only one SynthStyle.
      SynthStyle
      is used to access all style related properties: fonts, colors
      and other Component properties. In addition
      SynthStyles are used to obtain 
      SynthPainters for painting the background, border,
      focus and other portions of a Component. The ComponentUIs obtain
      SynthStyles from a
      SynthStyleFactory.
      A SynthStyleFactory
      can be provided directly by way of 
      SynthLookAndFeel.setStyleFactory(javax.swing.plaf.synth.SynthStyleFactory),
      or indirectly by way of
      SynthLookAndFeel.load(java.io.InputStream, java.lang.Class<?>). The
      following example uses the SynthLookAndFeel.load()
      method to configure a SynthLookAndFeel and sets it
      as the current look and feel:
    


  SynthLookAndFeel laf = new SynthLookAndFeel();
  laf.load(MyClass.class.getResourceAsStream(""laf.xml""), MyClass.class);
  UIManager.setLookAndFeel(laf);
      


      Many JComponents are broken down into smaller
      pieces and identified by the type safe enumeration in
      Region. For example, a JTabbedPane
      consists of a Region for the
      JTabbedPane (Region.TABBED_PANE), the content
      area (Region.TABBED_PANE_CONTENT), the
      area behind the tabs (Region.TABBED_PANE_TAB_AREA), and the
      tabs (Region.TABBED_PANE_TAB). Each
      Region of each
      JComponent will have a
      SynthStyle. This allows 
      you to customize individual pieces of each region of each
      JComponent.
    
      Many of the Synth methods take a SynthContext. This 
      is used to provide information about the current
      Component and includes: the
      SynthStyle associated with the current
      Region, the state of the Component
      as a bitmask (refer to SynthConstants for the valid
      states), and a Region identifying the portion of 
      the Component being painted.
    
      All text rendering by non-JTextComponents is
      delegated to a SynthGraphicsUtils, which is
      obtained using the SynthStyle method
      SynthStyle.getGraphicsUtils(javax.swing.plaf.synth.SynthContext). You can
      customize text rendering 
      by supplying your own SynthGraphicsUtils.

    
Notes on specific components
JTree

      Synth provides a region for the cells of a tree:
      Region.TREE_CELL.  To specify the colors of the
      renderer you'll want to provide a style for the
      TREE_CELL region.  The following illustrates this:

  <style id=""treeCellStyle"">
    <opaque value=""TRUE""/>
    <state>
      <color value=""WHITE"" type=""TEXT_FOREGROUND""/>
      <color value=""RED"" type=""TEXT_BACKGROUND""/>
    </state>
    <state value=""SELECTED"">
      <color value=""RED"" type=""TEXT_FOREGROUND""/>
      <color value=""WHITE"" type=""BACKGROUND""/>
    </state>
  </style>
  <bind style=""treeCellStyle"" type=""region"" key=""TreeCell""/>


      This specifies a color combination of red on white, when
      selected, and white on red when not selected.  To see the
      background you need to specify that labels are not opaque.  The
      following XML fragment does that:

  <style id=""labelStyle"">
    <opaque value=""FALSE""/>
  </style>
  <bind style=""labelStyle"" type=""region"" key=""Label""/>

JList and JTable

      The colors that the renderers for JList and JTable use are
      specified by way of the list and table Regions.  The following
      XML fragment illustrates how to specify red on white, when
      selected, and white on red when not selected:

  <style id=""style"">
    <opaque value=""TRUE""/>
    <state>
      <color value=""WHITE"" type=""TEXT_FOREGROUND""/>
      <color value=""RED"" type=""TEXT_BACKGROUND""/>
      <color value=""RED"" type=""BACKGROUND""/>
    </state>
    <state value=""SELECTED"">
      <color value=""RED"" type=""TEXT_FOREGROUND""/>
      <color value=""WHITE"" type=""TEXT_BACKGROUND""/>
    </state>
  </style>
  <bind style=""style"" type=""region"" key=""Table""/>
  <bind style=""style"" type=""region"" key=""List""/>",Package
10129,javax.swing.table,"Provides classes and interfaces for dealing with
javax.swing.JTable. 
JTable is Swing's grid or tabular view for
constructing user interfaces for tabular data structures inside
an application.  Use this package if you want control over how tables
are constructed, updated, and rendered, as well as how data associated
with the tables are viewed and managed.


Note:
Most of the Swing API is not thread safe.
For details, see
Threads and Swing,
a section in
The Java Tutorial.


Related Documentation

For overviews, tutorials, examples, guides, and tool documentation, please see:

How to Use Tables,
      a section in The Java Tutorial",Package
10130,javax.swing.text,"Provides classes and interfaces that deal with editable
and noneditable text components.  Examples of text components are text
fields and text areas, of which password fields and document editors
are special instantiations.  Features that are supported by this
package include selection/highlighting, editing, style,
and key mapping.


Note:
Most of the Swing API is not thread safe.
For details, see
Threads and Swing,
a section in
The Java Tutorial.

Related Documentation

For overviews, tutorials, examples, guides, and tool documentation, please see:

Using Text Components,
      a section in The Java Tutorial",Package
10131,javax.swing.text.html,"Provides the class HTMLEditorKit and supporting classes
for creating HTML text editors.


Note:
Most of the Swing API is not thread safe.
For details, see
Threads and Swing,
a section in
The Java Tutorial.

Package Specification


      HTML 3.2 Reference Specification - 
      The HTML specification on which HTMLEditorKit is based.",Package
10132,javax.swing.text.html.parser,"Provides the default HTML parser, along with support classes.
As the stream is parsed,
the parser notifies a delegate, 
which must implement
the HTMLEditorKit.ParserCallback interface.


Note:
Most of the Swing API is not thread safe.
For details, see
Threads and Swing,
a section in
The Java Tutorial.",Package
10133,javax.swing.text.rtf,"Provides a class (RTFEditorKit) for creating Rich-Text-Format
text editors.


Note:
Most of the Swing API is not thread safe.
For details, see
Threads and Swing,
a section in
The Java Tutorial.",Package
10134,javax.swing.tree,"Provides classes and interfaces for dealing with
javax.swing.JTree. You use these classes and interfaces if you want
control over how trees are constructed, updated, and rendered, as well
as how data associated with the tree nodes are viewed and managed.


Note:
Most of the Swing API is not thread safe.
For details, see
Threads and Swing,
a section in
The Java Tutorial.


Related Documentation

For overviews, tutorials, examples, guides, and tool documentation, please see:

How to Use Trees,
      a section in The Java Tutorial",Package
10135,javax.swing.undo,"Allows developers to provide support for undo/redo
in applications such as text editors. 


Note:
Most of the Swing API is not thread safe.
For details, see
Threads and Swing,
a section in
The Java Tutorial.

Related Documentation

For overviews, tutorials, examples, guides, and tool documentation, please see:

Implementing Undo and Redo,
      a section in The Java Tutorial",Package
10136,javax.tools,"Provides interfaces for tools which can be invoked from a program,
 for example, compilers.

 These interfaces and classes are required as part of the
 Java™ Platform, Standard Edition (Java SE),
 but there is no requirement to provide any tools implementing them.

 Unless explicitly allowed, all methods in this package might
 throw a NullPointerException if given a
 null argument or if given a
 list or collection containing
 null elements.  Similarly, no method may return
 null unless explicitly allowed.

 This package is the home of the Java programming language compiler framework.  This
 framework allows clients of the framework to locate and run
 compilers from programs.  The framework also provides Service
 Provider Interfaces (SPI) for structured access to diagnostics
 (DiagnosticListener) as well as a file
 abstraction for overriding file access (JavaFileManager and JavaFileObject).  See JavaCompiler for more details on using the SPI.

 There is no requirement for a compiler at runtime.  However, if
 a default compiler is provided, it can be located using the
 ToolProvider, for example:

 JavaCompiler compiler = ToolProvider.getSystemJavaCompiler();
It is possible to provide alternative compilers or tools
 through the service provider
 mechanism.

 For example, if com.vendor.VendorJavaCompiler is a
 provider of the JavaCompiler tool then its jar file
 would contain the file META-INF/services/javax.tools.JavaCompiler.  This file would
 contain the single line:

 com.vendor.VendorJavaCompiler
If the jar file is on the class path, VendorJavaCompiler can be
 located using code like this:

 JavaCompiler compiler = ServiceLoader.load(JavaCompiler.class).iterator().next();",Package
10137,javax.transaction,Contains three exceptions thrown by the ORB machinery during unmarshalling.,Package
10138,javax.transaction.xa,"Provides the API that defines the contract between the transaction 
manager and the resource manager, which allows the transaction 
manager to enlist and delist resource objects (supplied by the 
resource manager driver) in JTA transactions. The driver vendor 
for a specific resource manager provides the implementation of 
this API.",Package
10139,javax.xml,Utility class to contain basic XML values as constants.,Package
10140,javax.xml.bind,"Provides a runtime binding framework for client applications including
        unmarshalling, marshalling, and validation capabilities.

        
JAXBContext is the client-entry point to the runtime binding
        framework.


        Package Specification

JAXB 
                Specification

Related Documentation

        For overviews, tutorials, examples, guides, and tool documentation, 
        please see:
        
The JAXB 
            Website",Package
10141,javax.xml.bind.annotation,"Defines annotations for customizing Java program elements to XML Schema mapping.

        Package Specification
The following table shows the JAXB mapping annotations
           that can be associated with each program element. 



Program Element
JAXB annotation


Package



XmlAccessorOrder


XmlAccessorType


XmlSchema


XmlSchemaType


XmlSchemaTypes


XmlJavaTypeAdapter


XmlJavaTypeAdapters





Class



XmlAccessorOrder


XmlAccessorType


XmlInlineBinaryData


XmlRootElement


XmlType


XmlJavaTypeAdapter





Enum type



XmlEnum


XmlEnumValue (enum constant only)


XmlRootElement


XmlType


XmlJavaTypeAdapter





JavaBean Property/field



XmlElement


XmlElements


XmlElementRef


XmlElementRefs


XmlElementWrapper


XmlAnyElement


XmlAttribute


XmlAnyAttribute


XmlTransient


XmlValue


XmlID


XmlIDREF


XmlList


XmlMixed


XmlMimeType


XmlAttachmentRef


XmlInlineBinaryData


XmlElementDecl (only on method)


XmlJavaTypeAdapter





Parameter



XmlList


XmlAttachmentRef


XmlMimeType


XmlJavaTypeAdapter






Terminology

JavaBean property and field: For the purposes of
          mapping, there is no semantic difference between a field and
          a JavaBean property. Thus, an annotation that can be applied
          to a JavaBean property can always be applied to a
          field. Hence in the Javadoc documentation, for brevity, the
          term JavaBean property or property is used to mean either JavaBean
          property or a field. Where required, both are explicitly
          mentioned.
          
top level class: For the purpose of mapping, there is
          no semantic difference between a top level class and a
          static nested class. Thus, an annotation that can be applied
          to a top level class, can always be applied to a nested
          static class. Hence in the Javadoc documentation, for
          brevity, the term ""top level class"" or just class is used to
          mean either a top level class or a nested static
          class.
          
mapping annotation:A JAXB 2.0 defined program
          annotation based on the JSR 175 programming annotation
          facility.
         Common Usage Constraints
The following usage constraints are defined here since
          they apply to more than annotation:
          
 For a property, a given annotation can be applied to
                 either read or write property but not both. 
 A property name must be different from any other
                 property name in any of the super classes of the
                 class being mapped. 
 A mapped field name or the decapitalized name of a
                 mapped property must be unique within a class. 

Notations
Namespace prefixes
The following namespace prefixes are used in the XML Schema
           fragments in this package.



Prefix
Namespace
Notes


xs
http://www.w3.org/2001/XMLSchema
Namespace of XML Schema namespace


ref
http://ws-i.org/profiles/basic/1.1/xsd
Namespace for swaref schema component


xsi
http://www.w3.org/2001/XMLSchema-instance
XML Schema namespace for instances",Package
10142,javax.xml.bind.annotation.adapters,"XmlAdapter and its spec-defined
        sub-classes to allow arbitrary Java classes to be used with JAXB.

        Package Specification

JAXB
                Specification

Related Documentation

        For overviews, tutorials, examples, guides, and tool documentation,
        please see:
        
The JAXB
            Website",Package
10143,javax.xml.bind.attachment,"This package is implemented by a MIME-based package processor that 
        enables the interpretation and creation of optimized binary data 
        within an MIME-based package format.

        
        Soap MTOM[1], XOP([2][3]) and WS-I AP[4] standardize approaches to 
        optimized transmission of binary datatypes as an attachment.
        To optimally support these standards within a message passing 
        environment, this package enables an integrated solution between 
        a MIME-based package processor and JAXB unmarshall/marshal processes.

        Package Specification

JAXB 
                Specification

Related Standards

[1]SOAP Message Transmission Optimization Mechanism 
[2]XML-binary Optimized Packaging
[3]WS-I Attachments Profile Version 1.0.
[4]Describing Media Content of Binary Data in XML",Package
10144,javax.xml.bind.helpers,"JAXB Provider Use Only: Provides partial default implementations for 
        some of the javax.xml.bind interfaces.

        
        JAXB Providers can extend these classes and implement the abstract 
        methods.
 
        Package Specification

JAXB 
                Specification

Related Documentation

        For overviews, tutorials, examples, guides, and tool documentation, 
        please see:
        
The JAXB 
            Website",Package
10145,javax.xml.bind.util,"Useful client utility classes.

        Package Specification

JAXB 
                Specification

Related Documentation

        For overviews, tutorials, examples, guides, and tool documentation, 
        please see:
        
The JAXB 
            Website",Package
10146,javax.xml.crypto,"Common classes for XML cryptography. This package includes common classes that 
are used to perform XML cryptographic operations, such as generating
an XML signature or encrypting XML data. 

Package Specification



XML-Signature Syntax and Processing: W3C Recommendation


RFC 3275: XML-Signature Syntax and Processing



Since:
1.6",Package
10147,javax.xml.crypto.dom,"DOM-specific classes for the javax.xml.crypto package. 
Only users who are using a DOM-based XML cryptographic implementations (ex: 
XMLSignatureFactory or 
KeyInfoFactory) 
should need to make direct use of this package.

Package Specification



XML-Signature Syntax and Processing: W3C Recommendation


RFC 3275: XML-Signature Syntax and Processing



Since:
1.6",Package
10148,javax.xml.crypto.dsig,"Classes for generating and validating XML digital
signatures. This package includes classes that represent the core elements 
defined in the W3C XML digital signature specification:
XMLSignature,
SignedInfo,
CanonicalizationMethod,
SignatureMethod,
Reference, 
DigestMethod,
XMLObject, 
Manifest,
SignatureProperties, and
SignatureProperty. 
KeyInfo types
are defined in the javax.xml.crypto.dsig.keyinfo subpackage.
XMLSignatureFactory
is an abstract factory that creates 
XMLSignature objects from scratch
or from a pre-existing XML representation, such as a DOM node.
TransformService is a service provider
interface for creating and plugging in implementations of
transform and canonicalization algorithms.

Of primary significance in this package is the 
XMLSignature class,
which allows you to sign and validate an XML digital signature.

Package Specification



XML-Signature Syntax and Processing: W3C Recommendation


RFC 3275: XML-Signature Syntax and Processing



Since:
1.6",Package
10149,javax.xml.crypto.dsig.dom,"DOM-specific classes for the javax.xml.crypto.dsig package. 
Only users who are using a DOM-based XMLSignatureFactory or 
KeyInfoFactory 
should need to make direct use of this package.

Package Specification



XML-Signature Syntax and Processing: W3C Recommendation


RFC 3275: XML-Signature Syntax and Processing



Since:
1.6",Package
10150,javax.xml.crypto.dsig.keyinfo,"Classes for parsing and processing KeyInfo elements and structures. KeyInfo is an optional element
that enables the recipient(s) to obtain the key needed to validate an 
XMLSignature. KeyInfo 
may contain keys, names, certificates and other public key management 
information, such as in-band key distribution or key agreement data. This 
package contains classes representing types defined in the W3C specification 
for XML Signatures, such as 
KeyName,
KeyValue,
RetrievalMethod,
X509Data,
X509IssuerSerial, and
PGPData.
KeyInfoFactory
is an abstract factory that creates KeyInfo objects from scratch.

Package Specification



XML-Signature Syntax and Processing: W3C Recommendation


RFC 3275: XML-Signature Syntax and Processing



Since:
1.6",Package
10151,javax.xml.crypto.dsig.spec,"Parameter classes for XML digital signatures. This package
contains interfaces and classes representing input parameters for the
digest, signature, transform, or canonicalization algorithms used in
the processing of XML signatures. 

Package Specification



XML-Signature Syntax and Processing: W3C Recommendation


RFC 3275: XML-Signature Syntax and Processing


Exclusive XML Canonicalization algorithm: W3C Recommendation


XPath Filter 2.0 Transform Algorithm: W3C Recommendation



Since:
1.6",Package
10152,javax.xml.datatype,"XML/Java Type Mappings.
javax.xml.datatypeAPI provides XML/Java type mappings.
The following XML standards apply:

W3C XML Schema 1.0 Part 2, Section 3.2.7-14
XQuery 1.0 and XPath 2.0 Data Model, xdt:dayTimeDuration
XQuery 1.0 and XPath 2.0 Data Model, xdt:yearMonthDuration





W3C XML Schema Data Type
Java Data Type




xs:date
XMLGregorianCalendar


xs:dateTime
XMLGregorianCalendar


xs:duration
Duration


xs:gDay
XMLGregorianCalendar


xs:gMonth 
XMLGregorianCalendar


xs:gMonthDay
XMLGregorianCalendar


xs:gYear
XMLGregorianCalendar


xs:gYearMonth
XMLGregorianCalendar


xs:time
XMLGregorianCalendar







XQuery 1.0 and XPath 2.0 Data Model
Java Data Type




xdt:dayTimeDuration
Duration


xdt:yearMonthDuration
Duration





                        W3C XML Schema data types that have a ""natural"" mapping to Java types are defined by
                        JSR 31: Java™ Architecture for XML Binding (JAXB) Specification, Binding XML Schema to Java Representations.
                        JAXB defined mappings for XML Schema built-in data types include:
                

xs:anySimpleType
xs:base64Binary
xs:boolean
xs:byte
xs:decimal
xs:double
xs:float
xs:hexBinary
xs:int
xs:integer
xs:long
xs:QName
xs:short
xs:string
xs:unsignedByte
xs:unsignedInt
xs:unsignedShort



Author Jeff Suttor
See W3C XML Schema 1.0 Part 2, Section 3.2.7-14
See XQuery 1.0 and XPath 2.0 Data Model, xdt:dayTimeDuration
See XQuery 1.0 and XPath 2.0 Data Model, xdt:yearMonthDuration
Since 1.5",Package
10153,javax.xml.namespace,"XML Namespace processing.
The following XML standards apply:

XML Schema Part2: Datatypes specification
Namespaces in XML
Namespaces in XML Errata",Package
10154,javax.xml.parsers,"Provides classes allowing the processing of XML documents. Two types
                of plugable parsers are supported:
        

SAX (Simple API for XML)
DOM (Document Object Model)",Package
10155,javax.xml.soap,"Provides the API for creating and building SOAP messages. This package
 is defined in the SOAP with Attachments API for JavaTM (SAAJ) 1.3 specification.
 The API in the javax.xml.soap package allows you to do the
 following: 

create a point-to-point connection to a specified endpoint   
create a SOAP message   
create an XML fragment   
add content to the header of a SOAP message   
add content to the body of a SOAP message   
create attachment parts and add content to them   
access/add/modify parts of a SOAP message   
create/add/modify SOAP fault information   
extract content from a SOAP message   
send a SOAP request-response message   

  
 
 
  

 

  
In addition the APIs in the javax.xml.soap package extend
their  counterparts in the org.w3c.dom package. This means that
the  SOAPPart of a SOAPMessage is also a DOM Level
2 Document, and can be manipulated as such by applications,
tools and libraries that use DOM (see http://www.w3.org/DOM/ for more information).
It is important to note that, while it is possible to use DOM APIs to add
ordinary DOM nodes to a SAAJ tree, the SAAJ APIs are still required to return
SAAJ types when examining or manipulating the tree. In order to accomplish
this the SAAJ APIs (specifically SOAPElement.getChildElements())
are allowed to silently replace objects that are incorrectly typed relative
to SAAJ requirements with equivalent objects of the required type. These
replacements must never cause the logical structure of the tree to change,
so from the perspective of the DOM APIs the tree will remain unchanged. However,
the physical composition of the tree will have changed so that references
to the nodes that were replaced will refer to nodes that are no longer a
part of the tree. The SAAJ APIs are not allowed to make these replacements
if they are not required so the replacement objects will never subsequently
be silently replaced by future calls to the SAAJ API.

What this means in
practical terms is that an application that starts to use SAAJ APIs on a
tree after manipulating it using DOM APIs must assume that the tree has been
translated into an all SAAJ tree and that any references to objects within
the tree that were obtained using DOM APIs are no longer valid. Switching
from SAAJ APIs to DOM APIs is not allowed to cause invalid references and
neither is using SAAJ APIs exclusively. It is only switching from using DOM
APIs on a particular SAAJ tree to using SAAJ APIs that causes the risk of
invalid references.",Package
10156,javax.xml.stream,An error class for reporting factory configuration errors.,Package
10157,javax.xml.stream.events,This is the base event interface for handling markup events.,Package
10158,javax.xml.stream.util,"This is the base class for deriving an XMLStreamReader filter

 This class is designed to sit between an XMLStreamReader and an
 application's XMLStreamReader.",Package
10159,javax.xml.transform,"This package defines the generic APIs for processing transformation
instructions, and performing a transformation from source to result. These
interfaces have no dependencies on SAX or the DOM standard, and try to make as
few assumptions as possible about the details of the source and result of a
transformation. It achieves this by defining
Source and
Result interfaces.

To define concrete classes for the user, the API defines specializations
of the interfaces found at the root level. These interfaces are found in
javax.xml.transform.sax, javax.xml.transform.dom,
and javax.xml.transform.stream.

Creating Objects
The API allows a concrete
TransformerFactory object to be created from
the static function
TransformerFactory.newInstance().

Specification of Inputs and Outputs
This API defines two interface objects called
Source and
Result. In order to pass Source and Result
objects to the interfaces, concrete classes must be used.
Three concrete representations are defined for each of these
objects:
StreamSource and
StreamResult,
SAXSource and
SAXResult, and
DOMSource and
DOMResult. Each of these objects defines
a FEATURE string (which is i the form of a URL), which can be passed into
TransformerFactory.getFeature(java.lang.String) to see if the
given type of Source or Result object is supported. For instance, to test if a
DOMSource and a StreamResult is supported, you can apply the following
test.



TransformerFactory tfactory = TransformerFactory.newInstance();
if (tfactory.getFeature(DOMSource.FEATURE) && tfactory.getFeature(StreamResult.FEATURE)) {
...
}



Qualified Name Representation

Namespaces
present something of a problem area when dealing with XML objects. Qualified
Names appear in XML markup as prefixed names. But the prefixes themselves do
not hold identity. Rather, it is the URIs that they contextually map to that
hold the identity. Therefore, when passing a Qualified Name like ""xyz:foo""
among Java programs, one must provide a means to map ""xyz"" to a namespace.

One solution has been to create a ""QName"" object that holds the
namespace URI, as well as the prefix and local name, but this is not always an
optimal solution, as when, for example, you want to use unique strings as keys
in a dictionary object. Not having a string representation also makes it
difficult to specify a namespaced identity outside the context of an XML
document.

In order to pass namespaced values to transformations,
for 
instance when setting a property or a parameter on a 
Transformer object,
this specification defines that a
String ""qname"" object parameter be passed as two-part string, the namespace URI
enclosed in curly braces ({}), followed by the local name. If the qname has a
null URI, then the String object only contains the local name. An application
can safely check for a non-null URI by testing to see if the first character of
the name is a '{' character.

For example, if a URI and local name were obtained from an element
defined with <xyz:foo xmlns:xyz=""http://xyz.foo.com/yada/baz.html""/>,
then the Qualified Name would be ""{http://xyz.foo.com/yada/baz.html}foo"".
Note that the prefix is lost.

Result Tree Serialization
Serialization of the result tree to a stream can be controlled with
the Transformer.setOutputProperties(java.util.Properties) and the
Transformer.setOutputProperty(java.lang.String, java.lang.String) methods.
These properties only apply to stream results, they have no effect when
the result is a DOM tree or SAX event stream.
Strings that match the XSLT
specification for xsl:output attributes can be referenced from the
OutputKeys class. Other strings can be
specified as well.
If the transformer does not recognize an output key, a
IllegalArgumentException is thrown, unless the
key name is namespace qualified. Output key names
that are namespace qualified are always allowed, although they may be
ignored by some implementations.
If all that is desired is the simple identity transformation of a
source to a result, then TransformerFactory
provides a
TransformerFactory.newTransformer() method
with no arguments. This method creates a Transformer that effectively copies
the source to the result. This method may be used to create a DOM from SAX
events or to create an XML or HTML stream from a DOM or SAX events.  
Exceptions and Error Reporting
The transformation API throw three types of specialized exceptions. A
TransformerFactoryConfigurationError is parallel to
the FactoryConfigurationError, and is thrown
when a configuration problem with the TransformerFactory exists. This error
will typically be thrown when the transformation factory class specified with
the ""javax.xml.transform.TransformerFactory"" system property cannot be found or
instantiated.
A TransformerConfigurationException
may be thrown if for any reason a Transformer can not be created. A
TransformerConfigurationException may be thrown if there is a syntax error in
the transformation instructions, for example when
TransformerFactory.newTransformer(javax.xml.transform.Source) is
called.
TransformerException is a general
exception that occurs during the course of a transformation. A transformer
exception may wrap another exception, and if any of the
TransformerException.printStackTrace()
methods are called on it, it will produce a list of stack dumps, starting from
the most recent. The transformer exception also provides a
SourceLocator object which indicates where
in the source tree or transformation instructions the error occurred.
TransformerException.getMessageAndLocation()
may be called to get an error message with location info, and
TransformerException.getLocationAsString()
may be called to get just the location string.
Transformation warnings and errors are sent to an
ErrorListener, at which point the
application may decide to report the error or warning, and may decide to throw
an Exception for a non-fatal error. The ErrorListener may be set via
TransformerFactory.setErrorListener(javax.xml.transform.ErrorListener) for
reporting errors that have to do with syntax errors in the transformation
instructions, or via
Transformer.setErrorListener(javax.xml.transform.ErrorListener) to report
errors that occur during the transformation. The ErrorListener on both objects
will always be valid and non-null, whether set by the application or a default
implementation provided by the processor.
The default implementation provided by the processor will report all warnings and errors to System.err
and does not throw any Exceptions.
Applications are strongly encouraged to register and use
ErrorListeners that insure proper behavior for warnings and
errors.

Resolution of URIs within a transformation
The API provides a way for URIs referenced from within the stylesheet
instructions or within the transformation to be resolved by the calling
application. This can be done by creating a class that implements the
URIResolver interface, with its one method,
URIResolver.resolve(java.lang.String, java.lang.String), and use this class to
set the URI resolution for the transformation instructions or transformation
with TransformerFactory.setURIResolver(javax.xml.transform.URIResolver) or
Transformer.setURIResolver(javax.xml.transform.URIResolver). The
URIResolver.resolve method takes two String arguments, the URI found in the
stylesheet instructions or built as part of the transformation process, and the
base URI 
against which the first argument will be made absolute if the
absolute URI is required.
The returned Source object must be usable by
the transformer, as specified in its implemented features.",Package
10160,javax.xml.transform.dom,"This package implements DOM-specific transformation APIs.
The DOMSource class allows the
client of the implementation of this API to specify a DOM
Node as the source of the input tree. The model of
how the Transformer deals with the DOM tree in terms of mismatches with the
XSLT data model or
other data models is beyond the scope of this document. Any of the nodes
derived from Node are legal input.
The DOMResult class allows
a Node to be specified to which result DOM nodes will
be appended. If an output node is not specified, the transformer will use
DocumentBuilder.newDocument() to create an
output Document node. If a node is specified, it
should be one of the following: Document,
Element, or
DocumentFragment. Specification of any other node
type is implementation dependent and undefined by this API. If the result is a
Document, the output of the transformation must have
a single element root to set as the document element.
The DOMLocator node may be passed
to TransformerException objects, and
retrieved by trying to cast the result of the
TransformerException.getLocator() method.
The implementation has no responsibility to use a DOMLocator instead of a
SourceLocator (though line numbers and the
like do not make much sense for a DOM), so the result of getLocator must always
be tested with an instanceof.",Package
10161,javax.xml.transform.sax,"This package implements SAX2-specific transformation APIs. It provides
  classes which allow input from ContentHandler
  events, and also classes that produce org.xml.sax.ContentHandler events. It
  also provides methods to set the input source as an
  XMLReader, or to use a
  InputSource as the source. It also allows the
  creation of a XMLFilter, which enables
  transformations to ""pull"" from other transformations, and lets the transformer
  to be used polymorphically as an XMLReader.
The SAXSource class allows the
  setting of an XMLReader to be used for ""pulling""
  parse events, and an InputSource that may be used to
  specify the SAX source.
The SAXResult class allows the
  setting of a ContentHandler to be the receiver of
  SAX2 events from the transformation. 
The SAXTransformerFactory extends
  TransformerFactory to provide factory
  methods for creating TemplatesHandler,
  TransformerHandler, and
  XMLReader instances.
To obtain a SAXTransformerFactory,
  the caller must cast the TransformerFactory
  instance returned from
  TransformerFactory.newInstance(). 

The TransformerHandler interface
  allows a transformation to be created from SAX2 parse events, which is a ""push""
  model rather than the ""pull"" model that normally occurs for a transformation.
  Normal parse events are received through the
  ContentHandler interface, lexical events such as
  startCDATA and endCDATA are received through the
  LexicalHandler interface, and events that signal
  the start or end of disabling output escaping are received via
  ContentHandler.processingInstruction(java.lang.String, java.lang.String), with the
  target parameter being
  Result.PI_DISABLE_OUTPUT_ESCAPING and
  Result.PI_ENABLE_OUTPUT_ESCAPING. If
  parameters, output properties, or other features need to be set on the
  Transformer handler, a Transformer reference
  will need to be obtained from
  TransformerHandler.getTransformer(), and
  the methods invoked from that reference. 

The TemplatesHandler interface
  allows the creation of Templates objects
  from SAX2 parse events. Once the ContentHandler
  events are complete, the Templates object may be obtained from
  TemplatesHandler.getTemplates(). Note that
  TemplatesHandler.setSystemId(java.lang.String) should
  normally be called in order to establish a base system ID from which relative
  URLs may be resolved. 
The
  SAXTransformerFactory.newXMLFilter(javax.xml.transform.Source)
  method allows the creation of a XMLFilter, which
  encapsulates the SAX2 notion of a ""pull"" transformation. The following
  illustrates several transformations chained together. Each filter points to a
  parent XMLReader, and the final transformation is
  caused by invoking XMLReader.parse(org.xml.sax.InputSource) on the final
  reader in the chain.",Package
10162,javax.xml.transform.stax,"Provides for StAX-specific transformation APIs.
                        TODO: better description(s).
                
Package Specification

JSR 173: Streaming API for XML

Related Documentation
For overviews, tutorials, examples, guides, and tool documentation, please see:

TODO: Refer to non-spec documentation



@see XMLStreamReader
@see XMLEventReader",Package
10163,javax.xml.transform.stream,"This package implements stream- and URI- specific transformation APIs.
         
The StreamSource class
         provides methods for specifying InputStream input,
         Reader input, and URL input in the form of strings. Even
         if an input stream or reader is specified as the source,
         StreamSource.setSystemId(java.lang.String) should still
         be called, so that the transformer can know from where it should resolve
         relative URIs. The public identifier is always optional: if the application
         writer includes one, it will be provided as part of the
         SourceLocator information.
The StreamResult class
         provides methods for specifying OutputStream,
         Writer, or an output system ID, as the output of the
         transformation result.
Normally streams should be used rather than readers or writers, for
         both the Source and Result, since readers and writers already have the encoding
         established to and from the internal Unicode format. However, there are times
         when it is useful to write to a character stream, such as when using a
         StringWriter in order to write to a String, or in the case of reading source
         XML from a StringReader.",Package
10164,javax.xml.validation,"This package provides an API for validation of XML documents.  Validation is the process of verifying
                    that an XML document is an instance of a specified XML schema.  An XML schema defines the
                    content model (also called a grammar or vocabulary) that its instance documents
                    will represent.
        

            There are a number of popular technologies available for creating an XML schema. Some of the most
            popular include:
                

Document Type Definition (DTD) - XML's built-in schema language.
W3C XML Schema (WXS) - an object-oriented XML schema
                    language. WXS also provides a type system for constraining the character data of an XML document.
                    WXS is maintained by the World Wide Web Consortium (W3C) and is a W3C
                    Recommendation (that is, a ratified W3C standard specification).
RELAX NG (RNG) - a pattern-based,
                    user-friendly XML schema language. RNG schemas may also use types to constrain XML character data.
                    RNG is maintained by the Organization for the Advancement of
                    Structured Information Standards (OASIS) and is both an OASIS and an
                    ISO (International Organization for Standardization) standard.
Schematron - a rules-based XML schema
                language. Whereas DTD, WXS, and RNG are designed to express the structure of a content model,
                Schematron is designed to enforce individual rules that are difficult or impossible to express
                with other schema languages. Schematron is intended to supplement a schema written in
                structural schema language such as the aforementioned. Schematron is in the process
                of becoming an ISO standard.


                    Previous versions of JAXP supported validation as a feature of an XML parser, represented by
                    either a SAXParser or DocumentBuilder instance.
        

                    The JAXP validation API decouples the validation of an instance document from the parsing of an
                    XML document. This is advantageous for several reasons, some of which are:
                

Support for additional schema langauges. As of JDK 1.5, the two most
                        popular JAXP parser implementations, Crimson and Xerces, only support a subset of the available
                        XML schema languages. The Validation API provides a standard mechanism through which applications
                        may take of advantage of specialization validation libraries which support additional schema
                        languages.
Easy runtime coupling of an XML instance and schema. Specifying the location
                        of a schema to use for validation with JAXP parsers can be confusing. The Validation API makes this
                        process simple (see example below).


Usage example. The following example demonstrates validating
            an XML document with the Validation API (for readability, some exception handling is not shown):
                

            
    // parse an XML document into a DOM tree
    DocumentBuilder parser = DocumentBuilderFactory.newInstance().newDocumentBuilder();
    Document document = parser.parse(new File(""instance.xml""));

    // create a SchemaFactory capable of understanding WXS schemas
    SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI);

    // load a WXS schema, represented by a Schema instance
    Source schemaFile = new StreamSource(new File(""mySchema.xsd""));
    Schema schema = factory.newSchema(schemaFile);

    // create a Validator instance, which can be used to validate an instance document
    Validator validator = schema.newValidator();

    // validate the DOM tree
    try {
        validator.validate(new DOMSource(document));
    } catch (SAXException e) {
        // instance document is invalid!
    }


                    The JAXP parsing API has been integrated with the Validation API. Applications may create a Schema with the validation API
                    and associate it with a DocumentBuilderFactory or a SAXParserFactory instance
                    by using the DocumentBuilderFactory.setSchema(Schema) and SAXParserFactory.setSchema(Schema)
                    methods. You should not both set a schema and call setValidating(true) on a parser factory. The former technique
                    will cause parsers to use the new validation API; the latter will cause parsers to use their own internal validation
                    facilities. Turning on both of these options simultaneously will cause either redundant behavior or error conditions.",Package
10165,javax.xml.ws,This package contains the core JAX-WS APIs.,Package
10166,javax.xml.ws.handler,This package defines APIs for message handlers.,Package
10167,javax.xml.ws.handler.soap,This package defines APIs for SOAP message handlers.,Package
10168,javax.xml.ws.http,This package defines APIs specific to the HTTP binding.,Package
10169,javax.xml.ws.soap,This package defines APIs specific to the SOAP binding.,Package
10170,javax.xml.ws.spi,This package defines SPIs for JAX-WS.,Package
10171,javax.xml.ws.spi.http,"Provides HTTP SPI that is used for portable deployment of JAX-WS
  web services in containers(for e.g. servlet containers). This SPI
  is not for end developers but provides a way for the container
  developers to deploy JAX-WS services portably.

  
  The portable deployment is done as below:
  
Container creates Endpoint objects for an
  application. The necessary information to create Endpoint objects
  may be got from web service deployment descriptor files.
Container needs to create HttpContext
  objects for the deployment. For example, a HttpContext could be
  created using servlet configuration(for e.g url-pattern) for the
  web service in servlet container case.
Then publishes all the endpoints using
  Endpoint.publish(HttpContext). During publish(),
  JAX-WS runtime registers a HttpHandler
  callback to handle incoming requests or
  HttpExchange objects. The HttpExchange
  object encapsulates a HTTP request and a response.
  

  Container                               JAX-WS runtime
  ---------                               --------------
  1. Creates Invoker1, ... InvokerN
  2. Provider.createEndpoint(...)     --> 3. creates Endpoint1
     configures Endpoint1
     ...
  4. Provider.createEndpoint(...)     --> 5. creates EndpointN
     configures EndpointN
  6. Creates ApplicationContext
  7. creates HttpContext1, ... HttpContextN
  8. Endpoint1.publish(HttpContext1)  --> 9. creates HttpHandler1
                                          HttpContext1.setHandler(HttpHandler1)
     ...
 10. EndpointN.publish(HttpContextN)  --> 11. creates HttpHandlerN
                                         HttpContextN.setHandler(HttpHandlerN)

  

  The request processing is done as below(for every request):
  
  Container                               JAX-WS runtime
  ---------                               --------------
  1. Creates a HttpExchange
  2. Gets handler from HttpContext
  3. HttpHandler.handle(HttpExchange) --> 4. reads request from HttpExchange
                                      

  
  The portable undeployment is done as below:
  
  Container
  ---------
  1. @preDestroy on instances
  2. Endpoint1.stop()
  ...
  3. EndpointN.stop()",Package
10172,javax.xml.ws.wsaddressing,This package defines APIs related to WS-Addressing.,Package
10173,javax.xml.xpath,"This package provides an object-model neutral API for the
evaluation of XPath expressions and access to the evaluation
environment.

The following XML standards apply:

XML Path Language (XPath) Version 1.0


XPath Overview
The XPath language provides a simple, concise syntax for selecting
nodes from an XML document. XPath also provides rules for converting a
node in an XML document object model (DOM) tree to a boolean, double,
or string value. XPath is a W3C-defined language and an official W3C
recommendation; the W3C hosts the XML Path Language (XPath) Version
1.0 specification.

XPath started in life in 1999 as a supplement to the XSLT and
XPointer languages, but has more recently become popular as a
stand-alone language, as a single XPath expression can be used to
replace many lines of DOM API code.

XPath Expressions
An XPath expression is composed of a location
path and one or more optional predicates. Expressions
may also include XPath variables.

The following is an example of a simple XPath expression:

/foo/bar

This example would select the <bar> element in
an XML document such as the following:

<foo>
<bar/>
</foo>

The expression /foo/bar is an example of a location
path. While XPath location paths resemble Unix-style file system
paths, an important distinction is that XPath expressions return
all nodes that match the expression. Thus, all three
<bar> elements in the following document would be
selected by the /foo/bar expression:

<foo>
<bar/>
<bar/>
<bar/>
</foo>

A special location path operator, //, selects nodes at
any depth in an XML document. The following example selects all
<bar> elements regardless of their location in a
document:

//bar

A wildcard operator, *, causes all element nodes to be selected.
The following example selects all children elements of a
<foo> element:

/foo/*

In addition to element nodes, XPath location paths may also address
attribute nodes, text nodes, comment nodes, and processing instruction
nodes. The following table gives examples of location paths for each
of these node types:


Location Path
Description



/foo/bar/@id

Selects the attribute id of the <bar> element



/foo/bar/text()

Selects the text nodes of the <bar> element. No
distinction is made between escaped and non-escaped character data.



/foo/bar/comment()

Selects all comment nodes contained in the <bar> element.



/foo/bar/processing-instruction()

Selects all processing-instruction nodes contained in the
<bar> element.



Predicates allow for refining the nodes selected by an XPath
location path. Predicates are of the form
[expression]. The following example selects all
<foo> elements that contain an include
attribute with the value of true:

//foo[@include='true']

Predicates may be appended to each other to further refine an
expression, such as:

//foo[@include='true'][@mode='bar']

Using the XPath API

The following example demonstrates using the XPath API to select one
or more nodes from an XML document:

XPath xpath = XPathFactory.newInstance().newXPath();
String expression = ""/widgets/widget"";
InputSource inputSource = new InputSource(""widgets.xml"");
NodeList nodes = (NodeList) xpath.evaluate(expression, inputSource, XPathConstants.NODESET);

XPath Expressions and Types
While XPath expressions select nodes in the XML document, the XPath
API allows the selected nodes to be coalesced into one of the
following other data types:

Boolean
Number
String

The desired return type is specified by a QName parameter in method call used to evaluate
the expression, which is either a call to
XPathExpression.evalute(...) or to one of the
XPath.evaluate(...) convenience methods. The allowed
QName values are specified as constants in the XPathConstants class; they are:

XPathConstants.NODESET
XPathConstants.NODE
XPathConstants.STRING
XPathConstants.BOOLEAN
XPathConstants.NUMBER

When a Boolean return type is requested,
Boolean.TRUE is returned if one or more nodes were
selected; otherwise, Boolean.FALSE is returned.
The String return type is a convenience for retrieving
the character data from a text node, attribute node, comment node, or
processing-instruction node. When used on an element node, the value
of the child text nodes is returned.

The Number return type attempts to coalesce the text
of a node to a double data type.

XPath Context
XPath location paths may be relative to a particular node in the
document, known as the context. Consider the following
XML document:

<widgets>
<widget>
<manufacturer/>
<dimensions/>
</widget>
</widgets>

The <widget> element can be selected with the
following XPath API code:

// parse the XML as a W3C Document
DocumentBuilder builder = DocumentBuilderFactory.newInstance().newDocumentBuilder();
Document document = builder.parse(new File(""/widgets.xml""));

XPath xpath = XPathFactory.newInstance().newXPath();
String expression = ""/widgets/widget"";
Node widgetNode = (Node) xpath.evaluate(expression, document, XPathConstants.NODE);

With a reference to the <widget> element, a
relative XPath expression can now written to select the
<manufacturer> child element:

XPath xpath = XPathFactory.newInstance().newXPath();
String expression = ""manufacturer"";
Node manufacturerNode = (Node) xpath.evaluate(expression, widgetNode, XPathConstants.NODE);


Author Ben Galbraith
Author Norman Walsh
Author Jeff Suttor
See XML Path Language (XPath) Version 1.0
Since 1.5",Package
10174,org.ietf.jgss,"This package presents a framework that allows application developers to
    make use of security services like authentication, data integrity and
    data confidentiality from a variety of underlying security mechanisms
    like Kerberos, using a unified API. The security mechanisms that an
    application can
    chose to use are identified with unique object identifiers. One example 
    of such a mechanism is the Kerberos v5 GSS-API mechanism (object
    identifier 1.2.840.113554.1.2.2). This mechanism is available through
    the default instance of the GSSManager class.

    The GSS-API is defined in a language independent way in 
    RFC 2743. The Java
    language bindings are defined in 
    RFC 2853

    An application starts out by instantiating a GSSManager
    which then serves as a factory for a security context. An application
    can use specific principal names and credentials that are also created
    using the GSSManager; or it can instantiate a
    context with system defaults. It then goes through a context
    establishment loop. Once a context is established with the
    peer, authentication is complete. Data protection such as integrity
    and confidentiality can then be obtained from this context.

    The GSS-API does not perform any communication with the peer. It merely 
    produces tokens that the application must somehow transport to the
    other end.
Credential Acquisition

    The GSS-API itself does not dictate how an underlying mechanism
    obtains the credentials that are needed for authentication. It is
    assumed that prior to calling the GSS-API, these credentials are
    obtained and stored in a location that the mechanism provider is
    aware of. However, the default model in the Java platform will be
    that mechanism providers must obtain credentials only from the private
    or public credential sets associated with the
    Subject in the
    current access control context.  The Kerberos v5  
    mechanism will search for the required INITIATE and ACCEPT credentials 
    (KerberosTicket and
     KerberosKey) in
    the private credential set where as some other mechanism might look
    in the public set or in both.  If the desired credential is not
    present in the appropriate sets of the current Subject, the GSS-API
    call must fail.

    This model has the advantage that credential management
    is simple and predictable from the applications point of view.  An
    application, given the right permissions, can purge the credentials in
    the Subject or renew them using standard Java API's.  If it purged
    the credentials, it would be sure that the JGSS mechanism would fail,
    or if it renewed a time based credential it would be sure that a JGSS
    mechanism would succeed.

    This model does require that a JAAS login be performed in order to
    authenticate and populate a Subject that the JGSS mechnanism can later 
    utilize. However, applications have the ability to relax this
    restiction by means of a system property:
    javax.security.auth.useSubjectCredsOnly. By default
    this system property will be assumed to be true (even when
    it is unset) indicating that providers must only use the credentials
    that are present in the current Subject. However, if this property is
    explicitly set to false by the application, then it indicates that
    the provider is free to use any credentials cache of its choice. Such
    a credential cache might be a disk cache, an in-memory cache, or even
    just the current Subject itself.


Related Documentation

For an online tutorial on using Java GSS-API, please see
Introduction to JAAS and Java GSS-API.",Package
10175,org.omg.CORBA,"Provides the mapping of the OMG CORBA APIs to the JavaTM
programming language, including the class ORB, which is implemented
so that a programmer can use it as a fully-functional Object Request Broker
(ORB).

For a precise list of supported sections of official CORBA specifications with which 
the Java[TM] Platform, Standard Edition 6 complies, see Official Specifications for CORBA support in 
Java[TM] SE 6.


General Information
The information in this section is information relevant to someone who 
compiles Interface Definition Language (IDL) files and uses the
ORB to write clients and servers.

The classes and interfaces described in this section can be put into 
four groups: ORB classes, Exceptions, Helper classes,
and Holder classes.


The ORB Class
An ORB handles (or brokers) method invocations between a client and
the method's implementation on a server. Because the client and server
may be anywhere on a network, and because the invocation and implementation
may be written in different programming languages, an ORB does a great
deal of work behind the scenes to accomplish this communication.

Most of what an ORB does is completely transparent to the user, and a major
portion of the CORBA package consists of classes used by the ORB
behind the scenes. The result is that most programmers will use only a
small part of this package directly. In fact, most programmers will use
only a few methods from the ORB class, some exceptions, and 
occasionally,
a holder class. 

ORB Methods
Before an application can enter the CORBA environment, it must first: 


Be initialized into the ORB and possibly the object adapter (POA) environments.
Get references to ORB object (for use in future ORB operations) 
and perhaps other objects (including the root POA or some Object Adapter objects). 

The following operations are provided to initialize applications and obtain
 the appropriate object references:
 

Operations providing access to the ORB, which are discussed in this
 section.
 Operations providing access to Object Adapters, Interface Repository, 
 Naming Service, and other Object Services. These operations are described 
 in Other Classes.
 

When an application requires a CORBA environment it needs a mechanism to 
get an ORB object reference and possibly an OA object reference 
(such as the root POA). This serves two purposes. First, it initializes 
an application into the ORB and OA environments. Second, it returns the 
ORB object reference and the OA object reference to the application 
for use in future ORB and OA operations. 

In order to obtain an ORB object reference, applications call 
the ORB.init operation. The parameters to the call can comprise an 
identifier for the ORB for which the object reference is required,
 and an arg_list, which is used to allow environment-specific data to be 
 passed into the call. 

These are the ORB methods
 that provide access to the ORB:


init()

init(String [] args, Properties props)

init(Applet app, Properties props)

Using the init() method without parameters initiates 
a singleton ORB,  which can only
give typecode creation anys needed in code generated
in Helper classes by idlj.

Applications require a portable means by which to obtain their 
initial object references. References are required for the root 
POA, POA Current, Interface Repository, and various Object Services 
instances.  The functionality required by the application is similar
 to that provided by the Naming Service. However, the OMG does not 
 want to mandate that the Naming Service be made available to all 
 applications in order that they may be portably initialized. 
 Consequently, the operations shown in this section provide a 
 simplified, local version of the Naming Service that applications 
 can use to obtain a small, defined set of object references which 
 are essential to its operation. Because only a small well-defined 
 set of objects are expected with this mechanism, the naming context
 can be flattened to be a single-level name space. This simplification
 results in only two operations being defined to achieve the functionality
  required.
  
Initial references are obtained via two operations provided in 
the ORB object interface, providing facilities to list and 
resolve initial object references.  These are:


resolve_initial_references(String name)

list_initial_services()

register_initial_reference(String id, 
org.omg.CORBA.Object obj)

An example that uses some of these methods is 
Getting Started with Java IDL.


Exceptions
Exceptions in Java IDL are similar to those in any code written in the
Java programming language. If a method is defined to throw an exception,
then any code using that method must have a try/catch
block and handle that exception when it is thrown.

The documentation on Java
IDL exceptions has more information and explains the difference between
system exceptions and user-defined exceptions.

The following is a list of the system exceptions (which are unchecked
exceptions inheriting through 
org.omg.CORBA.SystemException from
java.lang.RuntimeException) that are defined in the package 
org.omg.CORBA:

        BAD_CONTEXT
        BAD_INV_ORDER
        BAD_OPERATION
        BAD_PARAM
        BAD_TYPECODE
        COMM_FAILURE
        DATA_CONVERSION
        FREE_MEM
        IMP_LIMIT
        INITIALIZE
        INTERNAL
        INTF_REPOS
        INVALID_TRANSACTION
        INV_FLAG
        INV_IDENT
        INV_OBJREF
        INV_POLICY
        MARSHAL
        NO_IMPLEMENT
        NO_MEMORY
        NO_PERMISSION
        NO_RESOURCES
        NO_RESPONSE
        OBJECT_NOT_EXIST
        OBJ_ADAPTER
        PERSIST_STORE
        TRANSACTION_REQUIRED
        TRANSACTION_ROLLEDBACK
        TRANSIENT
        UNKNOWN


The following is a list of user-defined exceptions defined in the package
org.omg.CORBA.

        Bounds
        UnknownUserException
        WrongTransaction 
        PolicyError

Subpackages
There are some packages inside the CORBA package with
""Package"" as part of their names. These packages are generally quite small
because all they do is provide exceptions or classes for use by interfaces
and classes in the CORBA package.

For example, the package 
org.omg.CORBA.TypeCodePackage contains
two exceptions thrown by methods in the class TypeCode. These
exceptions are:


BadKind

Bounds

The package 
org.omg.CORBA.ORBPackage contains two exceptions:


InvalidName

InconsistentTypeCode

Another package that is a subpackage of CORBA is the 
portable package.  It 
provides a set of ORB APIs that makes it 
possible for code generated by one vendor's IDL compiler to run
on another vendor's ORB. 





Holder classes
Support for out and inout parameter passing modes requires the use of 
additional  holder  
classes. Because the Java programming language does not support out or 
inout parameters, holder classes are needed as a means of passing a parameter
that can be modified.   To support portable stubs and skeletons, holder classes also implement
 the org.omg.CORBA.portable.Streamable
 interface.
 
 Holder classes are named by appending ""Holder"" to the name of the type.
 The name of the type refers to its name in the Java programming language.  For
 example, a holder class for the interface named Account in the Java programming
 language would be named AccountHolder.


Holder classes are available for all of the basic IDL
 datatypes in the org.omg.CORBA package.  So, for example, 
  there are already-defined classes for LongHolder, ShortHolder,
 FloatHolder, and so on.  Classes are also generated for 
 all named user-defined IDL types except those defined by typedefs. 
 (Note that in this context user defined includes types that are 
 defined in OMG specifications such as those for the Interface
  Repository, and other OMG services.) 


Each holder class has:


a constructor from an instance
a default constructor
a public instance member, value which is the typed value. 
a method for reading an input stream and assigning the contents to the 
type's value field
a method for writing the value of the value field to an output stream
a method for getting the typecode of the type

The default constructor sets the value field to the default value for the 
type as defined by the Java language: 


false for boolean
0 for numeric and char types
null for strings and object references


As an example, if the interface Account, defined in OMG IDL,
were mapped to the Java programming language, the following holder class
would be generated:

public final class AccountHolder implements 
    org.omg.CORBA.portable.Streamable
{
  // field that holds an Account object
  public Account value = null;

  // default constructor
  public AccountHolder ()
  {
  }
  
  // creates a new AccountHolder from initialValue
  public AccountHolder (Account initialValue)
  {
    value = initialValue;
  }
  
  // reads the contents of i and assigns the contents to value
  public void _read (org.omg.CORBA.portable.InputStream i)
  {
    value = AccountHelper.read (i);
  }

  // writes value to o
  public void _write (org.omg.CORBA.portable.OutputStream o)
  {
    AccountHelper.write (o, value);
  }
 
  // returns the typecode for Account
  public org.omg.CORBA.TypeCode _type ()
  {
    return AccountHelper.type ();
  }

}

For more information on Holder classes, see Chapter 1.4, Mapping for
Basic Types in the 
OMG IDL to Java Language Mapping. The Holder classes defined 
in the package org.omg.CORBA are:

     AnyHolder
     AnySeqHolder
     BooleanHolder
     BooleanSeqHolder
     ByteHolder
     CharHolder
     CharSeqHolder
     CurrentHolder
     DoubleHolder
     DoubleSeqHolder
     FixedHolder
     FloatHolder
     FloatSeqHolder
     IntHolder
     LongHolder
     LongLongSeqHolder
     LongSeqHolder
     ObjectHolder
     OctetSeqHolder
     ParameterModeHolder
     PolicyErrorHolder
     PolicyListHolder
     PrincipalHolder
     ServiceInformationHolder
     ShortHolder
     ShortSeqHolder
     StringHolder
     StringSeqHolder
     TypeCodeHolder
     ULongLongSeqHolder
     ULongSeqHolder
     UnknownUserExceptionHolder
     UShortSeqHolder
     ValueBaseHolder
     WCharSeqHolder
     WrongTransactionHolder
     WStringSeqHolder


Helper Classes 
Helper files supply several static methods needed to manipulate the type.
 These include:
 

Any insert and extract operations for the type
 getting the repository id
 getting the typecode
 reading and writing the type from and to a stream
 implement the ValueHelper interface (if it is  a user-defined
   value type)
 
The helper class for a mapped IDL interface or abstract interface
 also include narrow operation(s). The static narrow method allows 
 an org.omg.CORBA.Object to be narrowed to the object reference 
 of a more specific type. The IDL exception CORBA.BAD_PARAM 
 is thrown if the narrow fails because the object reference does not 
 support the requested type. A different system exception is raised 
 to indicate other kinds of errors. Trying to narrow a null will always
  succeed with a return value of null. Generally, the only helper method an application programmer uses is
the narrow method.  The other methods are normally used behind
the scenes and are transparent to the programmer.

Helper classes
fall into two broad categories, helpers for value types and
helpers for non value types. Because all of the helper 
classes in one category
provide the same methods, one generic explanation of each 
category of helper classes is presented here.


When OMG IDL is mapped to the Java programming language, 
a ""helper"" class is generated for each user-defined type.
This generated class will have the name of the user-defined type with
the suffix Helper appended.  For example, if the
interface Account is defined in OMG IDL, the
idlj compiler will automatically generate a class named
AccountHelper.  The AccountHelper class
will contain the static methods needed for manipulating instances of the type,
in this case, Account objects. 



The narrow Method
When an object is the return value for a method, it is returned in the
form of a generic object, either an org.omg.CORBA.Object object
or a java.lang.Object object. This object must be cast to its
more specific type before it can be operated on.  For example, an
Account object will be returned as a generic object and must
be narrowed to an Account object so that Account
methods may be called on it.

The narrow method has two forms, one that takes an
org.omg.CORBA.Object object and one that takes a
java.lang.Object object. Whether the interface is abstract or
not determines which narrow method its helper class will provide.
The helper class for an interface
that is not abstract will have a narrow method that takes a CORBA
object, whereas the narrow method for an interface that is abstract 
will
take an object in the Java programming language.  The helper class for a
non-abstract interface that has at least one abstract base interface will provide
both versions of the narrow method.
The Hello World 
tutorial uses a narrow method that looks 
like this:


        // create and initialize the ORB
        ORB orb = ORB.init(args, null);

        // get the root naming context
        org.omg.CORBA.Object objRef = 
            orb.resolve_initial_references(""NameService"");
        // Use NamingContextExt instead of NamingContext. This is 
        // part of latest Inter-Operable naming Service.  
        NamingContextExt ncRef = NamingContextExtHelper.narrow(objRef);
 
        // resolve the Object Reference in Naming
        String name = ""Hello"";
        helloImpl = HelloHelper.narrow(ncRef.resolve_str(name));


Example of a Basic Helper Class
A basic helper class, for purposes of this explanation, is one with
the methods that are provided by every helper class, plus a narrow 
method if the type defined in OMG IDL maps to an interface in the Java
programming language.  Types that are not value types will have a basic
helper class generated for them.

For example, assuming that the interface Account is not a
value type IDL type and is also not an abstract interface and has no
abstract base interfaces, its AccountHelper class will look
like this:

abstract public class AccountHelper
{
  private static String  _id = ""IDL:Account:1.0"";

  // inserts an Account object into an Any object
  public static void insert (org.omg.CORBA.Any a, Account that)
  {
    org.omg.CORBA.portable.OutputStream out = a.create_output_stream ();
    a.type (type ());
    write (out, that);
    a.read_value (out.create_input_stream (), type ());
  }

  // extracts an Account object from an Any object
  public static Account extract (org.omg.CORBA.Any a)
  {
    return read (a.create_input_stream ());
  }

  
  private static org.omg.CORBA.TypeCode __typeCode = null;
  // gets the typecode for this type
  synchronized public static org.omg.CORBA.TypeCode type ()
  {
    if (__typeCode == null)
    {
      __typeCode = org.omg.CORBA.ORB.init ().create_interface_tc (AccountHelper.id (), ""Account"");
    }
    return __typeCode;
  }

  // gets the repository id for this type
  public static String id ()
  {
    return _id;
  }

  // reads an Account object from an input stream
  public static Account read (org.omg.CORBA.portable.InputStream istream)
  {
    return narrow (istream.read_Object (_AccountStub.class));
  }

  // writes an Account object to an outputstream
  public static void write (org.omg.CORBA.portable.OutputStream ostream, Account value)
  {
    ostream.write_Object ((org.omg.CORBA.Object) value);
  }

  // converts (narrows) an Object to an Account object
  public static Account narrow (org.omg.CORBA.Object obj)
  {
    if (obj == null)
      return null;
    else if (obj instanceof Account)
      return (Account)obj;
    else if (!obj._is_a (id ()))
      throw new org.omg.CORBA.BAD_PARAM ();
    else
    {
      org.omg.CORBA.portable.Delegate delegate = ((org.omg.CORBA.portable.ObjectImpl)obj)._get_delegate ();
      _AccountStub stub = new _AccountStub ();
      stub._set_delegate(delegate);
      return stub;
    }
  }

}


Value Type Helper Classes
A helper class for a value type includes different renderings of
the same methods generated for non-value type methods. The main difference
 is that value types are types that can be
passed by value as parameters or return values of a method, which means that
they must be serializable.
Assuming that Address is a value type, the
AddressHelper class will look like this:

abstract public class AddressHelper
{
  private static String  _id = ""IDL:Address:1.0"";

  // same as for non-value type
  public static void insert (org.omg.CORBA.Any a, Address that)
  {
    org.omg.CORBA.portable.OutputStream out = a.create_output_stream ();
    a.type (type ());
    write (out, that);
    a.read_value (out.create_input_stream (), type ());
  }

  // same as for non-value type
  public static Address extract (org.omg.CORBA.Any a)
  {
    return read (a.create_input_stream ());
  }

  private static org.omg.CORBA.TypeCode __typeCode = null;
  private static boolean __active = false;
  
  // getting the typecode for the type
  synchronized public static org.omg.CORBA.TypeCode type ()
  {
    if (__typeCode == null)
    {
      synchronized (org.omg.CORBA.TypeCode.class)
      {
        if (__typeCode == null)
        {
          if (__active)
          {
            return org.omg.CORBA.ORB.init().create_recursive_tc ( _id );
          }
          __active = true;
          org.omg.CORBA.ValueMember[] _members0 = new org.omg.CORBA.ValueMember[0];
          org.omg.CORBA.TypeCode _tcOf_members0 = null;
          __typeCode = org.omg.CORBA.ORB.init ().create_value_tc (_id, ""Address"", org.omg.CORBA.VM_NONE.value, null, _members0);
          __active = false;
        }
      }
    }
    return __typeCode;
  }

  // same as for non-value type
  public static String id ()
  {
    return _id;
  }

  // reads a serializable instance of Address from the given input stream
  public static Address read (org.omg.CORBA.portable.InputStream istream)
  {
    return (Address)((org.omg.CORBA_2_3.portable.InputStream) istream).read_value (id ());
  }

  // writes a serializable instance of Address to the given output stream
  public static void write (org.omg.CORBA.portable.OutputStream ostream, Address value)
  {
    ((org.omg.CORBA_2_3.portable.OutputStream) ostream).write_value (value, id ());
  }


}

The Helper classes defined in the package org.omg.CORBA are:

     AnySeqHelper
     BooleanSeqHelper
     CharSeqHelper
     CompletionStatusHelper
     CurrentHelper
     DefinitionKindHelper
     DoubleSeqHelper
     FieldNameHelper
     FloatSeqHelper
     IdentifierHelper
     IDLTypeHelper
     LongLongSeqHelper
     LongSeqHelper
     NameValuePairHelper
     ObjectHelper
     OctetSeqHelper
     ParameterModeHelper
     PolicyErrorCodeHelper
     PolicyErrorHelper
     PolicyHelper
     PolicyListHelper
     PolicyTypeHelper
     RepositoryIdHelper
     ServiceDetailHelper
     ServiceInformationHelper
     SetOverrideTypeHelper
     ShortSeqHelper
     StringSeqHelper
     StringValueHelper
     StructMemberHelper
     ULongLongSeqHelper
     ULongSeqHelper
     UnionMemberHelper
     UnknownUserExceptionHelper
     UShortSeqHelper
     ValueBaseHelper
     ValueMemberHelper
     VersionSpecHelper
     VisibilityHelper
     WCharSeqHelper
     WrongTransactionHelper
     WStringSeqHelper
     WStringValueHelper




Other Classes
The other classes and interfaces in the CORBA package, which are
used behind the scenes, can be put into four groups. Three of the groups
are used with requests in some capacity, and the fourth group, concerning
the Interface Repository, is a category by itself.

Classes Created by an ORB
The first group contains classes that are created by an ORB and contain
information used in request operations. 


TCKind -- indicates the kind (datatype) for a TypeCode
object


TypeCode -- indicates a datatype and possibly other information


Any -- contains a value and its typecode


NamedValue -- contains a name, an Any object, and an
argument mode flag. NamedValue objects contain information about
method arguments, method return values, or a context.


ContextList -- a list of strings that describe the contexts that
need to be resolved and sent with an invocation


ExceptionList -- a list of TypeCodes for exceptions that
may be thrown by a method


Environment -- a container for the exception thrown during a method
invocation


Context -- a list of NamedValue objects used to pass
auxiliary information from client to server


NVList -- a list of NamedValue objects, used to pass
arguments or get results


Classes That Deal with Requests
The second group of classes deals with requests:


Object -- the base class for all CORBA object references


Request -- the main class in the DII, which contains methods for
adding arguments to the request, for accessing information about the method
being invoked (the method name, its arguments, exceptions it throws, and
so on), and for making invocations on the request


DynamicImplementation -- the base class for server implementations
using the DSI. It has the method invoke, which is used by an 
implementation
of this class to determine the state of a ServerRequest object
and to set its result or exception


ServerRequest -- captures the explicit state of a request for
the Dynamic Skeleton Interface


Interfaces That Serve as Constants
The third group contains interfaces that serve as constants. The IDL-to-Java
mapping mandates that IDL enums are mapped to a Java class with the enumerated
values represented as public static final fields in that class (e.g. 
DefinitionKind).
On the other hand IDL constants defined outside of an IDL interface are
mapped to a Java interface for each constant.

This is why several interfaces in the org.omg.CORBA package
consist of a single field, value, which is a short. This
field is a constant used for such things as an error code or value modifier.
For example, the value field of the interface BAD_POLICY
is one of the possible reasons for the exception PolicyError to
be thrown. To specify this error code, you would use BAD_POLICY.value.

The exception PolicyError uses the value field of
the following interfaces as its possible error codes.


BAD_POLICY

BAD_POLICY_TYPE

BAD_POLICY_VALUE

UNSUPPORTED_POLICY

UNSUPPORTED_POLICY_VALUE

The method TypeCode.type_modifier returns the value field
of one of the following interfaces. The VM in the names of these
interfaces stands for ""value modifier.""


VM_NONE

VM_ABSTRACT

VM_CUSTOM

VM_TRUNCATABLE

The following constants are returned by a ValueMember object's
access method to denote the visibility of the ValueMember object.


PRIVATE_MEMBER

PUBLIC_MEMBER

These flags, used in NamedValue objects or as parameters to methods,
are defined in the following interfaces:


ARG_IN

ARG_INOUT

ARG_OUT

CTX_RESTRICT_SCOPE


Interface Repository Interfaces and Classes
A fourth group contains the Interface Repository interfaces and classes,
which are generated by the idlj compiler from the OMG IDL
interface ir.idl. The purpose of the Interface Repository is to
identify the interfaces stored in it so that they can be accessed by an
ORB. Each module, type, interface, attribute, operation, parameter, exception,
constant, and so on is described completely by the Interface Repository
API.

An ORB does not require that there be an interface repository, and Java
IDL does not include one. Even though this release does not include an
implementation of an interface repository, the following IR classes and
interfaces have been included for the purpose of creating typecodes (see
create_value_tc, create_struct_tc, create_union_tc and create_exception_tc
methods in interface org.omg.CORBA.ORB):
&nbs


IRObject


IDLType


DefinitionKind


StructMember


UnionMember


ValueMember




Related Documentation
For overviews, guides, and a tutorial, please see:


Java IDL home page



CORBA Features Not Implemented in Java IDL
Some of the API included in org.omg subpackages is provided for
conformance with the current OMG CORBA specification but is not implemented
in Sun's release of the JDKTM. This enables
other JDK licensees to provide implementations of this API in standard
extensions and products.


Features That Throw NO_IMPLEMENT
Some of the API included in org.omg subpackages throw 
NO_IMPLEMENT exceptions for various reasons.  Among these reasons
are:


In some cases, for example LocalObject, the complete
        implementation according to the specification indicates that 
        these API should throw NO_IMPLEMENT.
        
In most cases, for example methods in ORB.java, 
        methods that throw  
        NO_IMPLEMENT are actually implemented in subclasses
        elsewhere in the ORB code.
        
In some cases, for example _get_interface_def() 
        and _get_interface, API are really not yet implemented.
        

General Summary of Features or API Not Implemented in This Release:


Interface Repository. An Interface Repository is not required for normal
operation of Java IDL.


Java IDL does not support long double.  



Policies (org.omg.CORBA.Policy) and methods for getting them are not implemented.


Domain managers (org.omg.CORBA.DomainManager) and methods for
getting them are not implemented.


Service Information org.omg.CORBA.ServiceInformation and ORB method public boolean get_service_information(short service_type, 
ServiceInformationHolder
service_info)  are not implemented.

ORB methods for supporting single-threading (perform_work, work_pending) are not implemented.

IDL contexts.



Specific List of Unimplemented Features in Package org.omg.CORBA

Unimplemented Methods in package org.omg.CORBA:


ORB


public org.omg.CORBA.Policy create_policy(int type, org.omg.CORBA.Any
val)

public void perform_work()

public boolean work_pending()

public org.omg.CORBA.Current get_current()

create_operation_list

get_default_context

get_service_information

obsolete DynAnys (deprecated in favor of DynamicAny package)",Package
10176,org.omg.CORBA_2_3,"The CORBA_2_3 package defines additions to existing CORBA interfaces
in the Java[tm] Standard Edition 6.   These changes occurred in recent
revisions to the CORBA API defined by the OMG.  The new methods were
added to  interfaces derived from the corresponding interfaces in
the CORBA package.  This provides backward compatibility and avoids
breaking the JCK tests.

Package Specification
For a precise list of supported sections of official specifications with which 
the Java[tm] Platform, Standard Edition 6, ORB complies, see Official Specifications for CORBA 
support in Java[tm] SE 6.


The following methods in the abstract class 
org.omg.CORBA_2_3.ORB are unimplemented:


public org.omg.CORBA.portable.ValueFactory 
  register_value_factory(String id, org.omg.CORBA.portable.ValueFactory 
factory)
public void unregister_value_factory(String id)
public org.omg.CORBA.portable.ValueFactory 
  lookup_value_factory(String id)
public org.omg.CORBA.Object get_value_def(String repid)
public void set_delegate(java.lang.Object wrapper)",Package
10177,org.omg.CORBA_2_3.portable,"Provides methods for the input and output of value types, and contains 
 other updates to the org/omg/CORBA/portable package.",Package
10178,org.omg.CORBA.DynAnyPackage,"Provides the exceptions used with the DynAny interface 
(InvalidValue,  
Invalid, InvalidSeq, and 
TypeMismatch).",Package
10179,org.omg.CORBA.ORBPackage,"Provides the exception InvalidName, which is thrown
by the method ORB.resolve_initial_references
and the exception InconsistentTypeCode, which is thrown
by the Dynamic Any creation methods in the ORB class.


        Related Documentation

For an overview, please see:


  comments on the CORBA package",Package
10180,org.omg.CORBA.portable,"Provides a portability layer, that is, a set of ORB APIs
that makes it possible for code generated
by one vendor to run on another vendor's ORB. 
Stubs and other code, generated either from IDL or 
interfaces written in the Java programming language, 
can call into these ORB APIs.






CORBA Features Throwing NO_IMPLEMENT() Exceptions

Some methods throw NO_IMPLEMENT() exceptions by default, but ORB vendors
can override them to provide real implementations.  The ORB included in
Sun's release of the Java[tm] Platform, Standard Edition 6, includes 
implementations for the following methods.

List of Unimplemented Features in Package
org.omg.CORBA.portable

Unimplemented Interfaces in package org.omg.CORBA.portable


InvokeHandler
    ResponseHandler



Unimplemented Methods in package org.omg.CORBA.portable


InputStream
  
public int read()
    public.math.BigDecimal read_fixed()
    public org.omg.CORBA.Context read_Context() 
    public  org.omg.CORBA.Object read_Object(java.lang.Class clz)
    public org.omg.CORBA.ORB orb() 
  
OutputStream
  
public org.omg.CORBA.ORB orb()
    public void write_Context(org.omg.CORBA.Context ctx,
                              org.omg.CORBA.ContextList contexts) 
    public void write_fixed(java.math.BigDecimal value) 
    public void write(int b) 
  
Delegate
  
public void releaseReply(org.omg.CORBA.Object self, InputStream input)
    public InputStream invoke(org.omg.CORBA.Object self, OutputStream output)
    public OutputStream request(org.omg.CORBA.Object self, String operation,
                                 boolean responseExpected)
    public org.omg.CORBA.Object set_policy_override(org.omg.CORBA.Object self,
                                        org.omg.CORBA.Policy[] policies,
                                        org.omg.CORBA.SetOverrideType set_add)
    public org.omg.CORBA.DomainManager[] get_domain_managers(
                                                org.omg.CORBA.Object
                                                self)
    public org.omg.CORBA.Policy get_policy(org.omg.CORBA.Object self,
                                         int policy_type)",Package
10181,org.omg.CORBA.TypeCodePackage,"Provides the user-defined exceptions BadKind
and Bounds, which are thrown by methods in
in the class TypeCode.


        Related Documentation

For an overview, please see:


  comments on the CORBA package",Package
10182,org.omg.CosNaming,"Provides a naming service for Java IDL.  The Object Request Broker Daemon
  (ORBD) also includes both a transient and persistent naming service.
  

  
  The package and all its classes and interfaces 
  were generated by running the tool idlj on the file
  nameservice.idl, which is a module written in OMG IDL.
  
  Package Specification
For a precise list of supported sections of official specifications with which 
the Java[tm] Platform, Standard Edition 6, ORB complies, see Official Specifications for CORBA 
support in Java[tm] SE 6.
  
Interfaces
  The package org.omg.CosNaming contains two public interfaces
  and several auxiliary classes. 
  
  The interfaces are:
  
NamingContext
BindingIterator


  These two interfaces provide the means to bind/unbind names and object
  references, to retrieve bound object references, and
  to iterate through a list of bindings.  The NamingContext
  interface supplies the main functionality for the naming service, and
  BindingIterator provides a means of iterating through a list
  of name/object reference bindings.
  
Auxiliary Classes
  In order to map an OMG IDL interface to the Java programming language,
  the idlj compiler creates Java classes that can be thought of
  as auxiliary classes.
  Comments for the generated auxiliary classes
  used by the interfaces NamingContext and 
  BindingIterator are included here.
  
Classes Used by NamingContext and
  BindingIterator
  The following are classes used by
  the naming service.  (Helper and  holder classes, which are
  generated for each of the classes listed here,  are discussed below.)
 
  
public final class NameComponent -- 
    a building block for names.  (Names are bound to object references
    in a naming context.)
    A name is an array of one or more NameComponent objects.
    A name with a single NameComponent is called
    a simple name; a name with multiple NameComponent
    objects is called a compound name.
    
    A NameComponent object consists of two fields:
    
id -- a String used as an identifier
    kind -- a String that can be used for 
any
    descriptive purpose.  Its importance is that it
    can be used to describe an object without affecting syntax.
    The C programming language, for example, uses the the syntactic convention
    of appending the extension "".c"" to a file name to indicate that it is
    a source code file.  In a NameComponent object,
    the kind field can be used to describe the type of object
    rather than a file extension or some other syntactic convention.
    Examples of the value of the kind field include the strings
    ""c_source"", ""object_code"",
    ""executable"", 
    ""postscript"", and """".  It is not unusual
        for the kind field to be the empty string.
    

    In a name, each NameComponent object except the last denotes
    a NamingContext object; the last NameComponent
    object denotes the bound object reference.
    This is similar to a path name, in which the last name is the
    file name, and all names before it are directory names.

public final class Binding -- 
    an object that associates a name with an object reference or a
    naming context.
    A Binding object has two fields:
    
binding_name - an array of one or more
    NameComponent objects that represents the bound name
    binding_type - a BindingType object
    indicating whether the binding is between a name and an object
    reference or between a name and a naming context
    

    The interface NamingContext has methods for
        binding/unbinding names with object references or naming contexts,
        for listing bindings,
    and for resolving bindings (given a name, the method
    resolve returns the object reference bound to it).
   
  
public final class BindingType --
    an object that specifies whether the given Binding
    object is a binding between a name and an object reference (that is,
    not a naming context) or between a name and a naming context.
    
    The classBindingType consists of two methods and
        four constants. Two of these constants are
        BindingType objects, and two are ints.
        
        The BindingType objects
    can be passed to the constructor for the class
    Binding or used as parameters or return values.  These
        BindingType objects are:
    
public static final BindingType nobject -- 
        to indicate that the binding is with an object reference
    public static final BindingType ncontext -- 
        to indicate that the binding is with a naming context
    

        The int constants can be supplied to the method
        from_int to create  BindingType objects,
        or they can be return values for the method value.
        These constants are:
        
public static final int _nobject
public static final int _ncontext

    If the method from_int is supplied with anything other
        than _nobject
    or _ncontext, it will throw
        the exception org.omg.CORBA.BAD_PARAM. 
        Usage is as follows:
    
       BindingType btObject = from_int(_nobject);
       BindingType btContext = from_int(_ncontext);
    
    The variable btObject refers to a BindingType
    object initialized to represent a binding with an object reference.
    The variable btContext refers to a BindingType
    object initialized to represent a binding with a
    NamingContex object.
    
    The method value returns either
    _nobject or _ncontext, so
    in the following line of code, the variable bt
    will contain _nobject or _ncontext:
    
       int bt = BindingType.value();
    

Holder Classes
 
  OMG IDL uses OUT and INOUT parameters for returning values from operations.
  The mapping to the Java programming language, which does not have OUT
  and INOUT parameters, creates a special class for each type, called
  a holder class. 
  An instance of a holder class can be passed to a
  Java method as a parameter, and
  a value can be assigned to its value field.  This allows
  it to perform the function of an OUT or INOUT parameter.  
  The following holder classes are generated for the package
  org.omg.CosNaming:
  
NamingContextHolder
BindingIteratorHolder
BindingHolder
BindingListHolder
BindingTypeHolder
NameComponentHolder
NameHolder


  Note that in the org.omg.CORBA package, 
  there is a holder class for each of the basic Java types:
  IntHolder, ShortHolder, 
  StringHolder, and so on.
  
  Note also that there is a NameHolder class even though
  there is no Name class; similarly, there is a
  BindingListHolder class even though there is no
  BindingList class.  This is true because in the OMG IDL
  interface, Name and BindingList are 
  typedefs.  There is no mapping from an IDL 
  typedef to a Java construct, but holder classes
  are generated if the typedef is for a sequence or
  an array.  As mapped to the
  Java programming language, Name is an array of
  NameComponent objects, and a BindingList
  is an array of Binding objects.
  
  All holder classes have at least two constructors and one field:
  
value field -- an instance of the type being used as
    an OUT or INOUT parameter.  For example, the value field of a
    NamingContextHolder will be a NamingContext
    object.  
  default constructor -- a constructor that creates a new holder object
    initialized with the default value for the type.  For example, a new
    BindingHolder object created with the default constructor
    will have its value field set to null because
    that is the default value for an object.  Other defaults are
    false for  boolean,
    0 for numeric and char types, and
    null for  object references.
  constructor from an instance -- a constructor that creates a new
    holder object whose value field is
    initialized with the instance supplied
  

  A holder class for a user-defined type (a Java class) has three more
  methods, but application developers do not use them directly.
 
  Helper Classes
  Helper classes, which are generated for all user-defined types
  in an OMG IDL interface, supply static methods needed to manipulate
  those types.  
  
  There is only one method in a helper class that an
  application programmer uses:  the
  method narrow.  Only Java interfaces mapped from IDL
  interfaces will have a helper class that includes a narrow
  method, so in the CosNaming package, only the classes
  NamingContextHelper and BindingIteratorHelper
  have a narrow method.
  
public static NamingContext
  narrow(org.omg.CORBA.Object obj) -- converts the given
   CORBA object to a NamingContext object
  public static BindingIterator
  narrow(org.omg.CORBA.Object obj) -- converts the given
   CORBA object to a BindingIterator object
  
Package org.omg.CosNaming.NamingContextPackage
This package supplies Helper and Holder classes for the exceptions used
in the package org.omg.CosNaming and also for the class
NotFoundReason, which supplies a reason for the exception
NotFound.  

There are Helper and Holder classes for the following exceptions:

AlreadyBound
CannotProceed
InvalidName
NotEmpty
NotFound

Naming Service Compatibility

Sun's implementation of the CosNaming package complies
with the OMG COSNaming specification.  In other words,
the APIs in Sun's naming service are implemented according to the
guidelines for a naming service provided by OMG.  Therefore, if a 
third-party vendor has implemented a naming service that is OMG
compliant, it is possible to switch between Sun's implementation of
CosNaming and the third-party vendor's implementation.
However, it is important to understand that there can be minor
variations in the way different vendors implement the naming service,
such as differences in the exception strings.

Instructions for Using a Third Party's Naming Service
Although we encourage using an ORB and ORB services that are both
from one vendor, it is possible to plug in a third party's 
COSNaming implementation with Sun's RMI-IIOP ORB.
Here are the steps to follow:

Create a properties file for the Bootstrap server and give it
      two entries.  For example, you could call this properties file 
      /tmp/services and put the following in it:
      NameService, <Stringified IOR of the Root Naming 
Context>.
      
      This associates NameService with the Root Naming
      Context of the CosNaming implementation that you 
      want to use.
          
Start the standalone Bootstrap server using the following command:
  
      
      java -classpath $(CLASSPATH)
      com.sun.corba.ee.internal.CosNaming.BootstrapServer -InitialServicesFile
      ""/tmp/services"" [-ORBInitialPort port]
      
  

  Note that the square brackets at the end of the command indicate that
  specifying a port number is optional.


Now when an application calls the method 
org.omg.CORBA.ORB.resolve_initial_references, CORBA
processes will contact the Bootstrap Server to get the Root Naming
Context.

Package Specification

Interoperable Naming Service (ptc/00-08-07)

Related Documentation

For an overview and examples of how to use the 
CosNaming API, please see:


        Naming Service


For an overview of Java IDL, please see:


        Java IDL home page",Package
10183,org.omg.CosNaming.NamingContextExtPackage,"This package contains the following classes, which are used in 
org.omg.CosNaming.NamingContextExt:


AddressHelper
StringNameHelper
URLStringHelper
InvalidAddress
Package Specification
For a precise list of supported sections of official specifications with which 
the Java[tm] Platform, Standard Edition 6 ORB complies, see Official Specifications for CORBA 
support in Java[tm] SE 6.",Package
10184,org.omg.CosNaming.NamingContextPackage,"This package contains Exception classes for the org.omg.CosNaming
 package.  The list  of exception classes are:
 

AlreadyBound
CannotProceed
InvalidName
NotEmpty
NotFound
NotFoundReason
Package Specification
For a precise list of supported sections of official specifications with which 
the Java[tm] Platform, Standard Edition 6 ORB complies, see Official Specifications for CORBA 
support in Java SE 6.",Package
10185,org.omg.Dynamic,"This package contains the Dynamic module specified in the OMG Portable
Interceptor specification,

http://cgi.omg.org/cgi-bin/doc?ptc/2000-08-06, section 21.9.  Please
refer to that OMG specification for further details.



Package Specification
For a precise list of supported sections of official specifications with which 
the Java[tm] Platform, Standard Edition 6 ORB complies, see Official Specifications for CORBA 
support in Java[tm] SE 6.",Package
10186,org.omg.DynamicAny,"Provides classes and interfaces that enable traversal of the data value
 associated with an any at
runtime, and extraction of the primitive constituents of the data value.


An any can be passed to a program that doesn't have any static information 
for the type of the any (code generated for the type by an IDL compiler has not 
been compiled with the object implementation). As a result, the object receiving the 
any does not have a portable method of using it.

DynAnys enable traversal of the data value associated with an 
any at runtime, and extraction of the primitive constituents of the data value. 
This is especially helpful for writing powerful generic servers (bridges, event channels 
supporting filtering).  Similarly, this facility enables the construction of an 
any at runtime, without having static knowledge of its type. This is especially 
helpful for writing generic clients (bridges, browsers, debuggers, user interface tools).

Any values can be dynamically interpreted (traversed) and constructed through  
DynAny objects.  A DynAny object is associated with a data 
value which corresponds to a copy of the value inserted into an Any.  A 
DynAny object may be viewed as an ordered collection of component 
DynAnys. For DynAnys representing a basic type, such as long, 
or a type without components, such as an empty exception, the ordered collection of 
components is empty. 

Each DynAny object maintains the notion of a current position into its collection 
of component DynAnys. The current position is identified by an index value that runs 
from 0 to n-1, where n is the number of components.  The special index value -1 
indicates a current position that points nowhere.
 For values that cannot have a current position (such as an empty exception),
 the index value is fixed at -1.
 If a DynAny is initialized with a value that has components, the index is 
initialized to 0.
 After creation of an uninitialized DynAny (that is, a DynAny that 
has no value but a TypeCode
 that permits components), the current position depends on the type of value represented by
 the DynAny. (The current position is set to 0 or -1, depending on whether the 
new DynAny
 gets default values for its components.)
 
 
 The iteration operations rewind, seek, and next 
can be used to change the current position
 and the current_component operation returns the component at the current 
position.
 The component_count operation returns the number of components of a 
DynAny.
 Collectively, these operations enable iteration over the components of a 
DynAny, for example,
 to (recursively) examine its contents.
 
 
 A constructed DynAny object is a DynAny object associated with 
a constructed type.
 There is a different interface, inheriting from the DynAny interface, 
associated with
 each kind of constructed type in IDL (fixed, enum, struct, sequence, union, array,
 exception, and value type).  A constructed DynAny object exports operations 
that enable the creation of new DynAny objects,
 each of them associated with a component of the constructed data value.
 As an example, a DynStruct is associated with a struct value. This 
means that the DynStruct
 may be seen as owning an ordered collection of components, one for each structure member.
 The DynStruct object exports operations that enable the creation of new 
DynAny objects,
 each of them associated with a member of the struct.
 
 
 If a DynAny object has been obtained from another (constructed) 
DynAny object,
 such as a DynAny representing a structure member that was created from a 
DynStruct,
 the member DynAny is logically contained in the DynStruct.
 Calling an insert or get operation leaves the current position 
unchanged.
 Destroying a top-level DynAny object (one that was not obtained as a component 
of another DynAny)
 also destroys any component DynAny objects obtained from it.
 Destroying a non-top level DynAny object does nothing.
 Invoking operations on a destroyed top-level DynAny or any of its descendants 
raises OBJECT_NOT_EXIST.
 If the programmer wants to destroy a DynAny object but still wants to 
manipulate some component
 of the data value associated with it, then he or she should first create a 
DynAny for the component
 and, after that, make a copy of the created DynAny object.
 
 
 The behavior of DynAny objects has been defined in order to enable efficient 
implementations
 in terms of allocated memory space and speed of access. DynAny objects are 
intended to be used
 for traversing values extracted from anys or constructing values of 
anys at runtime.
 Their use for other purposes is not recommended.
 
 
 
 Handling DynAny objects
Insert and get operations are necessary to handle basic 
DynAny objects
 but are also helpful to handle constructed DynAny objects.
 Inserting a basic data type value into a constructed DynAny object
 implies initializing the current component of the constructed data value
 associated with the DynAny object. For example, invoking 
insert_boolean on a
 DynStruct implies inserting a boolean data value at the current 
position
 of the associated struct data value.
 A type is consistent for inserting or extracting a value if its TypeCode is 
equivalent to
 the TypeCode contained in the DynAny or, if the 
DynAny has components, is equivalent to the TypeCode
 of the DynAny at the current position.
 
 Basic operations include:
 

insert_boolean, get_boolean
        insert_char, get_char
        insert_short, get_short
        insert_ushort, get_ushort
        insert_long, get_long
        insert_ulong, get_ulong
        insert_double, get_double
        insert_string, get_string
        insert_reference, get_reference
        insert_typecode, get_typecode
        insert_longlong, get_longlong
        insert_ulonglong, get_ulonglong
        insert_longdouble, get_longdouble
        insert_wchar, get_wchar
        insert_wstring, get_wstring
        insert_any, get_any
        insert_dyn_any, get_dyn_any
        insert_val, get_val
        insert_octet, get_octet
        insert_float, get_float
        get_value
        get_as_string
        get_as_ulong
        get_members
        get_members_as_dyn_any
        get_discriminator
        get_length
        get_elements
        get_elements_as_dyn_any
        get_boxed_value
        get_boxed_value_as_dyn_any
 
DynAny and DynAnyFactory objects are intended to be local to 
the process in which they are
 created and used. This means that references to DynAny and 
DynAnyFactory objects cannot be exported
 to other processes, or externalized with ORB.object_to_string().
 If any attempt is made to do so, the offending operation will raise a MARSHAL system 
exception.
 Since their interfaces are specified in IDL, DynAny objects export operations 
defined in the standard
 org.omg.CORBA.Object interface. However, any attempt to invoke operations 
exported through the Object
 interface may raise the standard NO_IMPLEMENT exception.
 An attempt to use a DynAny object with the DII may raise the NO_IMPLEMENT 
exception.
 






Package Specification
For a precise list of supported sections of official specifications with which 
the Java[tm] Platform, Standard Edition 6 ORB complies, see Official Specifications for CORBA 
support in Java[tm] SE 6.",Package
10187,org.omg.DynamicAny.DynAnyFactoryPackage,"This package contains classes and exceptions from the DynAnyFactory
interface of the
DynamicAny module
specified in the OMG The Common Object Request Broker: Architecture and
Specification,

http://cgi.omg.org/cgi-bin/doc?formal/99-10-07, section 9.2.2.  Please
refer to that OMG specification for further details.

Package Specification
For a precise list of supported sections of official specifications with which 
the Java[tm] Platform, Standard Edition 6 ORB complies, see Official Specifications for CORBA 
support in Java SE 6.",Package
10188,org.omg.DynamicAny.DynAnyPackage,"This package contains classes and exceptions from the DynAny
 interface of the DynamicAny module
specified in the OMG The Common Object Request Broker: Architecture and
Specification,

http://cgi.omg.org/cgi-bin/doc?formal/99-10-07, section 9.2.  Please
refer to that OMG specification for further details.



Package Specification
For a precise list of supported sections of official specifications with which 
the Java[tm] Platform, Standard Edition 6 ORB complies, see Official Specifications for CORBA 
support in Java[tm] SE 6.",Package
10189,org.omg.IOP,"This package contains the IOP module specified in the OMG document
The Common
Object Request Broker: Architecture and Specification,

http://cgi.omg.org/cgi-bin/doc?formal/99-10-07, section 13.6.  Please
refer to that OMG specification for further details.

Please note that we do not provide all parts of the IOP module from
the specification.  We only provide those parts that are referenced as
return values or parameter types in public APIs, most notably,
Portable Interceptors.





Package Specification
For a precise list of supported sections of official specifications with which 
the Java[tm] Platform, Standard Edition 6 ORB complies, see Official Specifications for CORBA 
support in Java[tm] SE 6.",Package
10190,org.omg.IOP.CodecFactoryPackage,"This package contains the exceptions
specified in the IOP::CodeFactory interface (as part of the Portable
 Interceptors spec).


Package Specification
For a precise list of supported sections of official specifications with which 
the Java[tm] Platform, Standard Edition 6 ORB complies, see Official Specifications for CORBA 
support in Java SE 6.",Package
10191,org.omg.IOP.CodecPackage,"This package is generated from the IOP::Codec IDL interface
definition.  It contains the Java representations of the IDL exceptions
specified in IOP::Codec (as part of the Portable Interceptors
specification).  
 Please
refer to that OMG specification for further details.


Package Specification
For a precise list of supported sections of official specifications with which 
the Java[tm] Platform, Standard Edition 6 ORB complies, see Official Specifications for CORBA 
support in Java[tm] SE 6.",Package
10192,org.omg.Messaging,"This package contains the Messaging module specified in the OMG CORBA
Messaging specification, 

http://cgi.omg.org/cgi-bin/doc?formal/99-10-07.  Please refer to that OMG
specification for further details.

Please note that we do not provide all parts of the Messaging module from
the specification.  We only provide those parts that are referenced as
return values or parameter types in public APIs, most notably,
Portable Interceptors.

Package Specification
For a precise list of supported sections of official specifications with which 
the Java[tm] Platform, Standard Edition 6 ORB complies, see Official Specifications for CORBA 
support in Java[tm] SE 6.",Package
10193,org.omg.PortableInterceptor,"Provides a mechanism to register ORB hooks through which ORB services
can intercept the normal flow of execution of the ORB.

Interceptor Types
There are currently three types of interceptors that can be registered:

IORInterceptor - 
      Used to establish tagged components in the profiles within an IOR.
ClientRequestInterceptor - 
      Intercepts the flow of a request/reply sequence through the ORB on 
      the client side.
ServerRequestInterceptor - 
      Intercepts the flow of a request/reply sequence through the ORB on 
      the server side.

See the javadocs for class 
ORBInitializer 
for how to go about registering interceptors.


Known limitations / unimplemented methods in package 
org.omg.PortableInterceptor



RequestInfo

sync_scope(): Always returns SYNC_WITH_TRANSPORT
arguments(): Only supported for DII/DSI calls
exceptions(): Only supported for DII calls on client side.  
          Not supported on server-side.
contexts(): Only supported for DII calls on client side.
          Not supported on server-side since our ORB does not send contexts.
          
operation_context(): Only supported for DII calls 
          on client side.  Not supported on server-side since ORB 
          does not send contexts.
result(): Only supported for DII/DSI calls



ClientRequestInfo

received_exception_id(): Always returns null in the 
          DII case
get_request_policy(int type): Not implemented.



ServerRequestInfo

sending_exception(): Does not support user exceptions on 
          the server side in non-DSI case.




Package Specification
For a precise list of supported sections of official OMG specifications with which 
the Java[tm] Platform, Standard Edition 6 complies, see Official Specifications for CORBA 
support in Java SE 6.",Package
10194,org.omg.PortableInterceptor.ORBInitInfoPackage,"This package contains the exceptions and typedefs from the ORBInitInfo
local interface of the PortableInterceptor module specified in the OMG
Portable Interceptor specification,

http://cgi.omg.org/cgi-bin/doc?ptc/2000-08-06, section 21.7.2.  Please
refer to that OMG specification for further details.
 

Package Specification
For a precise list of supported sections of official specifications with which 
the Java[tm] Platform, Standard Edition 6 ORB complies, see Official Specifications for CORBA 
support in Java SE 6.",Package
10195,org.omg.PortableServer,"Provides classes and interfaces for making the server side of your applications 
portable across multivendor ORBs.

In Java, Portable Object Adaptor (POA)-based Dynamic Skeleton Interface (DSI) 
servants inherit from the  standard DynamicImplementation class, which 
inherits from the Servant class. The native Servant type is 
defined by the PortableServer module for the POA. In Java, the 
  Servant type is mapped to the Java 
  org.omg.PortableServer.Servant class.
  It serves as the base class for all POA servant 
  implementations and provides a number of methods that may 
  be invoked by the application programmer, as well as methods 
  which are invoked by the POA itself and may be overridden by 
  the user to control aspects of servant behavior. 
  
Package Specification
For a precise list of supported sections of official OMG specifications with which 
the Java[tm] Platform, Standard Edition 6 complies, see Official Specifications for CORBA 
support in Java[tm] SE 6.

POA-related Interfaces
The PortableServer module defines the following POA-related interfaces:


POA
POAManager
ServantManager
ServantActivator
ServantLocator
AdapterActivator
ThreadPolicy
LifespanPolicy
IdUniquenessPolicy
IdAssignmentPolicy
ImplicitActivationPolicy
ServantRetentionPolicy
RequestProcessingPolicy
Current

In addition, the POA defines the Servant native type.

Operations classes
Each of the interfaces listed above has an associated Operations interface.  The Operations interface is generated by the idlj compiler and contains the method signatures for methods defined in its associated interface.  The Operations interface can be accessed by both the client and the server, while its associated interface can only be called by the client.

Value Classes

Classes ending in the suffix PolicyValue provide the values used for the create_POA call, which sets the policy for the POA.   See the sample code below for a demonstration.  PolicyValue files include the following:


IdAssignmentPolicyValue
IdUniquenessPolicyValue
ImplicitActivationPolicyValue
LifespanPolicyValue
RequestProcessingPolicyValue
ServantRetentionPolicyValue
ThreadPolicyValue

Helper Classes
Helper classes, which are generated for all user-defined types in an OMG IDL 
interface, supply static methods needed to manipulate those types.  There is only one method in a helper class that an application programmer uses: the  narrow method.  Only Java interfaces mapped from IDL interfaces will have a helper class that includes a narrow method, so in the PortableServer package, only the following classes have a narrow method:


ForwardRequestHelper
ServantActivatorHelper
ServantLocatorHelper

POA Classes
POA classes are used to implement the ServantActivator or ServantLocator.

Exceptions
The ForwardRequest exception indicates to the ORB 
that it is responsible for delivering the current request and subsequent ForwardRequest requests to the object denoted in the 
 forward_reference member of the exception.

Interfaces Implemented by the Application Programmer
Most of what PortableServer does is transparent to the user.  The result is that programmers will use only a few of the interfaces mentioned above.  The remaining interfaces will be provided by the ORB implementation.  The interfaces of interest to application programmers are the following:


AdapterActivator
Adapter activators are associated with POAs.  An adapter activator supplies a POA with the ability to create child POAs on demand, as a side-effect of receiving a request that names the child POA (or one of its children), or when find_POA is called with an activate parameter value of TRUE.  An application server that creates all its needed POAs at the beginning of execution does not need to use or provide an adapter activator; it is necessary only for the case in which POAs need to be created during request processing.
        
ServantLocator
When the POA has the NON_RETAIN policy, it uses servant managers that are ServantLocators.
        
ServantActivator
When the POA has the RETAIN policy, it uses servant managers that are ServantActivators.

Package org.omg.PortableServer.ServantLocatorPackage
This package supplies a CookieHolder class for passing 
the Cookie type as an out parameter. The CookieHolder class 
follows exactly the same pattern as the other holder classes for basic types.

Related Documentation
For an overview of Java IDL, please see:

Java IDL home page.

Example Code

Example Server Code


import javax.naming.InitialContext;
import javax.naming.Context;
import javax.rmi.PortableRemoteObject ;
import com.sun.corba.se.impl.poa.POAORB;
import org.omg.PortableServer.*;
import java.util.*;
import org.omg.CORBA.*;
import javax.rmi.CORBA.Stub;
import javax.rmi.CORBA.Util;



public class HelloServer {
    public HelloServer(String[] args) {
        try {
            Properties p = System.getProperties();
         //   p.put(""org.omg.CORBA.ORBClass"", ""com.sun.corba.ee.internal.POA.POAORB"");
            ORB orb = ORB.init( args, p );

            POA rootPOA = (POA)orb.resolve_initial_references(""RootPOA"");

            Policy[] tpolicy = new Policy[3];
            tpolicy[0] = rootPOA.create_lifespan_policy(
                LifespanPolicyValue.TRANSIENT );
            tpolicy[1] = rootPOA.create_request_processing_policy(
                RequestProcessingPolicyValue.USE_ACTIVE_OBJECT_MAP_ONLY );
            tpolicy[2] = rootPOA.create_servant_retention_policy(
                ServantRetentionPolicyValue.RETAIN);
            POA tpoa = rootPOA.create_POA(""MyTransientPOA"", null, tpolicy);


            String  ObjectId = ""MyObjectId"";
            byte[] oid = ObjectId.getBytes();

            org.omg.CORBA.Object obj = tpoa.create_reference_with_id(oid,
                new _HelloImpl_Tie()._all_interfaces(tpoa, oid)[0]);
            HelloInterface helloRef = (HelloInterface)PortableRemoteObject.narrow(
                obj, HelloInterface.class );

            Context initialNamingContext = new InitialContext();
            initialNamingContext.rebind(""HelloService"", helloRef);
            System.out.println(""Hello Server: Ready..."");
            orb.run();
         } catch (Exception e) {
            System.out.println(""Trouble: "" + e);
            e.printStackTrace();
         } 
     }


     public static void main(String args[]) {
         new HelloServer( args );
     }
}",Package
10196,org.omg.PortableServer.CurrentPackage,"Provides method implementations with 
 access to the identity of the object on which the 
 method was invoked. The Current package
 supports servants that implement multiple objects, 
 but can be used within the context of POA-dispatched 
 method invocations on any servant. To provide location 
 transparency, ORBs are required to support use of 
 Current in the context of both locally and remotely 
 invoked operations. An instance of Current can be 
 obtained by the application by issuing the 
 CORBA::ORB::resolve_initial_references(""POACurrent"") 
 operation. Thereafter, it can be used within the 
 context of a method dispatched by the POA to obtain 
 the POA and ObjectId that identify the object on 
 which that operation was invoked.

Package Specification
For a precise list of supported sections of official specifications with which 
the Java[tm] Platform, Standard Edition 6 ORB complies, see Official Specifications for CORBA 
support in Java[tm] SE 6.",Package
10197,org.omg.PortableServer.POAManagerPackage,"Encapsulates the processing 
 state of the POAs it is associated with.  Each POA object has an associated POAManager object.  A POA manager may be associated with one or more 
 POA objects.


Package Specification
For a precise list of supported sections of official specifications with which 
the Java[tm] Platform, Standard Edition 6 ORB complies, see Official Specifications for CORBA 
support in Java[tm] SE 6.",Package
10198,org.omg.PortableServer.POAPackage,"Allows programmers to construct object implementations that are portable
between different ORB products.  

The Portable Object Adaptor (POA) is designed to meet the following goals:


Allow programmers to construct object implementations that are portable between different ORB products.
Provide support for objects with persistent identities.
Provide support for transparent activation of objects.
Allow a single servant to support multiple object identities simultaneously.

Given an interface My defined in My.idl, the file MyPOA.java is generated by the idlj compiler. You must provide the implementation for My and it must inherit from MyPOA.  

MyPOA.java is a stream-based skeleton that extends org.omg.PortableServer.Servant and implements the InvokeHandler interface and the operations interface associated with the IDL interface the skeleton implements.

The PortableServer module for the Portable Object Adapter (POA) defines the native Servant type. In the Java programming language, the Servant type is mapped to the Java org.omg.PortableServer.Servant class.  It serves as the base class for all POA servant implementations and provides a number of methods that may 
be invoked by the application programmer, as well as methods which are invoked by the POA itself and may be overridden by the user to control aspects of servant behavior.
 


All Mapping corresponds to the Chapter 11 of 
 CORBA V2.3.1 specified by OMG document formal/99-10-07.pdf.
 The exception to this is the id attribute, which is added in ptc/00-08-06, 
 section 11.3.8.26.

Package Specification
For a precise list of supported sections of official specifications with which 
the Java[tm] Platform, Standard Edition 6, ORB complies, see Official Specifications for CORBA 
support in Java[tm] SE 6.",Package
10199,org.omg.PortableServer.portable,"Provides classes and interfaces for making the server side of your applications 
portable across multivendor ORBs.

The portable package contains interfaces and classes 
  that are designed for and intended to be used by an ORB 
implementor. It exposes the publicly defined APIs that 
 are used to connect stubs and skeletons to the ORB.
 The Delegate interface provides the ORB-vendor-specific 
 implementation of PortableServer::Servant.
 This package conforms CORBA Specification V2.3.1, ptc/00-01-08.",Package
10200,org.omg.PortableServer.ServantLocatorPackage,"Provides classes and interfaces for locating the servant.

This package supplies a CookieHolder class for passing 
the Cookie type as an out parameter. The CookieHolder class 
follows exactly the same pattern as the other holder classes for basic types.
  
Package Specification
For a precise list of supported sections of official OMG specifications with which 
the Java[tm] Platform, Standard Edition 6 complies, see Official Specifications for CORBA 
support in Java[tm] SE 6.",Package
10201,org.omg.SendingContext,"Provides support for the  marshalling of value types.  Value type
 marshalling may require access to an implementation of the value type or
 to meta information about the value type.  This information is passed
 between the sending context and the receiving context using a particular
 service context containing an instance of the
 SendingContext.RunTime interface.
 
 A sending context may be either the client side or the server side of
 an invocation, depending on which contains a value type.
 The sending context is the client side of an
 invocation if the request contains a value type. It is the server side
 if the reply contains a value type.  The other party in the communication
 is the receiving context.
 
 The service context marshalled for SendingContext
 consists of an encapsulated IOR for the SendingContext.RunTime
 interface.  RunTime is just a marker
 interface defined to allow extensibility in the future.  There is
 currently only one subinterface of RunTime defined:
 the SendingContext.CodeBase interface.
 The interface CodeBase defines operations to obtain code URLs
 and meta-information about a value type received from the sending
 context.
 
 Note that these classes are currently defined in the
 com.sun.org.omg.SendingContext
 package rather than in the package org.omg.SendingContext.
 This has been done to avoid including large parts of the interface
 repository in the JDK core, since the interface repository is still
 evolving in response to the needs of the CORBA Components work.
 
Package Specification
For a precise list of supported sections of official specifications with which 
the Java[tm] Platform, Standard Edition 6 ORB complies, see Official Specifications for CORBA 
support in Java[tm] SE 6.",Package
10202,org.omg.stub.java.rmi,"Contains RMI-IIOP Stubs for the Remote types that occur in the 
  java.rmi package.",Package
10203,org.w3c.dom,"Provides the interfaces for the Document Object Model (DOM) which is a
component API of the Java API for XML
Processing.  The Document Object Model Level 2 Core API allows programs
to dynamically access and update the content and structure of documents.
See the specification
for more information.",Package
10204,org.w3c.dom.bootstrap,"A factory that enables applications to obtain instances of
 DOMImplementation.",Package
10205,org.w3c.dom.events,"Event operations may throw an EventException as specified in
 their method descriptions.",Package
10206,org.w3c.dom.ls,"Parser or write operations may throw an LSException if the
 processing is stopped.",Package
10207,org.xml.sax,"This package provides the core SAX APIs.
Some SAX1 APIs are deprecated to encourage integration of
namespace-awareness into designs of new applications
and into maintenance of existing infrastructure. 
See http://www.saxproject.org
for more information about SAX.
 SAX2 Standard Feature Flags 
 One of the essential characteristics of SAX2 is that it added
feature flags which can be used to examine and perhaps modify
parser modes, in particular modes such as validation.
Since features are identified by (absolute) URIs, anyone
can define such features.   
Currently defined standard feature URIs have the prefix
http://xml.org/sax/features/ before an identifier such as
validation.  Turn features on or off using
setFeature.  Those standard identifiers are: 


Feature ID
Access
Default
Description


external-general-entities
read/write
unspecified
 Reports whether this parser processes external
            general entities; always true if validating.
                


external-parameter-entities
read/write
unspecified
 Reports whether this parser processes external
            parameter entities; always true if validating.
                


is-standalone
(parsing) read-only, (not parsing) none
not applicable
 May be examined only during a parse, after the
            startDocument() callback has been completed; read-only.
            The value is true if the document specified standalone=""yes"" in 
            its XML declaration, and otherwise is false.
                


lexical-handler/parameter-entities
read/write
unspecified
 A value of ""true"" indicates that the LexicalHandler will report
            the beginning and end of parameter entities.
                


namespaces
read/write
true
 A value of ""true"" indicates namespace URIs and unprefixed local names
            for element and attribute names will be available.
                


namespace-prefixes
read/write
false
 A value of ""true"" indicates that XML qualified names (with prefixes) and
            attributes (including xmlns* attributes) will be available.
                


resolve-dtd-uris
read/write
true
 A value of ""true"" indicates that system IDs in declarations will
            be absolutized (relative to their base URIs) before reporting.
            (That is the default behavior for all SAX2 XML parsers.)
            A value of ""false"" indicates those IDs will not be absolutized;
            parsers will provide the base URI from
            Locator.getSystemId().
            This applies to system IDs passed in 
DTDHandler.notationDecl(),
                DTDHandler.unparsedEntityDecl(), and
                DeclHandler.externalEntityDecl().
            
            It does not apply to EntityResolver.resolveEntity(),
            which is not used to report declarations, or to
            LexicalHandler.startDTD(), which already provides
            the non-absolutized URI.
            


string-interning
read/write
unspecified
 Has a value of ""true"" if all XML names (for elements, prefixes,
            attributes, entities, notations, and local names),
            as well as Namespace URIs, will have been interned
            using java.lang.String.intern. This supports fast
            testing of equality/inequality against string constants,
            rather than forcing slower calls to String.equals().
            


unicode-normalization-checking
read/write
false
 Controls whether the parser reports Unicode normalization 
        errors as described in section 2.13 and Appendix B of the 
        XML 1.1 Recommendation. If true, Unicode normalization
        errors are reported using the ErrorHandler.error() callback.
        Such errors are not fatal in themselves (though, obviously,
        other Unicode-related encoding errors may be).
                


use-attributes2
read-only
not applicable
 Returns ""true"" if the Attributes objects passed by
            this parser in ContentHandler.startElement()
            implement the org.xml.sax.ext.Attributes2 interface.
            That interface exposes additional DTD-related information,
            such as whether the attribute was specified in the
            source text rather than defaulted.
                


use-locator2
read-only
not applicable
 Returns ""true"" if the Locator objects passed by
            this parser in ContentHandler.setDocumentLocator()
            implement the org.xml.sax.ext.Locator2 interface.
            That interface exposes additional entity information,
            such as the character encoding and XML version used.
                


use-entity-resolver2
read/write
true
 Returns ""true"" if, when setEntityResolver is given
            an object implementing the org.xml.sax.ext.EntityResolver2 interface,
            those new methods will be used.
            Returns ""false"" to indicate that those methods will not be used.
                


validation
read/write
unspecified
 Controls whether the parser is reporting all validity
            errors; if true, all external entities will be read.
                


xmlns-uris
read/write
false
 Controls whether, when the namespace-prefixes feature
            is set, the parser treats namespace declaration attributes as
            being in the http://www.w3.org/2000/xmlns/ namespace.
            By default, SAX2 conforms to the original ""Namespaces in XML""
            Recommendation, which explicitly states that such attributes are
            not in any namespace.
            Setting this optional flag to ""true"" makes the SAX2 events conform to
            a later backwards-incompatible revision of that recommendation,
            placing those attributes in a namespace.
                


xml-1.1
read-only
not applicable
 Returns ""true"" if the parser supports both XML 1.1 and XML 1.0.
        Returns ""false"" if the parser supports only XML 1.0.
                


 Support for the default values of the
namespaces and namespace-prefixes
properties is required.
Support for any other feature flags is entirely optional.

 For default values not specified by SAX2,
each XMLReader implementation specifies its default,
or may choose not to expose the feature flag.
Unless otherwise specified here,
implementations may support changing current values
of these standard feature flags, but not while parsing.

 SAX2 Standard Handler and Property IDs 
 For parser interface characteristics that are described
as objects, a separate namespace is defined.  The
objects in this namespace are again identified by URI, and
the standard property URIs have the prefix
http://xml.org/sax/properties/ before an identifier such as
lexical-handler or
dom-node.  Manage those properties using
setProperty().  Those identifiers are: 


Property ID
Description


declaration-handler
 Used to see most DTD declarations except those treated
            as lexical (""document element name is ..."") or which are
            mandatory for all SAX parsers (DTDHandler).
            The Object must implement org.xml.sax.ext.DeclHandler.
            


document-xml-version
 May be examined only during a parse, after the startDocument()
            callback has been completed; read-only. This property is a 
            literal string describing the actual XML version of the document, 
            such as ""1.0"" or ""1.1"".
            


dom-node
 For ""DOM Walker"" style parsers, which ignore their
            parser.parse() parameters, this is used to
            specify the DOM (sub)tree being walked by the parser.
            The Object must implement the
            org.w3c.dom.Node interface.
            


lexical-handler
 Used to see some syntax events that are essential in some
            applications:  comments, CDATA delimiters, selected general
            entity inclusions, and the start and end of the DTD
            (and declaration of document element name).
            The Object must implement org.xml.sax.ext.LexicalHandler.
            


xml-string
 Readable only during a parser callback, this exposes a TBS
            chunk of characters responsible for the current event. 


 All of these standard properties are optional;
XMLReader implementations need not support them.",Package
10208,org.xml.sax.ext,"This package contains interfaces to SAX2 facilities that
conformant SAX drivers won't necessarily support.

See http://www.saxproject.org
for more information about SAX.
 This package is independent of the SAX2 core, though the functionality
exposed generally needs to be implemented within a parser core.
That independence has several consequences:

SAX2 drivers are not required to recognize these handlers.

You cannot assume that the class files will be present in every SAX2
installation.
This package may be updated independently of SAX2 (i.e. new
handlers and classes may be added without updating SAX2 itself).
The new handlers are not implemented by the SAX2
org.xml.sax.helpers.DefaultHandler or
org.xml.sax.helpers.XMLFilterImpl classes.
You can subclass these if you need such behavior, or
use the helper classes found here.
The handlers need to be registered differently than core SAX2
handlers.

This package, SAX2-ext, is a standardized extension to SAX2.  It is
designed both to allow SAX parsers to pass certain types of information
to applications, and to serve as a simple model for other SAX2 parser
extension packages.  Not all such extension packages should need to
be recognized directly by parsers, however.
As an example, most validation systems can be cleanly layered on top
of parsers supporting the standardized SAX2 interfaces.",Package
10209,org.xml.sax.helpers,"This package contains ""helper"" classes, including
support for bootstrapping SAX-based applications.

See http://www.saxproject.org
for more information about SAX.",Package
